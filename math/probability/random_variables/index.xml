<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>&#43;Random variables on Vishvas&#39;s notes</title>
    <link>https://vishvAsa.github.io/notes/math/probability/random_variables/</link>
    <description>Recent content in &#43;Random variables on Vishvas&#39;s notes</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <atom:link href="https://vishvAsa.github.io/notes/math/probability/random_variables/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>01 Random variable (RV) X</title>
      <link>https://vishvAsa.github.io/notes/math/probability/random_variables/01_Random_variable_RV_X/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://vishvAsa.github.io/notes/math/probability/random_variables/01_Random_variable_RV_X/</guid>
      <description>&lt;h2 id=&#34;map-sample-space-to-measurable-space&#34;&gt;Map sample space to measurable space&lt;/h2&gt;&#xA;&lt;p&gt;Consider the probability space \((S, \gs(S), v)\) and a measurable space \(R\) with an associated measure \(\gm\) and sigma algebra \(G\), aka state space.&lt;/p&gt;&#xA;&lt;p&gt;\(X:S \to R\), where \(X\) is a \((\gs(S), \gs(R))\) measurable function is a random variable (RV). To emphasize the (sigma algebra membership) structure preserving properties, we write: \(X:(S; F, v) \to R\).&lt;/p&gt;&#xA;&lt;p&gt;Note that \((R, \gs(R))\) is usually \((\Re, B)\), where B is the union and complement closure of the set of (semi)open intervals.&lt;/p&gt;</description>
    </item>
    <item>
      <title>02 Multiple random variables</title>
      <link>https://vishvAsa.github.io/notes/math/probability/random_variables/02_Multiple_random_variables/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://vishvAsa.github.io/notes/math/probability/random_variables/02_Multiple_random_variables/</guid>
      <description>&lt;h2 id=&#34;random-vector&#34;&gt;Random vector&lt;/h2&gt;&#xA;&lt;p&gt;A random vector is an n-dim vector \(X = (A_{i})\), which are a bunch of jointly distributed random variables. Similarly, \(X\) can be a \(m \times n\) random matrix.&lt;/p&gt;&#xA;&lt;p&gt;Below, we consider \(X = (X_1, X_2)\), where \(X_1:(S_1; F_1, v_1) \to R_1\) and \(X_2:(S_2; F_2, v_2) \to R_2\).&lt;/p&gt;&#xA;&lt;p&gt;A random vector is itself a random variable \(X:(S_1 \times S_2; F_1 \times F_2, v) \to (R_1 \times R_2)\).&lt;/p&gt;&#xA;&lt;h3 id=&#34;marginalization&#34;&gt;Marginalization&lt;/h3&gt;&#xA;&lt;p&gt;The marginalization properties of the joint/ product probability space leads to: \(Pr(X_1 \in E_1, X_2 \in S_2) = Pr(X_1 \in E_1)\), so \(\int_{E_1 \times S_2} f_X(x) dv = \int_{E_1} \int_{x_2 \in S_2} f_{X}(x_1, x_2) dv_2 dv_1 = \int_{E_1} f_{X_1}(x_1)dv_1\).&lt;/p&gt;</description>
    </item>
    <item>
      <title>03 Averaging using the pdf</title>
      <link>https://vishvAsa.github.io/notes/math/probability/random_variables/03_Averaging_using_the_pdf/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://vishvAsa.github.io/notes/math/probability/random_variables/03_Averaging_using_the_pdf/</guid>
      <description>&lt;p&gt;Consider the real valued random variable \(X: (S, B) \to (R, B_r, m)\), whose pdf is \(f_X\) defined relative to the reference measure \(m\).&lt;/p&gt;&#xA;&lt;h2 id=&#34;mean-expectation-of-real-valued-rv&#34;&gt;Mean/ Expectation of real valued RV&lt;/h2&gt;&#xA;&lt;p&gt;Aka Expected value. \(E:\set{RV} \to R\). \(E[X] = \mean = \int_{X} x f_X(x) dm = E_{X}[X]\).&lt;/p&gt;&#xA;&lt;p&gt;This is the weighted average of \(range(X)\). \(E[X]\) is actually a convex combination of points in range(X).&lt;/p&gt;&#xA;&lt;h3 id=&#34;subscript-notation&#34;&gt;Subscript notation&lt;/h3&gt;&#xA;&lt;p&gt;See probability section.&lt;/p&gt;&#xA;&lt;h3 id=&#34;conditional-expectation&#34;&gt;Conditional Expectation&lt;/h3&gt;&#xA;&lt;p&gt;Conditional expectation of X wrt event A: \(E_{X}[X|A]\) is computed  using the conditional pdf \(f_{X|A}(x)\). Sometimes, this is considered as a function of variable \(A\).&lt;/p&gt;</description>
    </item>
    <item>
      <title>04 Random Vector properties</title>
      <link>https://vishvAsa.github.io/notes/math/probability/random_variables/04_Random_Vector_properties/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://vishvAsa.github.io/notes/math/probability/random_variables/04_Random_Vector_properties/</guid>
      <description>&lt;h2 id=&#34;mean&#34;&gt;Mean&lt;/h2&gt;&#xA;&lt;p&gt;\(E[X] \dfn (E[X_i])\).&lt;/p&gt;&#xA;&lt;h3 id=&#34;linearity&#34;&gt;Linearity&lt;/h3&gt;&#xA;&lt;p&gt;If \(X\) is a random matrix, A, B, C are constant matrices: \(E[AXB + C] = AE[X]B + C\). Proof: by using \((AXB)&lt;em&gt;{i, j} = A&lt;/em&gt;{i,:} X B_{:, j}\), which is a linear combination of \(X_{k,l}\).&lt;/p&gt;&#xA;&lt;p&gt;Also, if \(X\) is random vector, \(E[a^{T}X] = a^{T}E[X]\).&lt;/p&gt;&#xA;&lt;h2 id=&#34;covariance&#34;&gt;Covariance&lt;/h2&gt;&#xA;&lt;h3 id=&#34;definition&#34;&gt;Definition&lt;/h3&gt;&#xA;&lt;p&gt;How correlated are deviations of X, Y from their means?\&#xA;\(cov(X, Y) = E_{x, y}[(X - E[X])(Y - E[Y])]\).&lt;/p&gt;</description>
    </item>
    <item>
      <title>05 Random variable sequence</title>
      <link>https://vishvAsa.github.io/notes/math/probability/random_variables/05_Random_variable_sequence/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://vishvAsa.github.io/notes/math/probability/random_variables/05_Random_variable_sequence/</guid>
      <description>&lt;p&gt;\((X_{i})\) with CDF \((F_i)\).&lt;/p&gt;&#xA;&lt;h2 id=&#34;convergence-in-distribution-to-x&#34;&gt;Convergence in distribution to X&lt;/h2&gt;&#xA;&lt;p&gt;Aka weak convergence. If \(\forall x: \lim_{n \to \infty} F_n(x) = F(x)\), then \(X_n \to^{d} X\). Comments about limit of CDF&amp;rsquo;s.&lt;/p&gt;&#xA;&lt;h2 id=&#34;convergence-in-probability-to-x&#34;&gt;Convergence in probability to X&lt;/h2&gt;&#xA;&lt;p&gt;If \(\forall \eps: \lim_{n \to \infty}Pr(|X_n - X| &amp;gt; \eps) = 0\), say \(X_n \to^p c\); so limit of sequence of probabilities. Probability of deviation from \(X\) grows smaller and smaller, but doesn&amp;rsquo;t necessarily hit 0. Eg: Weak law of large numbers.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
