+++
title = "Risk & eval"
+++

It may be essential to model \\(Pr(L|X, S)\\); this is called **Inference** in the context of probabilistic graphical models.

## Loss functions: labeling single data points
Different measures of goodness/ error functions are appropriate for different scenarios.

### Loss functions: vector labels
Loss functions in this case are often defined to penalize deviation from the actual label symmetrically.

See loss functions in regression section.

### Loss functions for classification
Below we mainly consider the loss functions \\(l(\hat{y}, y)\\) which are without regularization to account for prior belief. Loss functions used in regression can directly be applied to this case: Eg: like squared difference.

Good loss functions are realistic, maybe convex and smooth too - so that the corresponding empirical risk minimization problem (for picking classifiers) they lead to is tractable.

### 0/1 loss
\\(l() = I[\hat{y} \neq y]\\). The corresponding risk will be \\(Pr(\hat{y} \neq y) = E[I[\hat{y} \neq y]]\\), the misclassification rate.

The minimal risk classifier has the form: \\(h(X) = \argmax_L Pr(L|X, S)\\). The maximization procedure is called **Decoding** in the context of probabilistic graphical models.

However, the corresponding empirical risk minimization is non-convex, is NP hard and cannot is not approximable to a constant fraction of goodness. So, auxiliary loss functions are used.

#### Minimal risk: Binary classification
Aka Bayes risk. Suppose that data is generated by the model specified by specifying the pdfs \\(f_{X|Y=1}\\), \\(f_{X|Y=0}\\), \\(Pr(y)\\). Then, the best possible classifier is one which has accurate knowledge of the generative model, and even this classifier, in general, has a non zero risk. Its risk is given by \\(\sum_y Pr_{x: Pr(y|x) \geq 1/2}(\lnot y)\\), or by \\(E_x[\min_y Pr(y|x)]\\).


#### Connection to log loss risk: binary classification
Whenever \\(I[\hat{y} \neq y]\\), we know that \\(Pr_t(y|x) \geq 1/2\\). So, \\(E_{x, y}[-\log Pr_t(y|x)] \geq (-\log Pr_t(y|x)) Pr(\hat{y} \neq y) \geq \log 2 Pr(\hat{y} \neq y)\\). Hence, upper-bound on log loss risk is also an upper bound for \\(Pr(\hat{y} \neq y)\\).

### Log loss
Suppose that our predictor is based on the model \\(f_{Y|X,T=t}\\). Then log loss is \\(-log f_{Y|X,T=t}(y|x)\\). This punishes the model for assigning low probabilities to an observation. Minimizing log loss corresponds to maximum likelihood estimation. The corresponding risk is \\(E_{x, y}[-log f_{Y|X,T=t}(y|x)]\\).

## Loss functions: labeling multiple data points
### Confusion matrix
For qualitative evaluation, make k*k confusion matrix \\(C\\) with \\(C_{i,j}\\) as number of points belonging to class i predicted as belonging to class j.

### True and false positives, notation
\\(U \dfn \\) set of all points. \\(y(c) \dfn\\) points belonging to class c. \\(\hat{y}(c) \dfn\\) set of points predicted to belong to class c.

True positives: \\(tp(c, \hat{y}) \dfn |y(c) \inters \hat{y}(c)|\\). False positives: \\(fp(c, \hat{y}) \dfn |\hat{y}(c) - y(c)|\\).

False negatives: \\(function(c, \hat{y}) = |y(c) \inters (U - \hat{y}(c))|\\). True negatives: \\(tn(c, \hat{y}) = |(U - y(c)) \inters (U - \hat{y}(c))|\\).

### Precision, recall, specificity
Micro averaged precision : \\(P(\hat{y}) = \frac{\sum_{c}tp(c, \hat{y})}{\sum_{c} (fp(c, \hat{y})+tp(c, \hat{y}))}\\).

Recall, or completeness or sensitivity or true positive rate:\\ \\(R(\hat{y}) = \frac{\sum_{c}tp(c, \hat{y})}{\sum_{c} (function(c, \hat{y}) + tp(c, \hat{y}))}\\). Measures ability to identify items belonging to class c.

Specificity: \\(S(c, \hat{y}) = \frac{tn(c, \hat{y})}{tn(c, \hat{y}) + fp(c, \hat{y})}\\). Measures ability to discard items not belonging to class c. \\(1 - S(c, \hat{y})\\) is false positive rate.

F-measure, the harmonic mean of precision and recall, is also used to evaluate success.

#### Emphasis on one '+ve' class
If you only care about performance from the perspective of one class, as in the case of link prediction, let c range over only that class in the summations above.

#### Sensitivity - specificity tradeoff
Ideally, want to increase both sensitivity and specificity. But to increase sensitivity, the classifier often needs to take more risks in classifying an entity as 'positive'. There will be many cases where -ve entities are declared +ve: there is decrease in specificity.

Visualize two normal curves over 1-D feature: one for the -ve case and one for the +ve case. On observing a feature, a classifier uses a cutoff to identify +ve cases. Compare with tradeoff between type-1 and type-2 errors in hypothesis testing.

#### Sensitivity vs 1-specificity curve
Aka Receiver operating characteristic (ROC) curve. Take a parametrized family of predictors/ tests to identify +ve cases; the predictors are distinguished by the cutoff they choose in making classifications using the same scores for items. ROC considers the sensitivity vs specificy tradeoffs of various tests belonging to this family.

So, for all tests, you plot sensitivy and 1- specificity on a graph, and join these points by a straight line : a piecewise linear function starting at 0, and ending at 1; not a step function.

##### Area under curve (AUC)
Ranges of sensitivity and 1-specificity are [0, 1]. All curves startat 0, where every item is classified -ve, and end at 1, where every item is classified +ve.

A good test (family) is as close as possible to the left axis: parameters can be tuned to increase sensitivity without sacrificing specificity too much. An ideal test has area under the curve (AUC) 1. The higher the AUC, the better the test family. A random predictor has AUC 0.5.

So, AUC measures the test's discrimination, or the ability to separate +ve cases from the -ve cases.

#### Precision/ recall tradeoff
Recall monotonically increases with number of points classified as +ve. Precision monotonically decreases with the number of false positives. Often precision and recall have inverse relationship: if you classify all points as +ve, you have very high completeness but bad recall.

Often want to see how these change with classification parameters: so draw plots.

