<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>Vishvas&#39;s notes  | Parametric density estimation</title>
    <meta name="HandheldFriendly" content="True">
    <meta name="MobileOptimized" content="320">

    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="generator" content="Hugo 0.143.0">
    
    
      <META NAME="ROBOTS" CONTENT="INDEX, FOLLOW">
    

    <link href="/notes/math/probability/statistics/distribution_structure_learning/parametric_density_estimation/" rel="alternate" type="application/rss+xml" title="Vishvas&#39;s notes" />
    <link href="/notes/math/probability/statistics/distribution_structure_learning/parametric_density_estimation/" rel="feed" type="application/rss+xml" title="Vishvas&#39;s notes" />

    <meta property="og:url" content="https://vishvAsa.github.io/notes/math/probability/statistics/distribution_structure_learning/parametric_density_estimation/">
  <meta property="og:site_name" content="Vishvas&#39;s notes">
  <meta property="og:title" content="Parametric density estimation">
  <meta property="og:description" content="Problem and solution ideals Density estimation using a distribution class Suppose that parameter \(t\) specifies the distribution \(f_t(x_r|x_{\lnot r})\), where \(x_{\lnot r}\) can be empty! Let \(T\) be parameter space spanned by such \(t\); it represents the class of distributions which can be specified in this form.
Given finite data set \(\set{x^{(i)}}\), we want to approximate an unknown target distribution \(D(x_r|x_{\lnot r})\) which may not belong to this distribution family using \(T\). The approximation can be a weighted combination of combination of distributions in \(T\).">
  <meta property="og:locale" content="en_us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="math">

  <meta itemprop="name" content="Parametric density estimation">
  <meta itemprop="description" content="Problem and solution ideals Density estimation using a distribution class Suppose that parameter \(t\) specifies the distribution \(f_t(x_r|x_{\lnot r})\), where \(x_{\lnot r}\) can be empty! Let \(T\) be parameter space spanned by such \(t\); it represents the class of distributions which can be specified in this form.
Given finite data set \(\set{x^{(i)}}\), we want to approximate an unknown target distribution \(D(x_r|x_{\lnot r})\) which may not belong to this distribution family using \(T\). The approximation can be a weighted combination of combination of distributions in \(T\).">
  <meta itemprop="wordCount" content="1276">
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Parametric density estimation">
  <meta name="twitter:description" content="Problem and solution ideals Density estimation using a distribution class Suppose that parameter \(t\) specifies the distribution \(f_t(x_r|x_{\lnot r})\), where \(x_{\lnot r}\) can be empty! Let \(T\) be parameter space spanned by such \(t\); it represents the class of distributions which can be specified in this form.
Given finite data set \(\set{x^{(i)}}\), we want to approximate an unknown target distribution \(D(x_r|x_{\lnot r})\) which may not belong to this distribution family using \(T\). The approximation can be a weighted combination of combination of distributions in \(T\).">
<script type="text/javascript">
    
    let baseURL = "https:\/\/vishvAsa.github.io\/notes\/";
    let basePath = "/" + baseURL.split("/").slice(3).join("/");
    let siteParams = JSON.parse("{\u0022build_img\u0022:\u0022https:\/\/github.com\/vishvAsa\/notes\/actions\/workflows\/build.yml\/badge.svg\u0022,\u0022build_url\u0022:\u0022https:\/\/github.com\/vishvAsa\/notes\/actions\/workflows\/build.yml\u0022,\u0022contactlink\u0022:\u0022https:\/\/github.com\/vishvAsa\/notes\/issues\/new\u0022,\u0022env\u0022:\u0022production\u0022,\u0022githubeditmepathbase\u0022:\u0022https:\/\/github.com\/vishvAsa\/notes\/edit\/content\/\u0022,\u0022js_extras\u0022:[\u0022mathjax\u0022]}");
    let pageDefaultsList = JSON.parse("[{\u0022scope\u0022:{\u0022pathPrefix\u0022:\u0022\u0022},\u0022values\u0022:{\u0022comments\u0022:true,\u0022layout\u0022:\u0022page\u0022,\u0022search\u0022:true,\u0022sidebar\u0022:\u0022home_sidebar\u0022}}]");
    let sidebarsData = JSON.parse("{\u0022home_sidebar\u0022:{\u0022contents\u0022:[{\u0022url\u0022:\u0022recdir:\/\/\u0022},{\u0022contents\u0022:[{\u0022title\u0022:\u0022‡§ú‡•ç‡§Ø‡•å‡§§‡§ø‡§∑‡§Æ‡•ç\u0022,\u0022url\u0022:\u0022..\/jyotiSham\/\u0022},{\u0022title\u0022:\u0022‡§∏‡§Ç‡§∏‡•ç‡§ï‡•É‡§§‡§Æ‡•ç\u0022,\u0022url\u0022:\u0022..\/sanskrit\/\u0022},{\u0022title\u0022:\u0022‡§¶‡•á‡§µ‡§É\u0022,\u0022url\u0022:\u0022..\/devaH\/\u0022},{\u0022title\u0022:\u0022‡§Ü‡§ó‡§Æ‡§É\u0022,\u0022url\u0022:\u0022..\/AgamaH\/\u0022},{\u0022title\u0022:\u0022‡§Ü‡§ó‡§Æ‡§É ‡§∂‡•à‡§µ‡§É\u0022,\u0022url\u0022:\u0022..\/AgamaH_shaivaH\/\u0022},{\u0022title\u0022:\u0022‡§Ü‡§ó‡§Æ‡§É ‡§µ‡•à‡§∑‡•ç‡§£‡§µ‡§É\u0022,\u0022url\u0022:\u0022..\/AgamaH_vaiShNavaH\/\u0022},{\u0022title\u0022:\u0022‡§∞‡§æ‡§Æ‡§æ‡§®‡•Å‡§ú‡•Ä‡§Ø‡§Æ‡•ç\u0022,\u0022url\u0022:\u0022..\/rAmAnujIyam\/\u0022},{\u0022title\u0022:\u0022‡§Æ‡§æ‡§ß‡•ç‡§µ‡§Æ‡•ç\u0022,\u0022url\u0022:\u0022..\/mAdhvam\/\u0022},{\u0022title\u0022:\u0022‡§Ü‡§ó‡§Æ‡§É ‡§¨‡•ç‡§∞‡§æ‡§π‡•ç‡§Æ‡§É\u0022,\u0022url\u0022:\u0022..\/AgamaH_brAhmaH\/\u0022},{\u0022title\u0022:\u0022‡§ï‡§≤‡•ç‡§™‡§æ‡§®‡•ç‡§§‡§∞‡§Æ‡•ç\u0022,\u0022url\u0022:\u0022..\/kalpAntaram\/\u0022},{\u0022title\u0022:\u0022Notes Home\u0022,\u0022url\u0022:\u0022..\/notes\/\u0022},{\u0022title\u0022:\u0022‡§µ‡•á‡§¶‡§æ‡§É\u0022,\u0022url\u0022:\u0022..\/vedAH\/\u0022},{\u0022title\u0022:\u0022‡§µ‡•á‡§¶‡§æ‡§É - ‡§ã‡§ï‡•ç\u0022,\u0022url\u0022:\u0022..\/vedAH_Rk\/\u0022},{\u0022title\u0022:\u0022‡§µ‡•á‡§¶‡§æ‡§É - ‡§Ø‡§ú‡•Å‡§É\u0022,\u0022url\u0022:\u0022..\/vedAH_yajuH\/\u0022},{\u0022title\u0022:\u0022‡§µ‡•á‡§¶‡§æ‡§É - ‡§∏‡§æ‡§Æ\u0022,\u0022url\u0022:\u0022..\/vedAH_sAma\/\u0022},{\u0022title\u0022:\u0022‡§™‡•Å‡§∞‡§æ‡§£‡§Æ‡•ç\u0022,\u0022url\u0022:\u0022..\/purANam\u0022},{\u0022title\u0022:\u0022‡§™‡•Å‡§∞‡§æ‡§£‡§Æ‡•ç ‡§µ‡•à‡§∑‡•ç‡§£‡§µ‡§Æ‡•ç\u0022,\u0022url\u0022:\u0022..\/purANam_vaiShNavam\/\u0022},{\u0022title\u0022:\u0022‡§Æ‡§π‡§æ‡§≠‡§æ‡§∞‡§§‡§Æ‡•ç\u0022,\u0022url\u0022:\u0022..\/mahAbhAratam\/\u0022},{\u0022title\u0022:\u0022‡§∞‡§æ‡§Æ‡§æ‡§Ø‡§£‡§Æ‡•ç\u0022,\u0022url\u0022:\u0022..\/rAmAyaNam\/\u0022},{\u0022title\u0022:\u0022‡§ï‡§æ‡§µ‡•ç‡§Ø‡§Æ‡•ç\u0022,\u0022url\u0022:\u0022..\/kAvyam\/\u0022},{\u0022title\u0022:\u0022‡§Æ‡•Ä‡§Æ‡§æ‡§Ç‡§∏‡§æ\u0022,\u0022url\u0022:\u0022..\/mImAMsA\/\u0022},{\u0022title\u0022:\u0022‡≤ï‡≤®‡≥ç‡≤®‡≤°\u0022,\u0022url\u0022:\u0022..\/kannaDa\/\u0022},{\u0022title\u0022:\u0022‡§§‡•ç‡§∞‡§ø‡§™‡§ø‡§ü‡§ï‡§Æ‡•ç\u0022,\u0022url\u0022:\u0022..\/tipiTaka\/\u0022},{\u0022title\u0022:\u0022‡§™‡§æ‡§≥‡§Ø‡§É\u0022,\u0022url\u0022:\u0022..\/pALi\/\u0022},{\u0022title\u0022:\u0022‡§≠‡§æ‡§∑‡§æ‡§®‡•ç‡§§‡§∞‡§Æ‡•ç\u0022,\u0022url\u0022:\u0022..\/bhAShAntaram\/\u0022},{\u0022title\u0022:\u0022English Lit\u0022,\u0022url\u0022:\u0022..\/english\/\u0022},{\u0022title\u0022:\u0022Book pub\u0022,\u0022url\u0022:\u0022..\/book-pub\u0022},{\u0022title\u0022:\u0022Vishvas\u0027s home page\u0022,\u0022url\u0022:\u0022..\/\u0022}],\u0022title\u0022:\u0022‡§∏‡§ô‡•ç‡§ó‡•ç‡§∞‡§π‡§æ‡§®‡•ç‡§§‡§∞‡§Æ‡•ç\u0022},{\u0022title\u0022:\u0022\\u003ci class=\\\u0022fas fa-hand-holding-heart\\\u0022\\u003e\\u003c\/i\\u003eDonate Via Vishvas\u0022,\u0022url\u0022:\u0022https:\/\/vishvAsa.github.io\/interests\/dharma-via-vishvas\/\u0022}],\u0022title\u0022:\u0022Parts\u0022}}");
    
    var pageRelUrlTree = {};
</script>

    
    <script type="text/javascript">
  let pageVars = {};
  pageVars.pageUrlMinusBasePath = "\/notes\/math\/probability\/statistics\/distribution_structure_learning\/parametric_density_estimation\/".replace(basePath, "/");
  pageVars.pageParams = {};
  pageVars.pageSource = "math\/probability\/statistics\/distribution_structure_learning\/parametric_density_estimation.md";
  console.log(pageVars.pageSource);
  var pageDefaults;
  for (let possiblePageDefaults of pageDefaultsList) {
    if (pageVars.pageSource.startsWith(possiblePageDefaults.scope.pathPrefix)) {
      pageDefaults = possiblePageDefaults.values
    }
  }
    
</script>


    <script src="/notes/webpack_dist/uiLib-bundle.js"></script>


<script>


MathJax = {
  tex: {
    inlineMath: [ ["@#", "#@"], ["\\(", "\\)"] ],
    displayMath: [ ["$$","$$"], ["\\[", "\\]"] ],
    processEscapes: true,  
  },
  svg: {
    fontCache: 'global'
  },
  options: {
    ignoreHtmlClass: "tex2jax_ignore|dno"
  }
};
</script>
<script type="text/javascript" id="MathJax-script" async
        src="/notes/non_webpack_js/mathjax/tex-svg.js">
</script>






    <link rel="stylesheet" href="/notes/webpack_dist/uiLib.css">
<link rel="stylesheet" href="/notes/css/uiLibPrint.css" media="print" >
<link rel="stylesheet" href="/notes/css/fonts.css" >
<link rel="stylesheet" href="/notes/css/@fortawesome/fontawesome-free/css/solid.min.css">

<link rel="stylesheet" href="/notes/css/@fortawesome/fontawesome-free/css/fontawesome.min.css">


<link rel="alternate" hreflang="sa-Deva" href="https://vishvAsa.github.io/notes/math/probability/statistics/distribution_structure_learning/parametric_density_estimation/" />
<link rel="alternate" hreflang="sa-Deva" href="https://vishvAsa.github.io/notes/math/probability/statistics/distribution_structure_learning/parametric_density_estimation/?transliteration_target=devanagari" />

<link rel="alternate" hreflang="sa-Knda" href="https://vishvAsa.github.io/notes/math/probability/statistics/distribution_structure_learning/parametric_density_estimation/?transliteration_target=kannada" />
<link rel="alternate" hreflang="sa-Mlym" href="https://vishvAsa.github.io/notes/math/probability/statistics/distribution_structure_learning/parametric_density_estimation/?transliteration_target=malayalam" />
<link rel="alternate" hreflang="sa-Telu" href="https://vishvAsa.github.io/notes/math/probability/statistics/distribution_structure_learning/parametric_density_estimation/?transliteration_target=telugu" />
<link rel="alternate" hreflang="sa-Taml-t-sa-Taml-m0-superscript" href="https://vishvAsa.github.io/notes/math/probability/statistics/distribution_structure_learning/parametric_density_estimation/?transliteration_target=tamil_superscripted" />
<link rel="alternate" hreflang="sa-Taml" href="https://vishvAsa.github.io/notes/math/probability/statistics/distribution_structure_learning/parametric_density_estimation/?transliteration_target=tamil" />
<link rel="alternate" hreflang="sa-Gran" href="https://vishvAsa.github.io/notes/math/probability/statistics/distribution_structure_learning/parametric_density_estimation/?transliteration_target=grantha" />

<link rel="alternate" hreflang="sa-Gujr" href="https://vishvAsa.github.io/notes/math/probability/statistics/distribution_structure_learning/parametric_density_estimation/?transliteration_target=gujarati" />
<link rel="alternate" hreflang="sa-Guru" href="https://vishvAsa.github.io/notes/math/probability/statistics/distribution_structure_learning/parametric_density_estimation/?transliteration_target=gurmukhi" />
<link rel="alternate" hreflang="sa-Shar" href="https://vishvAsa.github.io/notes/math/probability/statistics/distribution_structure_learning/parametric_density_estimation/?transliteration_target=sharada" />
<link rel="alternate" hreflang="sa-Dogr" href="https://vishvAsa.github.io/notes/math/probability/statistics/distribution_structure_learning/parametric_density_estimation/?transliteration_target=dogra" />
<link rel="alternate" hreflang="sa-Phag" href="https://vishvAsa.github.io/notes/math/probability/statistics/distribution_structure_learning/parametric_density_estimation/?transliteration_target=phags_pa" />
<link rel="alternate" hreflang="sa-Tibt" href="https://vishvAsa.github.io/notes/math/probability/statistics/distribution_structure_learning/parametric_density_estimation/?transliteration_target=tibetan" />
<link rel="alternate" hreflang="sa-Sidd" href="https://vishvAsa.github.io/notes/math/probability/statistics/distribution_structure_learning/parametric_density_estimation/?transliteration_target=siddham" />
<link rel="alternate" hreflang="sa-Newa" href="https://vishvAsa.github.io/notes/math/probability/statistics/distribution_structure_learning/parametric_density_estimation/?transliteration_target=newa" />
<link rel="alternate" hreflang="sa-Modi" href="https://vishvAsa.github.io/notes/math/probability/statistics/distribution_structure_learning/parametric_density_estimation/?transliteration_target=modi" />
<link rel="alternate" hreflang="sa-Tirh" href="https://vishvAsa.github.io/notes/math/probability/statistics/distribution_structure_learning/parametric_density_estimation/?transliteration_target=tirhuta_maithili" />
<link rel="alternate" hreflang="sa-Gong" href="https://vishvAsa.github.io/notes/math/probability/statistics/distribution_structure_learning/parametric_density_estimation/?transliteration_target=gondi_gujala" />
<link rel="alternate" hreflang="sa-Gonm" href="https://vishvAsa.github.io/notes/math/probability/statistics/distribution_structure_learning/parametric_density_estimation/?transliteration_target=gondi_masaram" />


<link rel="alternate" hreflang="sa-Orya" href="https://vishvAsa.github.io/notes/math/probability/statistics/distribution_structure_learning/parametric_density_estimation/?transliteration_target=oriya" />
<link rel="alternate" hreflang="sa-Beng-t-sa-Beng-m0-assamese" href="https://vishvAsa.github.io/notes/math/probability/statistics/distribution_structure_learning/parametric_density_estimation/?transliteration_target=assamese" />
<link rel="alternate" hreflang="sa-Beng" href="https://vishvAsa.github.io/notes/math/probability/statistics/distribution_structure_learning/parametric_density_estimation/?transliteration_target=bengali" />
<link rel="alternate" hreflang="sa-Mtei" href="https://vishvAsa.github.io/notes/math/probability/statistics/distribution_structure_learning/parametric_density_estimation/?transliteration_target=manipuri" />
<link rel="alternate" hreflang="sa-Sinh" href="https://vishvAsa.github.io/notes/math/probability/statistics/distribution_structure_learning/parametric_density_estimation/?transliteration_target=sinhala" />
<link rel="alternate" hreflang="sa-Limb" href="https://vishvAsa.github.io/notes/math/probability/statistics/distribution_structure_learning/parametric_density_estimation/?transliteration_target=limbu" />
<link rel="alternate" hreflang="sa-Lepc" href="https://vishvAsa.github.io/notes/math/probability/statistics/distribution_structure_learning/parametric_density_estimation/?transliteration_target=lepcha" />


<link rel="alternate" hreflang="sa-Cyrl" href="https://vishvAsa.github.io/notes/math/probability/statistics/distribution_structure_learning/parametric_density_estimation/?transliteration_target=cyrillic" />
<link rel="alternate" hreflang="sa-Latn-t-sa-Zyyy-m0-iso" href="https://vishvAsa.github.io/notes/math/probability/statistics/distribution_structure_learning/parametric_density_estimation/?transliteration_target=iso" />
<link rel="alternate" hreflang="sa-Latn-t-sa-Zyyy-m0-iast" href="https://vishvAsa.github.io/notes/math/probability/statistics/distribution_structure_learning/parametric_density_estimation/?transliteration_target=iast" />
<link rel="alternate" hreflang="sa-Aran" href="https://vishvAsa.github.io/notes/math/probability/statistics/distribution_structure_learning/parametric_density_estimation/?transliteration_target=urdu" />
<link rel="alternate" hreflang="sa-Avst" href="https://vishvAsa.github.io/notes/math/probability/statistics/distribution_structure_learning/parametric_density_estimation/?transliteration_target=avestan" />

<link rel="alternate" hreflang="sa-Brah" href="https://vishvAsa.github.io/notes/math/probability/statistics/distribution_structure_learning/parametric_density_estimation/?transliteration_target=brahmi" />
<link rel="alternate" hreflang="sa-Khar" href="https://vishvAsa.github.io/notes/math/probability/statistics/distribution_structure_learning/parametric_density_estimation/?transliteration_target=kharoshthi" />
<link rel="alternate" hreflang="sa-Zanb" href="https://vishvAsa.github.io/notes/math/probability/statistics/distribution_structure_learning/parametric_density_estimation/?transliteration_target=zanbazar_square" />
<link rel="alternate" hreflang="sa-Bhks" href="https://vishvAsa.github.io/notes/math/probability/statistics/distribution_structure_learning/parametric_density_estimation/?transliteration_target=bhaiksuki" />

<link rel="alternate" hreflang="sa-Bali" href="https://vishvAsa.github.io/notes/math/probability/statistics/distribution_structure_learning/parametric_density_estimation/?transliteration_target=balinese" />
<link rel="alternate" hreflang="sa-Java" href="https://vishvAsa.github.io/notes/math/probability/statistics/distribution_structure_learning/parametric_density_estimation/?transliteration_target=javanese" />
<link rel="alternate" hreflang="sa-Laoo" href="https://vishvAsa.github.io/notes/math/probability/statistics/distribution_structure_learning/parametric_density_estimation/?transliteration_target=lao" />
<link rel="alternate" hreflang="sa-Laoo-t-sa-Laoo-m0-Laopali" href="https://vishvAsa.github.io/notes/math/probability/statistics/distribution_structure_learning/parametric_density_estimation/?transliteration_target=lao_pali" />
<link rel="alternate" hreflang="sa-Mymr" href="https://vishvAsa.github.io/notes/math/probability/statistics/distribution_structure_learning/parametric_density_estimation/?transliteration_target=burmese" />
<link rel="alternate" hreflang="sa-Mymr-t-sa-Mymr-m0-Mon" href="https://vishvAsa.github.io/notes/math/probability/statistics/distribution_structure_learning/parametric_density_estimation/?transliteration_target=mon" />
<link rel="alternate" hreflang="sa-Cham" href="https://vishvAsa.github.io/notes/math/probability/statistics/distribution_structure_learning/parametric_density_estimation/?transliteration_target=cham" />
<link rel="alternate" hreflang="sa-Khmr" href="https://vishvAsa.github.io/notes/math/probability/statistics/distribution_structure_learning/parametric_density_estimation/?transliteration_target=khmer" />
<link rel="alternate" hreflang="sa-Thai" href="https://vishvAsa.github.io/notes/math/probability/statistics/distribution_structure_learning/parametric_density_estimation/?transliteration_target=thai" />

  </head>

  <body class="ma0 bg-near-white">
    
\(
% groupings of objects.
\newcommand{\set}[1]{\left\{ #1 \right\}}
\newcommand{\seq}[1]{\left(#1\right)}
\newcommand{\ang}[1]{\langle#1\rangle}
\newcommand{\tuple}[1]{\left(#1\right)}
\newcommand{\size}[1]{\left| #1\right|}

\newcommand{\comp}{\circ}


% numerical shortcuts.
\newcommand{\abs}[1]{\left| #1\right|}
\newcommand{\floor}[1]{\left\lfloor #1 \right\rfloor}
\newcommand{\ceil}[1]{\left\lceil #1 \right\rceil}

% linear algebra shortcuts.
\newcommand{\change}{\Delta}
\newcommand{\norm}[1]{\left\| #1\right\|}
\newcommand{\dprod}[1]{\langle#1\rangle}
\newcommand{\linspan}[1]{\langle#1\rangle}
\newcommand{\conj}[1]{\overline{#1}}
\newcommand{\der}[1]{\frac{d#1}{dx}}
\newcommand{\lap}{\Delta}
\newcommand{\kron}{\otimes}
\newcommand{\nperp}{\nvdash}

\newcommand{\mat}[1]{\left[ \begin{smallmatrix}#1 \end{smallmatrix} \right]}

% derivatives and limits
\newcommand{\partder}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\partdern}[3]{\frac{\partial^{#3 #1}}{\partial #2^{#3}}}
\newcommand{\gradient}{\nabla}
\newcommand{\subdifferential}{\partial}

% Arrows
\newcommand{\diverge}{\nearrow}
\newcommand{\notto}{\nrightarrow}
\newcommand{\up}{\uparrow}
\newcommand{\down}{\downarrow}
% gets and gives are defined!

% ordering operators
\newcommand{\oleq}{\preceq}
\newcommand{\ogeq}{\succeq}

% programming and logic operators
\newcommand{\dfn}{:=}
\newcommand{\assign}{:=}
\newcommand{\co}{\ co\ }
\newcommand{\en}{\ en\ }


% logic operators
\newcommand{\xor}{\oplus}
\newcommand{\Land}{\bigwedge}
\newcommand{\Lor}{\bigvee}
\newcommand{\finish}{\Box}
\newcommand{\contra}{\Rightarrow \Leftarrow}
\newcommand{\iseq}{\stackrel{_?{=}}}


% Set theory
\newcommand{\symdiff}{\Delta}
\newcommand{\setdiff}{\backslash}
\newcommand{\union}{\cup}
\newcommand{\inters}{\cap}
\newcommand{\Union}{\bigcup}
\newcommand{\Inters}{\bigcap}
\newcommand{\nullSet}{\phi}


% graph theory
\newcommand{\nbd}{\Gamma}

% Script alphabets
% For reals, use \Re

% greek letters
\newcommand{\eps}{\epsilon}
\newcommand{\del}{\delta}
\newcommand{\ga}{\alpha}
\newcommand{\gb}{\beta}
\newcommand{\gd}{\del}
\newcommand{\gp}{\pi}
\newcommand{\gf}{\phi}
\newcommand{\gh}{\eta}
\newcommand{\gF}{\Phi}
\newcommand{\gl}{\lambda}
\newcommand{\gm}{\mu}
\newcommand{\gn}{\nu}
\newcommand{\gr}{\rho}
\newcommand{\gs}{\sigma}
\newcommand{\gth}{\theta}
\newcommand{\gx}{\xi}
\newcommand{\gw}{\omega}

\newcommand{\sw}{\sigma}
\newcommand{\SW}{\Sigma}
\newcommand{\ew}{\lambda}
\newcommand{\EW}{\Lambda}

\newcommand{\Del}{\Delta}
\newcommand{\gD}{\Delta}
\newcommand{\gG}{\Gamma}
\newcommand{\gW}{\Omega}
\newcommand{\gS}{\Sigma}
\newcommand{\gTh}{\Theta}

% Bold english letters.
\newcommand{\bA}{\mathbf{A}}
\newcommand{\bB}{\mathbf{B}}
\newcommand{\bC}{\mathbf{C}}
\newcommand{\bD}{\mathbf{D}}
\newcommand{\bE}{\mathbf{E}}
\newcommand{\bF}{\mathbf{F}}
\newcommand{\bG}{\mathbf{G}}
\newcommand{\bH}{\mathbf{H}}
\newcommand{\bI}{\mathbf{I}}
\newcommand{\bJ}{\mathbf{J}}
\newcommand{\bK}{\mathbf{K}}
\newcommand{\bL}{\mathbf{L}}
\newcommand{\bM}{\mathbf{M}}
\newcommand{\bN}{\mathbf{N}}
\newcommand{\bO}{\mathbf{O}}
\newcommand{\bP}{\mathbf{P}}
\newcommand{\bQ}{\mathbf{Q}}
\newcommand{\bR}{\mathbf{R}}
\newcommand{\bS}{\mathbf{S}}
\newcommand{\bT}{\mathbf{T}}
\newcommand{\bU}{\mathbf{U}}
\newcommand{\bV}{\mathbf{V}}
\newcommand{\bW}{\mathbf{W}}
\newcommand{\bX}{\mathbf{X}}
\newcommand{\bY}{\mathbf{Y}}
\newcommand{\bZ}{\mathbf{Z}}

\newcommand{\bba}{\mathbf{a}}
\newcommand{\bbb}{\mathbf{b}}
\newcommand{\bbc}{\mathbf{c}}
\newcommand{\bbd}{\mathbf{d}}
\newcommand{\bbe}{\mathbf{e}}
\newcommand{\bbf}{\mathbf{f}}
\newcommand{\bbg}{\mathbf{g}}
\newcommand{\bbh}{\mathbf{h}}
\newcommand{\bbk}{\mathbf{k}}
\newcommand{\bbl}{\mathbf{l}}
\newcommand{\bbm}{\mathbf{m}}
\newcommand{\bbn}{\mathbf{n}}
\newcommand{\bbp}{\mathbf{p}}
\newcommand{\bbq}{\mathbf{q}}
\newcommand{\bbr}{\mathbf{r}}
\newcommand{\bbs}{\mathbf{s}}
\newcommand{\bbt}{\mathbf{t}}
\newcommand{\bbu}{\mathbf{u}}
\newcommand{\bbv}{\mathbf{v}}
\newcommand{\bbw}{\mathbf{w}}
\newcommand{\bbx}{\mathbf{x}}
\newcommand{\bby}{\mathbf{y}}
\newcommand{\bbz}{\mathbf{z}}
\newcommand{\0}{\mathbf{0}}
\newcommand{\1}{\mathbf{1}}

% Caligraphic english alphabet
\newcommand{\cA}{\mathcal{A}}
\newcommand{\cB}{\mathcal{B}}
\newcommand{\cC}{\mathcal{C}}
\newcommand{\cD}{\mathcal{D}}
\newcommand{\cE}{\mathcal{E}}
\newcommand{\cF}{\mathcal{F}}
\newcommand{\cG}{\mathcal{G}}
\newcommand{\cH}{\mathcal{H}}
\newcommand{\cI}{\mathcal{I}}
\newcommand{\cJ}{\mathcal{J}}
\newcommand{\cK}{\mathcal{K}}
\newcommand{\cL}{\mathcal{L}}
\newcommand{\cM}{\mathcal{M}}
\newcommand{\cN}{\mathcal{N}}
\newcommand{\cO}{\mathcal{O}}
\newcommand{\cP}{\mathcal{P}}
\newcommand{\cQ}{\mathcal{Q}}
\newcommand{\cR}{\mathcal{R}}
\newcommand{\cS}{\mathcal{S}}
\newcommand{\cT}{\mathcal{T}}
\newcommand{\cU}{\mathcal{U}}
\newcommand{\cV}{\mathcal{V}}
\newcommand{\cW}{\mathcal{W}}
\newcommand{\cX}{\mathcal{X}}
\newcommand{\cY}{\mathcal{Y}}
\newcommand{\cZ}{\mathcal{Z}}


% Formatting shortcuts
\newcommand{\red}[1]{\textcolor{red}{#1}}
\newcommand{\blue}[1]{\textcolor{blue}{#1}}
\newcommand{\htext}[2]{\texorpdfstring{#1}{#2}}

% Statistics
\newcommand{\distr}{\sim}
\newcommand{\stddev}{\sigma}
\newcommand{\covmatrix}{\Sigma}
\newcommand{\mean}{\mu}
\newcommand{\param}{\theta}
\newcommand{\gthEst}{\hat{\theta}}
\newcommand{\ftr}{\phi}
\newcommand{\est}[1]{\hat{#1}}

% General utility
\newcommand{\todo}[1]{\textbf{[TODO]}] \footnote{TODO: #1}}
\newcommand{\tbc}{[\textbf{Incomplete}]}
\newcommand{\chk}{[\textbf{Check}]}
\newcommand{\why}{[\textbf{Find proof}]}
\newcommand{\opt}[1]{\textit{#1}}

\newcommand{\experience}[1]{[\textbf{Personal Experience}]: #1 \blacktriangle}
\newcommand{\pf}[1]{[\textbf{Proof}]: #1 \Box}
\newcommand{\core}[1]{\textbf{Core Idea}: #1 \Arrowvert}
\newcommand{\example}[1]{\textbf{Example}: #1 \blacktriangle}
\newcommand{\error}[1]{\textbf{Error alert}: #1 \triangle}
\newcommand{\oprob}{[\textbf{OP}]: }


\renewcommand{\~}{\htext{$\sim$}{~}}

\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}


\)



    
<header class="p-1 bg-yellow noPrint">
    <nav role="navigation" class="col">
      <div id="div_top_bar" class="row">
        <div class="col-md-3 justify-content-start">
          <a  href="/" class="btn col border">
            <i class="fas fa-gopuram ">Vishvas&#39;s notes <br/> Parametric density estimation</i>
          </a>
        </div>
        <div id="div_top_bar_right" class="col-md-auto d-flex justify-content-center">
          <button class="btn btn-light"  href="#transliterationDropdown" data-toggle="collapse">
            ‚úç
          </button>
          <select id="transliterationDropdown" size="1" class="collapse" onchange="module_uiLib.default.content.updateTransliteration()">
            <optgroup label="üåç">
              <option value="iso">ƒÅISO</option>
              <option value="iso_vedic">ƒÅi-ƒÅu</option>
              <option value="cyrillic">–ø—É</option>
              <option value="urdu">ŸÜÿ≥</option>
              <option value="??">üåç??</option>
            </optgroup>
            <optgroup label="üõïüß≠S">
              <option value="kannada">‡≤Ö</option>
              <option value="malayalam">‡¥Ö</option>
              <option value="telugu">‡∞ï</option>
              <option value="tamil_superscripted">‡Æï¬≤</option>
              <option value="tamil_extended">‡Æï</option>
              <option value="grantha">ëåÖ</option>
            </optgroup>
            <optgroup label="üõïüß≠N">
              <option value="devanagari" selected="">‡§∏</option>
              <option value="gujarati">‡™Ö</option>
              <option value="gurmukhi">‡®Ö</option>
            </optgroup>
            <optgroup label="üõïüß≠E">
              <option value="oriya">‡¨Ö</option>
              <option value="assamese">‡¶Ö‡¶∏</option>
              <option value="bengali">‡¶Ö</option>
            </optgroup>
            <optgroup label="üõïüè∫üìú">
              <option value="sharada">ëÜëëáÄëÜ∞</option>
              <option value="brahmi">ëÄÖ</option>
            </optgroup>
            <optgroup label="üõïüåã">
              <option value="balinese">·¨©·¨Æ·¨∂</option>
            </optgroup>
          </select>
          <div>
          <button class="btn btn-outline-secondary btn-sm"  href="#transliterationDropdownAlt" data-toggle="collapse">
          (‚úç)
          </button>
          <select id="transliterationDropdownAlt" size="1"  style="font-size:12px" class="bg-light-yellow collapse" onchange="module_uiLib.default.content.updateTransliteration()">
            <optgroup label="üåç">
              <option value="iso">ƒÅISO</option>
              <option value="iso_vedic">ƒÅi-ƒÅu</option>
              <option value="cyrillic">–ø—É</option>
              <option value="urdu">ŸÜÿ≥</option>
              <option value="??">üåç??</option>
            </optgroup>
            <optgroup label="üõïüß≠S">
              <option value="kannada">‡≤Ö</option>
              <option value="malayalam">‡¥Ö</option>
              <option value="telugu">‡∞ï</option>
              <option value="tamil_superscripted">‡Æï¬≤</option>
              <option value="tamil_extended">‡Æï</option>
              <option value="grantha">ëåÖ</option>
            </optgroup>
            <optgroup label="üõïüß≠N">
              <option value="devanagari" selected="">‡§∏</option>
              <option value="gujarati">‡™Ö</option>
              <option value="gurmukhi">‡®Ö</option>
            </optgroup>
            <optgroup label="üõïüß≠E">
              <option value="oriya">‡¨Ö</option>
              <option value="assamese">‡¶Ö‡¶∏</option>
              <option value="bengali">‡¶Ö</option>
            </optgroup>
            <optgroup label="üõïüè∫üìú">
              <option value="sharada">ëÜëëáÄëÜ∞</option>
              <option value="brahmi">ëÄÖ</option>
            </optgroup>
            <optgroup label="üõïüåã">
              <option value="balinese">·¨©·¨Æ·¨∂</option>
            </optgroup>
          </select>
          </div>
          <div class="row col d-flex  dropdown">
            <button class="btn btn-secondary-outline btn-sm dropdown-toggle" type="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
              A¬±
            </button>
            <div class="dropdown-menu" aria-labelledby="dropdownMenuButton">
            <a class="btn btn-secondary btn-sm" onclick="module_uiLib.changeTextSize(2)">A+</a>
            <a class="btn btn-secondary btn-sm" onclick="module_uiLib.changeTextSize(-2)">A-</a>
            </div>
          </div>
          <button class="btn btn-light btn-sm"  href="#commentStyleDropdown" data-toggle="collapse">
            üó®
          </button>
          <select id="commentStyleDropdown" class="collapse" size="1" onchange="module_uiLib.default.content.updateCommentStyleFromDropdown()">
            <option value="on">‚úî</option>
            <option value="hidden">‚úó</option>
          </select>
          <div><a id="expandAllButton" class="btn btn-secondary" onclick="module_uiLib.default.query.setParamsAndGo({'expandDetails': '.*'})">‚ÜïÔ∏èÔ∏è</a></div>
          <div id="printStyleDiv" class="row col d-flex  dropdown">
          <button class="btn btn-light btn-sm dropdown-toggle"  href="#printStyleDropdown" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
          üñ®
          </button>
            <div class="dropdown-menu col" aria-labelledby="printStyleDropdown">
              <div class="row justify-content-center">
                <p>Cols:</p>
                <input type="number" min="1" max="10" value="2" step="1" id="tbColumns" style="width: 3ch;"  accesskey="c"/>
              </div>
              <div class="row justify-content-center">
                <p>A¬±:</p> <input type="text" id="tbBodyFontSize" value="0.4cm" style="width: 6ch;"  accesskey="f"></input>
              </div>
              <div class="row justify-content-center">
                <p>Incl:</p> <input checked type="checkbox" id="tbIncludeStyle" value="on"></input>
                <button id="btnPrintStyle" onclick="module_uiLib.default.content.updatePrintStyle()">üñ®
                </button>
              </div>
            </div>
        </div>
        </div>
        <div id="audioDiv" class="row col d-flex  dropdown">
          <button class="btn btn-secondary-outline btn-sm dropdown-toggle" type="button" id="audioDropdownMenuButton" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
            üéß
          </button>
          <div class="dropdown-menu" aria-labelledby="dropdownMenuButton">
          <a id="speakerButton" class="btn btn-outline-secondary btn-sm" onclick="module_uiLib.default.content.handleSpeakToggle()">‚èØ</a>
          <button id="speakerPauseButton" class="btn btn-outline-secondary btn-sm">‚è∏</button>
            <div id="audioOptionsDiv" class="row justify-content-center" >
              <div>
                <p class="lead">Vol</p>
                <input type="range" min="0" max="1" value="1" step="0.1" id="volume" />
                <span id="volume-label" class="ms-2">1</span>
              </div>
              <div class="mx-5">
                <p class="lead">Rate</p>
                <input type="range" min="0.1" max="10" value="1" id="rate" step="0.1" />
                <span id="rate-label" class="ms-2">1</span>
              </div>
              <div>
                <p class="lead">Pitch</p>
                <input type="range" min="0" max="2" value="1" step="0.1" id="pitch" />
                <span id="pitch-label" class="ms-2">1</span>
              </div>
            </div>
          </div>
        </div>
        <a href="https://vishvAsa.github.io/notes/search"  class="btn btn-light btn-sm">ü•Ωüî¶</a>
        <div class="row col  d-flex justify-content-center">
          <div><a id="previousPage" href="" class="btn btn-secondary">###<i class="fas fa-caret-left"></i></a></div>
          <div ><a id="nextPage" href="" class="btn btn-secondary"><i class="fas fa-caret-right"></i> ### </a></div>
        </div>
        <ul id="top-bar-right-custom" class="list-group list-group-horizontal">
        </ul>
      </div>
    </nav>
</header>

    
    <div class="row" name="contentRow">
      
      <aside class="col-md-3 card border noPrint " id="sidebar">
          <div id="fastSearch">
              <datalist id="pageDataList"></datalist>
              <input id="searchInput" placeholder="‡§∂‡•Ä‡§∞‡•ç‡§∑‡§ø‡§ï‡§æ‡§®‡•ç‡§µ‡§ø‡§∑‡•ç‡§Ø‡§§‡§æ‡§Æ‡•ç" list="pageDataList" onchange="module_uiLib.default.navigation.pageLoader()">
          </div>
          <details open  class="bg-light-gray" >
              <summary id="sidebarToggleLink" onclick="module_uiLib.default.navigation.sidebarToggleHandler()">
            Menu
              </summary>
              <ul id="sidebarBody" class="list pl2 p-0 bg-yellow">
              </ul>
          </details>
      </aside>
      <main class="col p-3" role="main" data-pagefind-body>
        
<header class='border d-flex justify-content-between'>
    <h1 id="Parametric density estimation">Parametric density estimation</h1>
    
    <a id="editLink" class="btn btn-primary noPrint"  href="https://github.com/vishvAsa/notes/edit/content/math/probability/statistics/distribution_structure_learning/parametric_density_estimation.md"><i class="fas fa-edit"></i></a>
    
</header>
<article>
  <aside id="toc_card" class="card border noPrint ">
    <details id="toc_header">
        <summary>What's in this page?</summary>
      <div id="toc_body" class="p-0">
        
        <ul id="toc_ul" class="list p-0">
        </ul>
      </div>
    </details>
    <div id="progressBarDiv" class="row d-flex justify-content-center">
      üêéüí™<progress id="progressLoading" value="0" max="100"> 32% </progress>
    </div>
  </aside>
  <div id="post_content">
  <h2 id="problem-and-solution-ideals">Problem and solution ideals</h2>
<h3 id="density-estimation-using-a-distribution-class">Density estimation using a distribution class</h3>
<p>Suppose that parameter \(t\) specifies the distribution \(f_t(x_r|x_{\lnot r})\), where \(x_{\lnot r}\) can be empty! Let \(T\) be parameter space spanned by such \(t\); it represents the class of distributions which can be specified in this form.</p>
<p>Given finite data set \(\set{x^{(i)}}\), we want to approximate an unknown target distribution \(D(x_r|x_{\lnot r})\) which may not belong to this distribution family using \(T\). The approximation can be a weighted combination of combination of distributions in \(T\).</p>
<h4 id="related-problems">Related problems</h4>
<p>Note that estimating \(t\) which is good at predicting the value of \(x_r\) given \(x_{\lnot r}\) by doing \(h(x_{\lnot r}) = \max_{x_r} f_t(x_r|x_{\lnot r})\) is a separate problem, where a different estimation procedure which minimizes the classification error \(Pr(h(x_{\lnot r}) \neq x_r)\) (corresponding to the 0/1 classification loss) may be used.</p>
<h3 id="solution-ideas">Solution ideas</h3>
<p>Empirical risk minimization, for various forumulations of risk functions which in someway also incorporate prior belief about the best \(t\).</p>
<h2 id="approximation-with-normal-distribution">Approximation with Normal distribution</h2>
<p>Aka Laplace approximation. Suppose that we have the probability distribution \(p(x) = Z^{-1}f(x)\).</p>
<h3 id="algorithm">Algorithm</h3>
<p>Here, one finds a mode / strict local maximum \(x&rsquo;\) of the distribution \(p(x)\), which corresponds to a mode of \(f(x)\), using numerical techniques. Then, one creates a normal distribution \(N(\mean = x&rsquo;, \stddev)\) around this point.</p>
<h4 id="2nd-order-approximation-of-log-f">2nd order approximation of log f</h4>
<p>\(\log N(x&rsquo;, \covmatrix)\) is a quadratic function. So, we try to find \(\covmatrix\) such that \(\log N\) approximates the 2nd order approximation of \(\log f\).</p>
<p>As \(\gradient f(x&rsquo;)= 0\), taking the quadratic approximation \(\log f(x) \approx \log f(x&rsquo;) + (f(x&rsquo;))^{-2} (x-x&rsquo;)^{T}\gradient^{2} f(x&rsquo;)(x - x&rsquo;)\). So, \(f(x) \approx f(x&rsquo;)exp((f(x&rsquo;))^{-2} (x-x&rsquo;)^{T}\gradient^{2} f(x&rsquo;)(x - x&rsquo;))\)</p>
<p>The RHS can now be used to construct \(\covmatrix\). As \(x&rsquo;\) is a mode, \(-2(f(x&rsquo;))^{-2}\gradient^{2} f(x&rsquo;) \succ 0\) as expected.</p>
<h3 id="properties">Properties</h3>
<h4 id="estimating-z">Estimating Z</h4>
<p>Z can be approximated to equal the normailizer of N, which is easily calculated. Note that knowledge of Z is not required to get the approximation \(N\).</p>
<h4 id="non-uniqueness">Non-uniqueness</h4>
<p>Different modes yield different approximate distributions.</p>
<h2 id="log-loss-minimization">Log loss minimization</h2>
<p>Aka Maximum likelihood estimation (MLE).</p>
<h3 id="optimization-problem-estimate">Optimization problem, estimate</h3>
<p>Likelihood function: \(L:T \to [0,1]\). \
\(L(t|\set{x^{(i)}}) = f_t(\set{x_r^{(i)}}|\set{x_{\lnot r}^{(i)}}) = \prod f_t(x^{(i)}|x_{\lnot r}^{(i)})\).</p>
<p>\(\hat{t} = argmax_{t} L(t|x)\). This may be a biased estimator; but is always a sufficient statistic, as it is defined on \(L(t|x)\). Often, an equivalent optimization problem: minimizing log-likelihood is used.</p>
<h4 id="functional-invariance-property">Functional Invariance property</h4>
<p>If you want to estimate \(g(t)\), \(g(\hat{t})\) is the MLE of g(t). From definition.</p>
<h4 id="avg-log-likelihood-function">Avg Log likelihood function</h4>
<p>Take \(l(t|\set{x^{(i)}}) = \ln(L(t|\set{x^{(i)}}))\), and do \(\min_t -n^{-1}l(t|X)\). Useful as often \(L\) and distribution of X are from exponential family.</p>
<p>Example: In case of \(N(\mean, \stddev^{2})\), \(\ln f(\set{x^{(i)}}|\mean, \stddev^{2}) = -\frac{1}{2\stddev^{2}}\sum(x^{(i)} - \mean)^{2} - \frac{N}{2}\ln (\frac{\stddev^{2}}{2 \pi})\); by maximization, MLE is \(\mean = \bar{x}, \stddev^{2}= N^{-1}(x^{(i)} - \mean)^{2}\): because biased estimator is used, \(N^{-1}(x^{(i)} - \mean)^{2}\) often underestimates.</p>
<h3 id="other-perspectives">Other perspectives</h3>
<h4 id="as-log-loss-risk-minimization">As log loss risk minimization</h4>
<p>The negative log-likelihood of a single sample-point, \(-\log L(t|x)\), is also called the &rsquo;log loss&rsquo; in the general decision theoretic framework. So, by doing maximum likelihood estimation, we are actually minimizing empirical log-loss.</p>
<h4 id="priors-as-regularizers">Priors as regularizers</h4>
<p>If you add regularizer \(r(t)\), you are imposing a prior distribution on \(t\); so you are doing bayesian inference. The optimization problem becomes: \(\min l(t|X) + r(t)\).</p>
<h4 id="as-empirical-code-length-divergence-minimization">As empirical code-length divergence minimization</h4>
<p>Let \cF be a class of distributions, \
let \(D\) be the actual distribution of \(X\). In the limit where \(n \to \infty\), maximum likelihood estimation tries to find \(\argmin_{F \in \cF} E_D[- \log F(X)]\). This is the same problem as finding \(\argmin_{F \in \cF} E_D[- \log F(X)] - E_D[-\log D(x)] = \argmin_{F \in \cF} KL(F||D)\). So we are finding a member of \cF, with minimum code-length divergence to \(D\).</p>
<h3 id="derivatives-of-log-likelihood">Derivatives of log likelihood</h3>
<h4 id="score-function--sensitivity-of-log-likelihood">Score function : Sensitivity of log Likelihood</h4>
<p>\(V(t, X) = \gradient_t{\log L(t|X)} =  L(t|X)^{-1} \gradient_t L(t|X)\): variability of \(L(t|X)\) normalized by \(L(t|X)\): like conditioning in numerical analysis.</p>
<h5 id="mean-wrt-x">Mean wrt X</h5>
<p>Under some regularity conditions, \</p>
<p>$$E_X[V(t, X)] = \int_x (f_{X|T}(x|t)^{-1} \gradient_t f_{X|T}(x|t)) f_{X|T}(x|t))dx =\
\gradient_t \int_x f_{X|T}(x|t)) dx = \gradient_t 1 = 0$$.</p>
<h4 id="variance-wrt-x-of-sensitivity-score-of-likelihood">Variance wrt X of sensitivity score of likelihood</h4>
<p>Aka Fisher Information matrix. As \(E_X[V(t, X)] = 0\), \(I(t) = E_X[V(t, X)^{2}] = E_X[(\gradient_t{\log L(t|X)})^{2} | t]\). Measures information about t in the observable RV X. If I(t) is high for RV X, then the absolute value of the sensitivity score is high in expectation.</p>
<p>If conditions like those in \(E_X[V(t, X)] = 0\) hold,\ \(E_X[(f_{X|T}(x|t))^{-1} \gradient_t^{2} f_{X|T}(x|t)] = 0\) will hold, and so \(I(t) = -E_X[(\gradient_t^{2}{\log L(t|X)})^{2} | t]\).</p>
<h3 id="computational-cost">Computational cost</h3>
<p>If this optimization problem can be accurately and efficiently: great!</p>
<h4 id="computing-partition-function">Computing partition function</h4>
<p>Suppose only \(f(x, t)\) proportional to th epdf \(f_t(x_r|x_{\lnot r})\) is specified. Doing \
\(\max_r \frac{f(x, t)}{\sum_y f(y, t)}\) is not the same as doing \(\max_r f(x, t)\), as the normalizer (aka partition function) \(Z(t) = \sum_y f(y, t)\), even though independent of \(x\),  varies with \(t\).</p>
<p>If range of \(x\) is huge, and Z(t) does not have a closed-form solution, computing \(Z(t) = \sum_y f(y, t)\) can become costly and MLE is impractical.</p>
<h5 id="ease-in-case-of-conditional-probabilities">Ease in case of conditional probabilities</h5>
<p>Suppose that \(range(X_t)\) is actually small. Here, rather than having to sum over the entire range of \(X\),  which may be \(range(x_r)^{|V|}\) in size, we just sum over \(range(x_r)\) values to get \(Z(t) = \sum_y f(y, t)\).</p>
<h4 id="pseudolikelihood-maximization">Pseudolikelihood maximization</h4>
<p>In case finding/ maximizing \(f_t(x_r|x_{\lnot r})\) is hard due to the need to compute \(Z(t)\), but finding \(f_{X_{r_j}|X_{\lnot r_j}}\) is easy. So we can consider maximizing the pseudo-likelihood function \(\prod_{r_j} f_{X_{r_j}|X_{\lnot r_j}}\) instead.</p>
<h2 id="non-uniform-model-for-pt">Non uniform model for P(t)</h2>
<p>Aka Maximum a posteriori (MAP).</p>
<h3 id="objective-estimate">Objective, estimate</h3>
<p>Posterior probability of model considering observations \(\propto\) likelihood of observations given the model \(\times\) prior probability of model.</p>
<p>So, solve : \(argmax_{t} f_{X|T}(x|t)f_T(t)\), or \(argmax_{t} f_X(x)\) + regularizer.</p>
<h3 id="relation-to-mle">Relation to MLE</h3>
<p>MLE is a special case: it ignores prior distribution/ assumes it are uniform. So, often superior MLE. Eg: In MLE, upon seeing 4 H in coin tosses, you would conclude that the coin will always come up H.</p>
<p>The MLE optimization objective with a regularizer is a case of MAP, where the regularizer implitly defines a prior.</p>
<h3 id="defining-prior-distributions">Defining prior distributions</h3>
<p>Often, the prior distribution on \(T\) may be specified, and the regularizer associated with the risk function may be derived thence.</p>
<h4 id="hyperparameters-for-prior-distribution-of-parameters">Hyperparameters for prior distribution of parameters</h4>
<p>\(f_{T|C}\) may have hyperparameters C, which may inturn come from distribution \(f_{C|D}\) with hyperparameters \(D\). Eventually must fix (hyper)parameter, perhaps with n-fold cross validation.</p>
<p>Eg: Can have hyper-parameters: \(\stddev\) for label noise , \(\ga\) for prior over \(\param\).</p>
<p>These are akin to parameters, but of a special kind.</p>
<h4 id="conjugate-prior-for-a-likelihood">Conjugate prior for a likelihood</h4>
<p>You got distribution family \(f_{X|T=t}\). Conjugacy: If \(f_{X|T=t}\) and \(f_T(t)\)\
have the same form, finding \(Pr(t|X) = f_{(X_{i})|t}((x_i))f_T(t) =  \prod_{i} f_{X|T=t}(x_i)f_T(t)\) simpler. Then can update these probabilities with each incoming observation \(X_{i}\) easily.</p>
<p>Eg: For k-categorical distribution: \(Pr(X_{j}=x|p) = \prod_{i=1}^{k} p_{i}^{x_{i}}\), dirichlet distribution is the conjugate: \(f_{P|A=a}(p) = \prod p_{i}^{a_{i}-1}\) for hyperparameters a.</p>
<h2 id="model-combination">Model combination</h2>
<p>Aka Fully Bayesian approach. We may first determine posterior distribution over parameters \(f_{T|S}\) in the training stage, where \(S\) is the training set. We may then arrive at the model \(f_{L|X, S} = \int_{t \in T} f_{L|X, T=t}f_{T|S}(t)\).</p>
<p>So you use an ensemble of hypothesis distribution models.</p>
<h2 id="information-criteria">Information criteria</h2>
<p>Bayesian/ Schwartz information criterion (BIC): \(\min 2^{-1}L(D, t) + p \log n\), where \(p\) is the number of parameters needed to specify \(t\), and \(n\) is the number of samples.</p>
<h3 id="use">Use</h3>
<p>These are good if certain &lsquo;Gaussianness&rsquo; assumptions hold, otherwise, the result of using them can be misleading. They allow us to pick \(t\) without having to, for example, do cross-validation, which would have been necessary if \(\min L(D, t) + l r(t)\) were used instead.</p>

  </div>
</article>


        

        



    <aside class="card border noPrint" id="section-tree-item-math_probability_statistics_distribution_structure_learning_parametric_density_estimation_md">
        <div class="card-title bg-light-gray border d-flex justify-content-between">
            <a href="https://vishvAsa.github.io/notes/math/probability/statistics/distribution_structure_learning/parametric_density_estimation/">Parametric density estimation </a>
            <a data-toggle="collapse" href="#section-tree-item-body-math_probability_statistics_distribution_structure_learning_parametric_density_estimation_md" role="button" aria-expanded="false" aria-controls="section-tree-item-body-math_probability_statistics_distribution_structure_learning_parametric_density_estimation_md" >‚Ä¶<i class="fas fa-caret-down" class="collapsed"></i> </a>
        </div>
        <nav id="section-tree-item-body-math_probability_statistics_distribution_structure_learning_parametric_density_estimation_md" class="card-body p-0 collapse">
            
            <li>draft: false</li>
            
            <li>iscjklanguage: false</li>
            
            <li>title: Parametric density estimation</li>
            
        </nav>
    </aside>


      </main>
    </div>
    <footer class="bg-yellow  p-1 noPrint" role="contentinfo">
  

  <div id="div_foot_nav_bar" class="row">
    <a href="https://vishvAsa.github.io/notes/search"  class="btn btn-light btn-sm">ü•Ωüî¶</a>
    <div class="row col  d-flex justify-content-center">
      <div><a id="previousPageFoot" href="" class="btn btn-secondary">###<i class="fas fa-caret-left"></i></a></div>
      <div ><a id="nextPageFoot" href="" class="btn btn-secondary"><i class="fas fa-caret-right"></i> ### </a></div>
    </div>
      <ul id="footer-bar-right-custom" class="list-group list-group-horizontal">
      </ul>
  </div>
  <div id="div_footer_bar" class="container-fluid d-flex justify-content-between">
    <a class="btn btn-secondary" href="https://github.com/vishvAsa/notes/issues/new" >
      ‚úâÔ∏èContact
    </a>
    <a class="btn btn-secondary" href="http://creativecommons.org/licenses/by/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by/4.0/80x15.png" /></a>
    <div class="btn small border">
      
      <a href="https://github.com/vishvAsa/notes/actions/workflows/build.yml"><img src="https://github.com/vishvAsa/notes/actions/workflows/build.yml/badge.svg"> Built </a> on 2026 Feb 12 01:34:45 UTC. (<a href="http://google.com/search?q=01%3a34%3a45%20UTC to IST">IST</a>)
    </div>
  </div>
</footer>



<script async src="https://www.googletagmanager.com/gtag/js?id=G-33H08JSLQR"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-33H08JSLQR');
</script>

  </body>
  <script type='text/javascript'>
    
    
    
    module_uiLib.onDocumentReadyTasks();
  </script>
  
</html>
