<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>Vishvas&#39;s notes  | 05 Partially observed states</title>
    <meta name="HandheldFriendly" content="True">
    <meta name="MobileOptimized" content="320">

    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="generator" content="Hugo 0.72.0" />
    
    
      <META NAME="ROBOTS" CONTENT="INDEX, FOLLOW">
    

    <link href="/storage/emulated/0/notesData/notes/math/probability/probabilistic_models/RV_interdependence/05_Modeling_stochastic_processes/05_Partially_observed_states/" rel="alternate" type="application/rss+xml" title="Vishvas&#39;s notes" />
    <link href="/storage/emulated/0/notesData/notes/math/probability/probabilistic_models/RV_interdependence/05_Modeling_stochastic_processes/05_Partially_observed_states/" rel="feed" type="application/rss+xml" title="Vishvas&#39;s notes" />

    <meta property="og:title" content="05 Partially observed states" />
<meta property="og:description" content="Observations, states \((X_i)\) are called features/ covariates/ predictor/ input/ observed variables. \(\seq{L_i}\) is the unobserved response/ state variable sequence. \(X_i\), being a partially dependent of \(L_i\), can be viewed as a partial observation of the state \(L_i\).
The state space is \(ran(L_i)\), while the observation space is \(ran(X_i)\).
Use These models are not only used for deriving models for \(f_X\), but also for determining the state sequence \(L\) given \(X\)." />
<meta property="og:type" content="article" />
<meta property="og:url" content="file:///storage/emulated/0/notesData/notes/math/probability/probabilistic_models/RV_interdependence/05_Modeling_stochastic_processes/05_Partially_observed_states/" />

<meta itemprop="name" content="05 Partially observed states">
<meta itemprop="description" content="Observations, states \((X_i)\) are called features/ covariates/ predictor/ input/ observed variables. \(\seq{L_i}\) is the unobserved response/ state variable sequence. \(X_i\), being a partially dependent of \(L_i\), can be viewed as a partial observation of the state \(L_i\).
The state space is \(ran(L_i)\), while the observation space is \(ran(X_i)\).
Use These models are not only used for deriving models for \(f_X\), but also for determining the state sequence \(L\) given \(X\).">

<meta itemprop="wordCount" content="1047">



<meta itemprop="keywords" content="" /><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="05 Partially observed states"/>
<meta name="twitter:description" content="Observations, states \((X_i)\) are called features/ covariates/ predictor/ input/ observed variables. \(\seq{L_i}\) is the unobserved response/ state variable sequence. \(X_i\), being a partially dependent of \(L_i\), can be viewed as a partial observation of the state \(L_i\).
The state space is \(ran(L_i)\), while the observation space is \(ran(X_i)\).
Use These models are not only used for deriving models for \(f_X\), but also for determining the state sequence \(L\) given \(X\)."/>

      
    

    <script src="/storage/emulated/0/notesData/notes/webpack_dist/dir_tree-bundle.js"></script>
    <script type="text/javascript">
    
    let baseURL = "file:\/\/\/storage\/emulated\/0\/notesData\/notes";
    let basePath = "/" + baseURL.split("/").slice(3).join("/");
    let siteParams = JSON.parse("{\u0022contactlink\u0022:\u0022https:\/\/github.com\/vvasuki\/notes\/issues\/new\u0022,\u0022disqusshortcode\u0022:\u0022vvasuki-site\u0022,\u0022env\u0022:\u0022production\u0022,\u0022githubeditmepathbase\u0022:\u0022https:\/\/github.com\/vvasuki\/notes\/edit\/master\/content\/\u0022,\u0022mainSections\u0022:[\u0022math\u0022],\u0022mainsections\u0022:[\u0022math\u0022]}");
    let pageDefaultsList = JSON.parse("[{\u0022scope\u0022:{\u0022pathPrefix\u0022:\u0022\u0022},\u0022values\u0022:{\u0022comments\u0022:true,\u0022layout\u0022:\u0022page\u0022,\u0022search\u0022:true,\u0022sidebar\u0022:\u0022home_sidebar\u0022}}]");
    let sidebarsData = JSON.parse("{\u0022home_sidebar\u0022:{\u0022contents\u0022:[{\u0022url\u0022:\u0022recdir:\/\/\u0022},{\u0022contents\u0022:[{\u0022title\u0022:\u0022‡§ú‡•ç‡§Ø‡•å‡§§‡§ø‡§∑‡§Æ‡•ç\u0022,\u0022url\u0022:\u0022..\/jyotiSham\/\u0022},{\u0022title\u0022:\u0022‡§∏‡§Ç‡§∏‡•ç‡§ï‡•É‡§§‡§Æ‡•ç\u0022,\u0022url\u0022:\u0022..\/sanskrit\/\u0022},{\u0022title\u0022:\u0022‡§Æ‡•Ä‡§Æ‡§æ‡§Ç‡§∏‡§æ\u0022,\u0022url\u0022:\u0022..\/mImAMsA\/\u0022},{\u0022title\u0022:\u0022Notes Home\u0022,\u0022url\u0022:\u0022..\/notes\/\u0022},{\u0022title\u0022:\u0022‡§ï‡§æ‡§µ‡•ç‡§Ø‡§Æ‡•ç\u0022,\u0022url\u0022:\u0022..\/kAvya\/\u0022},{\u0022title\u0022:\u0022‡§∏‡§Ç‡§∏‡•ç‡§ï‡§æ‡§∞‡§æ‡§É\u0022,\u0022url\u0022:\u0022\/..\/saMskAra\/\u0022},{\u0022title\u0022:\u0022Vishvas\u0027s home page\u0022,\u0022url\u0022:\u0022\/..\/\u0022}],\u0022title\u0022:\u0022‡§∏‡§ô‡•ç‡§ó‡•ç‡§∞‡§π‡§æ‡§®‡•ç‡§§‡§∞‡§Æ‡•ç\u0022},{\u0022title\u0022:\u0022\\u003ci class=\\\u0022fas fa-hand-holding-heart\\\u0022\\u003e\\u003c\/i\\u003eDonate Via Vishvas\u0022,\u0022url\u0022:\u0022https:\/\/vvasuki.github.io\/interests\/dharma-via-vishvas\/\u0022}],\u0022title\u0022:\u0022Parts\u0022}}");
    let autocompletePageUrl = "\/storage\/emulated\/0\/notesData\/notes\/data\/pages.tsv";
    
    var pageRelUrlTree = {};
</script>

    <script>
    
    let pageVars = {};
    pageVars.pageUrlMinusBasePath = "\/storage\/emulated\/0\/notesData\/notes\/math\/probability\/probabilistic_models\/RV_interdependence\/05_Modeling_stochastic_processes\/05_Partially_observed_states\/".replace(basePath, "/");
    pageVars.pageParams = {};
    pageVars.pageSource = "math\/probability\/probabilistic_models\/RV_interdependence\/05_Modeling_stochastic_processes\/05_Partially_observed_states.md";
    console.log(pageVars.pageSource);
    var pageDefaults;
    for (let possiblePageDefaults of pageDefaultsList) {
      if (pageVars.pageSource.startsWith(possiblePageDefaults.scope.pathPrefix)) {
        pageDefaults = possiblePageDefaults.values
      }
    }
    
    </script>
    <script src="/storage/emulated/0/notesData/notes/webpack_dist/main-bundle.js"></script>
    <script src="/storage/emulated/0/notesData/notes/webpack_dist/transliteration-bundle.js"></script>
    <script src="/storage/emulated/0/notesData/notes/non_webpack_js/disqus.js"></script>
    <script src="/storage/emulated/0/notesData/notes/webpack_dist/ui_lib-bundle.js"></script>
    <link rel="stylesheet" href="/storage/emulated/0/notesData/notes/css/fonts.css">
    <link rel="stylesheet" href="/storage/emulated/0/notesData/notes/css/@fortawesome/fontawesome-free/css/solid.min.css">
    

    <link rel="stylesheet" href="/storage/emulated/0/notesData/notes/css/@fortawesome/fontawesome-free/css/fontawesome.min.css">

    
    <link rel="alternate" hreflang="sa-Deva" href="#ZgotmplZ" />
    <link rel="alternate" hreflang="sa-Deva" href="#ZgotmplZ?transliteration_target=devanagari" />
    <link rel="alternate" hreflang="sa-Knda" href="#ZgotmplZ?transliteration_target=kannada" />
    <link rel="alternate" hreflang="sa-Mlym" href="#ZgotmplZ?transliteration_target=malayalam" />
    <link rel="alternate" hreflang="sa-Telu" href="#ZgotmplZ?transliteration_target=telugu" />
    <link rel="alternate" hreflang="sa-Taml-t-sa-Taml-m0-superscript" href="#ZgotmplZ?transliteration_target=tamil_superscripted" />
    <link rel="alternate" hreflang="sa-Taml" href="#ZgotmplZ?transliteration_target=tamil" />
    <link rel="alternate" hreflang="sa-Gran" href="#ZgotmplZ?transliteration_target=grantha" />
    <link rel="alternate" hreflang="sa-Gujr" href="#ZgotmplZ?transliteration_target=gujarati" />
    <link rel="alternate" hreflang="sa-Orya" href="#ZgotmplZ?transliteration_target=oriya" />
    <link rel="alternate" hreflang="sa-Beng-t-sa-Beng-m0-assamese" href="#ZgotmplZ?transliteration_target=assamese" />
    <link rel="alternate" hreflang="sa-Beng" href="#ZgotmplZ?transliteration_target=bengali" />
    <link rel="alternate" hreflang="sa-Guru" href="#ZgotmplZ?transliteration_target=gurmukhi" />
    <link rel="alternate" hreflang="sa-Cyrl" href="#ZgotmplZ?transliteration_target=cyrillic" />
    <link rel="alternate" hreflang="sa-Sinh" href="#ZgotmplZ?transliteration_target=sinhala" />
    <link rel="alternate" hreflang="sa-Shar" href="#ZgotmplZ?transliteration_target=sharada" />
    <link rel="alternate" hreflang="sa-Brah" href="#ZgotmplZ?transliteration_target=brahmi" />
    <link rel="alternate" hreflang="sa-Modi" href="#ZgotmplZ?transliteration_target=modi" />
    <link rel="alternate" hreflang="sa-Tirh" href="#ZgotmplZ?transliteration_target=tirhuta_maithili" />
    <link rel="alternate" hreflang="sa-Latn-t-sa-Zyyy-m0-iast" href="#ZgotmplZ?transliteration_target=iast" />
  </head>

  <body class="ma0 bg-near-white">
    


    
<header class="p-1 bg-yellow">
    <nav role="navigation">
      <div id="div_top_bar" class="row">
        <div class="col-md-3 justify-content-start">
          <a  href="/storage/emulated/0/notesData/notes/" class="btn col border">
            <i class="fas fa-gopuram ">Vishvas&#39;s notes <br/> 05 Partially observed states</i>
          </a>
        </div>
        <div id="div_top_bar_right" class="col-md-auto d-flex justify-content-center">
          <form action="/storage/emulated/0/notesData/notes/search">
            <input id="titleSearchInputBox" placeholder="‡§∂‡•Ä‡§∞‡•ç‡§∑‡§ø‡§ï‡§æ‡§®‡•ç‡§µ‡§ø‡§∑‡•ç‡§Ø‡§§‡§æ‡§Æ‡•ç" name="s"><i class="btn fas fa-search "></i>
          </form>
          <a href="/storage/emulated/0/notesData/notes/custom_site_search/"  class="btn btn-default">Full search</a>
          <select name="transliterationDropdown" size="1" onchange="module_transliteration.updateTransliteration()">
            <option value="devanagari" selected="">‡§∏</option>
            <option value="iast">ƒÅ</option>
            <option value="kannada">‡≤Ö</option>
            <option value="malayalam">‡¥Ö</option>
            <option value="telugu">‡∞ï</option>
            <option value="tamil_superscripted">‡Æï¬≤</option>
            <option value="tamil_extended">‡Æï</option>
            <option value="grantha">ëåÖ</option>
            <option value="gujarati">‡™Ö</option>
            <option value="oriya">‡¨Ö</option>
            <option value="assamese">‡¶Ö‡¶∏</option>
            <option value="bengali">‡¶Ö</option>
            <option value="gurmukhi">‡®Ö</option>
            <option value="cyrillic">–ø—É</option>
            <option value="sinhala">‡∂Ö</option>
            <option value="sharada">ëÜëëáÄëÜ∞</option>
            <option value="brahmi">ëÄÖ</option>
            <option value="modi">ëò¶ëòªëòöëò≤</option>
            <option value="tirhuta_maithili">ëíÅ</option>
          </select>
        </div>
        <div class="row col  d-flex justify-content-center">
          <div><a  name="previousPage" href="" class="btn btn-secondary">###<i class="fas fa-caret-left"></i></a></div>
          <div ><a name="nextPage" href="" class="btn btn-secondary"><i class="fas fa-caret-right"></i> ### </a></div>
        </div>
        <ul id="top-bar-right-custom" class="list-group list-group-horizontal">
        </ul>
      </div>
    </nav>
</header>

    
    <div class="row" name="contentRow">
      
      <aside class="col-md-3 card border " id="sidebar">
        <div id="sidebarTitle" class="card-title bg-light-gray border d-flex justify-content-between" >
          <a name="sidebarToggleLink" data-toggle="collapse" href="#sidebar_body" role="button" aria-expanded="true" aria-controls="sidebar_body" onclick="module_main.default.sidebarToggleHandler()">
            Menu <i class="fas fa-caret-down"></i></a>
        </div>
        <nav class="card-body p-0 collapse show" id="sidebar_body">
          <ul id="displayed_sidebar" class="list pl2 p-2 bg-yellow">
        </ul>
        </nav>
      </aside>
      <main class="col p-3" role="main">
        
<header class='border d-flex justify-content-between'>
    <h1 id="05 Partially observed states">05 Partially observed states</h1>
    
    <a id="editLink" class="btn btn-primary"  href="https://github.com/vvasuki/notes/edit/master/content/math/probability/probabilistic_models/RV_interdependence/05_Modeling_stochastic_processes/05_Partially_observed_states.md"><i class="fas fa-edit"></i></a>
    
</header>
<article>
  <aside id="toc_card" class="card border ">
    <div id="toc_header" class="card-title border d-flex justify-content-between">
        <a data-toggle="collapse" href="#toc_body" role="button" aria-expanded="true" aria-controls="toc_body">
          What's in this page? <i class="fas fa-caret-down"></i> </a>
    </div>
    <div id="toc_body" class="card-body collapse p-0">
      
      <ul id="toc_ul" class="list p-0">
      </ul>
    </div>
  </aside>
  <div id="post_content">
  <h2 id="observations-states">Observations, states</h2>
<p>\((X_i)\) are called features/ covariates/ predictor/ input/ observed variables. \(\seq{L_i}\) is the unobserved response/ state variable sequence. \(X_i\), being a partially dependent of \(L_i\), can be viewed as a partial observation of the state \(L_i\).</p>
<p>The state space is \(ran(L_i)\), while the observation space is \(ran(X_i)\).</p>
<h3 id="use">Use</h3>
<p>These models are not only used for deriving models for \(f_X\), but also for determining the state sequence \(L\) given \(X\).</p>
<h3 id="applications">Applications</h3>
<p>Spelling corrector, where X stands for the observed typed word and L stands for unobserved dictionary word.</p>
<p>Predicting part of speech is a classic application of HMM&rsquo;s.</p>
<h2 id="model-classes">Model classes</h2>
<h3 id="generative-model-of-prx-l">Generative model of Pr(X, L)</h3>
<p>As in the case of general models of response variables, one may use these models to derive models for \(f_{L|X}\) if needed.</p>
<p>This class of models includes HMM&rsquo;s.</p>
<h3 id="model-l-given-x">Model L given X</h3>
<p>Aka Conditional random field (CRF). Here, one uses a discriminative model \(f_{L|X}\); so no effort is wasted in modeling \(f_X\). The most common CRF is just a chain among \(L_i\).</p>
<h4 id="ignoring-sequentiality">Ignoring sequentiality</h4>
<p>One can model \(f_{L|X}(l |x) = \prod_i f_{L'|X&rsquo;} (l_i|x_i)\). This model works surprisingly very well: Eg: In part of speech tagging, it yields around .95 correctness, while HMM may yield perhaps .02 more accuracy.</p>
<p>Note that this is not entirely same as Naive Bayes because \(ran(X_i)\) may be multidimensional, and the  model \(f_{L'|X&rsquo;}\) need not assume that these features are independent. So, any of the wide variety of classifiers may be used.</p>
<h2 id="partially-observed-state-chain">Partially observed state chain</h2>
<p>Aka Bigram Hidden Markov Model (HMM).</p>
<h3 id="graphical-model">Graphical model</h3>
<p>The graphical model of the observation and label sequences has the following structure for \(i = 2:N\) :</p>

<figure >
    
    
    
    <a href="../images/bigram_HMM.svg">
        <img src="../images/bigram_HMM.svg" alt="bigram HMM " />
    </a>
    <figcaption>
        bigram HMM
        
    </figcaption>
</figure>


<h3 id="representations">Representations</h3>
<p>Parameters of a bigram HMM are the state transition probabilities \(f_{L_t|L_{t-1}}\) and observation generation probabilities: \(f_{X_t|L_t}\). As in the case of fully observed state chains, the state transition probabilities can be represented using a transition matrix or as labels of edges in a state transition graph which could now be expanded to include vertices corresponding to various observations.</p>
<h3 id="decoding-filtering">Decoding/ filtering</h3>
<h4 id="problem">Problem</h4>
<p>We want to find the most likely state sequence \(X_1:X_N\).</p>
<h4 id="message-passing-algorithm">Message passing algorithm</h4>
<p>Viewing the state-chain as an equivalent undirected tree-structured graphical model, we can solve the problem using the divide and conquer max-product algorithm. When the messages passed during this computation are done in an order similar to that described in case of the forward-backward algorithm for finding marginal state distributions, we have the Viterbi algorithm.</p>
<h3 id="online-label-distribution-inference">Online label distribution inference</h3>
<h4 id="problem-1">Problem</h4>
<p>Unlike the decoding problem, one is not satisfied with finding the most likely state sequence, the task is to find \(f_{L_N|X_{1:N} = x_{1:N}}\) at time \(N\).</p>
<h4 id="forward-algorithm">Forward algorithm</h4>
<p>One can use a node elimination/ message passing \<br>
algorithm applied to find the marginal probability distribution in the equivalent undirected tree structured graphical model. The node elimination ordering is: \(1 .. N\). So, this is aka &lsquo;forward&rsquo; algorithm.</p>
<p>This algorithm can be described inductively. At step \(t\), suppose that one has determined \(f_{L_{t-1}, x_{1:t-1}}\), one simply does:</p>
<p>$$f_{L_t, x_{1:t}}(l_t) = \sum_{l_{t-1}} f_{L_{t-1}, x_{1:t-1}}(l_{t-1}) f_{L_{t}|L_{t-1}}(l_t|l_{t-1}) f_{X_t|L = l_t}(x_t)$$.</p>
<p>The base case is when \(t = 1\), and \(f_{L_1|x_1} = f_{X|L_1}(x_1)f_{L_1 = l}\) can be easily determined. So, by induction it follows that we are able to determine \(f_{L_N, X_{1:N} = x_{1:N}} \propto f_{L_N| X_{1:N} = x_{1:N}}\).</p>
<h4 id="analysis">Analysis</h4>
<p>This is an \(O(|T|^{2})\) operation at each time step, where \(T\) is the state space.</p>
<p>If there are \(N\) time steps, the algorithm yields the correct result for \(f_{L_N|x_{1:N}}\). But for \(k &lt; N\), \(f_{L_k|x_{1:k}} \neq f_{L_k|x}\). This can be remedied by using the forward backward algorithm described below.</p>
<h3 id="past-label-distribution-inference">Past Label Distribution inference</h3>
<h4 id="problem-2">Problem</h4>
<p>Aka Smoothing. One wants to find the sequence of distributions \((f_{L_k})\). This is a particular type of inference.</p>
<h4 id="algorithm">Algorithm</h4>
<p>One simply uses the node-elimination/ message passing sum-product dynamic programming algorithm to find marginal probabilities \(f_{L_k}\) of tree structured graphical models.</p>
<p>This is aka the forward backward algorithm when done for all \(k\), and when computation is done in the following order: upchain &lsquo;messages&rsquo; (\(m_{t-1 \to t}\)) are passed first (in the forward step) and then down-chain &lsquo;messages&rsquo; (\(m_{t+1 \to t}\)) are passed (in the backward step).</p>
<h4 id="analysis-1">Analysis</h4>
<p>The first step corresponds to the forward step described earlier, so \(f_{L_i, x_{1:i}}\) is computed, at each node \(i \in 1:N\).</p>
<p>In the backward step, at each node \(i \in N:1\), \(f_{x_{i+1:N}|L_i}\) is calculated. This can be described iteratively: suppose that \(f_{x_{i+1:N}|L_i}\) is available, then one can find: \(f_{x_{i:N}|L_{i-1}}(l_{i-1}) = \sum_{l_i} f_{x_{i+1:N}|L_i}(l_i) f_{L_i|L_{i-1}}(l_i|l_{i-1})\). So, it is in a way symmetric to the forward step.</p>
<p>Then, \(f_{L_i, x} \propto f_{L_i| x}\) can be found by multiplying these.</p>
<h3 id="learning-given-x-l-examples">Learning given (X, L) examples</h3>
<p>Aka Supervised HMM learning. The basic idea is to use the empirical transition/ observation generation probabilities in order to estimate the HMM parameters.</p>
<h4 id="smoothing">Smoothing</h4>
<p>Especially in the case of observation generation probabilities, some smoothing is required: otherwise the distribution model would assign a probability of 0 to every state sequence \(l\) which might generate the observation sequence \(x\) containing a word not seen among the labeled examples. Also, it may be desirable to ensure that the observation generation probability \(f_{X'|L&rsquo;}(x'|l&rsquo;) &gt; 0\) for any pair \((x&rsquo;, l&rsquo;)\).</p>
<h4 id="reestimation-using-observation-sequences">Reestimation using observation sequences</h4>
<p>Suppose that one also has access to samples of \(X\), one can improve the parameter estimates by applying the EM algorithm described elsewhere for the case where only samples of \(X\) are provided.</p>
<h3 id="learning-given-observation-samples-x-only">Learning given observation samples X only</h3>
<p>To do this, starting with an initial guess about the parameters \(\param^{(0)}\), one can iteratively produce parameters \(\param^{(i)}\) with greater likelihood values \(f_{X|\param}(x)\) from \(\param^{(i-1)}\) using the EM local optimization algorithm.</p>
<p>Two steps of the algorithm: 1] For each sample \(x\): using \(\param^{(i-1)}\) with the forward-backward algorithm, infer distributions \(f_{L_i| x}\); 2] Use this distribution to update maximum likelihood estimates [ie expectations] of the number of occurrences of \(k \in ran(L_i)\), \((k_1, k_2) \in ran(L_i)^2\), \((k, x)\); using which \(\param^{(i)}\) is computed as in the supervised case (: empirical emission and transition probabilities, possibly smoothed).</p>
<h2 id="k-gram-hmm">k-gram HMM</h2>
<p>One can extend the notion of bigram HMM&rsquo;s to allow the current state to depend on previous \(k-1\) states. Analogous the case of k-gram Markov chains, these can be reduced to bigram HMM&rsquo;s by expanding the state space to \(ran(L_i)^{k-1}\). Thus, inference and learning algorithms for bigram HMM&rsquo;s can be adapted to work on k-gram HMM&rsquo;s.</p>

  </div>
</article>







<aside class="card border" id="section-tree-item-">
    <div class="card-title bg-light-gray border d-flex justify-content-between">
        <a href="#ZgotmplZ">05 Partially observed states </a>
        <a data-toggle="collapse" href="#section-tree-item-body-" role="button" aria-expanded="false" aria-controls="section-tree-item-body-" >‚Ä¶<i class="fas fa-caret-down" class="collapsed"></i> </a>
    </div>
    <nav id="section-tree-item-body-" class="card-body p-0 collapse">
        
        <li>draft: false</li>
        
        <li>iscjklanguage: false</li>
        
        <li>title: 05 Partially observed states</li>
        
    </nav>
</aside>


      </main>
    </div>
    <footer class="bg-yellow  p-1" role="contentinfo">
  <div id="disqus_thread"></div>
  <div id="div_footer_bar" class="container-fluid d-flex justify-content-between">
    <a class="btn btn-secondary" href="https://github.com/vvasuki/notes/issues/new" >
      ‡§™‡•ç‡§∞‡§§‡§ø‡§∏‡•ç‡§™‡§®‡•ç‡§¶‡§É
    </a>
    <a class="btn btn-secondary" href="http://creativecommons.org/licenses/by/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by/4.0/80x15.png" /></a>
    <div class="btn small border">
      Built on 2020 Nov 22 10:54:55 UTC. (<a href="http://google.com/search?q=10%3a54%3a55%20UTC to IST">IST</a>)
    </div>
  <ul id="footer-bar-right-custom" class="list-group list-group-horizontal">
  </ul>
  </div>
</footer>

  </body>
  <script type='text/javascript'>
    
    
    
    module_main.default.onDocumentReadyTasks();
  </script>
</html>
