\contentsline {chapter}{Contents}{1}{section*.1}
\contentsline {part}{\partnumberline {I}Introduction}{7}{part.1}
\contentsline {chapter}{\chapternumberline {1}Modeling}{8}{chapter.1}
\contentsline {section}{\numberline {1.1}Model/ hypothesize for predictive ability}{8}{section.1.1}
\contentsline {subsection}{\numberline {1.1.1}Realism vs conciseness}{8}{subsection.1.1.1}
\contentsline {subsection}{\numberline {1.1.2}Frequentist vs Subjective interpretations}{8}{subsection.1.1.2}
\contentsline {subsection}{\numberline {1.1.3}Sampling mechanism}{8}{subsection.1.1.3}
\contentsline {subsubsection}{\numberline {1.1.3.1}Possible errors}{9}{subsubsection.1.1.3.1}
\contentsline {section}{\numberline {1.2}Using the models}{9}{section.1.2}
\contentsline {subsection}{\numberline {1.2.1}Effectiveness of simple models}{9}{subsection.1.2.1}
\contentsline {chapter}{\chapternumberline {2}Non probabilistic models}{9}{chapter.2}
\contentsline {part}{\partnumberline {II}Simple Random variable densities}{9}{part.2}
\contentsline {chapter}{\chapternumberline {3}Distribution of values}{9}{chapter.3}
\contentsline {section}{\numberline {3.1}Specification and classes}{9}{section.3.1}
\contentsline {subsection}{\numberline {3.1.1}Notation}{10}{subsection.3.1.1}
\contentsline {subsection}{\numberline {3.1.2}Parameter types}{10}{subsection.3.1.2}
\contentsline {subsection}{\numberline {3.1.3}Specify continuous distribution over bounded support}{10}{subsection.3.1.3}
\contentsline {section}{\numberline {3.2}Inference, Sampling from distribution}{10}{section.3.2}
\contentsline {chapter}{\chapternumberline {4}Discrete probability distributions}{10}{chapter.4}
\contentsline {section}{\numberline {4.1}Coin toss distribution}{10}{section.4.1}
\contentsline {subsection}{\numberline {4.1.1}Properties}{10}{subsection.4.1.1}
\contentsline {subsection}{\numberline {4.1.2}Odds of success}{10}{subsection.4.1.2}
\contentsline {section}{\numberline {4.2}Multiple coin-toss}{10}{section.4.2}
\contentsline {subsection}{\numberline {4.2.1}Properties}{11}{subsection.4.2.1}
\contentsline {subsection}{\numberline {4.2.2}Approximations}{11}{subsection.4.2.2}
\contentsline {subsubsection}{\numberline {4.2.2.1}With exponential decay for sq deviation distribution}{11}{subsubsection.4.2.2.1}
\contentsline {subsection}{\numberline {4.2.3}Poisson distribution}{11}{subsection.4.2.3}
\contentsline {subsection}{\numberline {4.2.4}Random walk on a line}{11}{subsection.4.2.4}
\contentsline {subsection}{\numberline {4.2.5}(balls, bins)}{11}{subsection.4.2.5}
\contentsline {subsubsection}{\numberline {4.2.5.1}Process}{11}{subsubsection.4.2.5.1}
\contentsline {subsubsection}{\numberline {4.2.5.2}Distribution}{12}{subsubsection.4.2.5.2}
\contentsline {section}{\numberline {4.3}Categorical distribution}{12}{section.4.3}
\contentsline {section}{\numberline {4.4}Multinomial distribution}{12}{section.4.4}
\contentsline {section}{\numberline {4.5}Geometric distribution}{12}{section.4.5}
\contentsline {section}{\numberline {4.6}Hypergeometric distribution}{12}{section.4.6}
\contentsline {section}{\numberline {4.7}Smoothing}{13}{section.4.7}
\contentsline {subsection}{\numberline {4.7.1}Motivation}{13}{subsection.4.7.1}
\contentsline {subsubsection}{\numberline {4.7.1.1}Incomplete knowledge of range}{13}{subsubsection.4.7.1.1}
\contentsline {subsubsection}{\numberline {4.7.1.2}Assumption of continuous ran(X)}{13}{subsubsection.4.7.1.2}
\contentsline {subsection}{\numberline {4.7.2}Add 1}{13}{subsection.4.7.2}
\contentsline {subsubsection}{\numberline {4.7.2.1}Add k}{13}{subsubsection.4.7.2.1}
\contentsline {subsection}{\numberline {4.7.3}Different additions}{13}{subsection.4.7.3}
\contentsline {subsubsection}{\numberline {4.7.3.1}Use backoff probabilities}{14}{subsubsection.4.7.3.1}
\contentsline {chapter}{\chapternumberline {5}Mode-deviation penalizers}{14}{chapter.5}
\contentsline {section}{\numberline {5.1}Inverse squared decay}{14}{section.5.1}
\contentsline {subsection}{\numberline {5.1.1}Limited to positive deviation}{14}{subsection.5.1.1}
\contentsline {chapter}{\chapternumberline {6}Exponential families}{14}{chapter.6}
\contentsline {section}{\numberline {6.1}Exponential family of distributions}{14}{section.6.1}
\contentsline {subsection}{\numberline {6.1.1}Generated by h and feature function, parametrized by t}{14}{subsection.6.1.1}
\contentsline {subsubsection}{\numberline {6.1.1.1}Canonical form.}{14}{subsubsection.6.1.1.1}
\contentsline {subsubsection}{\numberline {6.1.1.2}Minimal parametrization.}{15}{subsubsection.6.1.1.2}
\contentsline {subsection}{\numberline {6.1.2}Undirected graphical model from exp family distribution}{15}{subsection.6.1.2}
\contentsline {subsection}{\numberline {6.1.3}Maximum entropy distribution with given means}{15}{subsection.6.1.3}
\contentsline {subsubsection}{\numberline {6.1.3.1}The optimization problem}{15}{subsubsection.6.1.3.1}
\contentsline {subsubsection}{\numberline {6.1.3.2}Lagrangian form}{15}{subsubsection.6.1.3.2}
\contentsline {subsubsection}{\numberline {6.1.3.3}Closest distribution to h with given means}{15}{subsubsection.6.1.3.3}
\contentsline {subsubsection}{\numberline {6.1.3.4}Parametrization by means}{15}{subsubsection.6.1.3.4}
\contentsline {section}{\numberline {6.2}Inverse Exponential decay for squared deviation from mean}{15}{section.6.2}
\contentsline {subsection}{\numberline {6.2.1}Importance}{16}{subsection.6.2.1}
\contentsline {subsection}{\numberline {6.2.2}1D case}{16}{subsection.6.2.2}
\contentsline {subsubsection}{\numberline {6.2.2.1}pdf, cdf}{16}{subsubsection.6.2.2.1}
\contentsline {paragraph}{Important densities}{16}{section*.5}
\contentsline {subsubsection}{\numberline {6.2.2.2}Standard Normal distribution}{16}{subsubsection.6.2.2.2}
\contentsline {subsubsection}{\numberline {6.2.2.3}CDF calculation}{16}{subsubsection.6.2.2.3}
\contentsline {subsubsection}{\numberline {6.2.2.4}Moment generating function}{16}{subsubsection.6.2.2.4}
\contentsline {subsubsection}{\numberline {6.2.2.5}Other properties}{17}{subsubsection.6.2.2.5}
\contentsline {subsection}{\numberline {6.2.3}Multidimensional case}{17}{subsection.6.2.3}
\contentsline {subsubsection}{\numberline {6.2.3.1}Definition with univariates}{17}{subsubsection.6.2.3.1}
\contentsline {subsubsection}{\numberline {6.2.3.2}Distribution}{17}{subsubsection.6.2.3.2}
\contentsline {subsubsection}{\numberline {6.2.3.3}Covariance matrix is symmetric}{17}{subsubsection.6.2.3.3}
\contentsline {subsubsection}{\numberline {6.2.3.4}Geometric view}{17}{subsubsection.6.2.3.4}
\contentsline {subsubsection}{\numberline {6.2.3.5}Product of normal distributions}{18}{subsubsection.6.2.3.5}
\contentsline {subsection}{\numberline {6.2.4}$\infty $ dimensional Normal distribution}{18}{subsection.6.2.4}
\contentsline {subsection}{\numberline {6.2.5}Gaussian graphical models}{18}{subsection.6.2.5}
\contentsline {subsubsection}{\numberline {6.2.5.1}Uncorrelated variables}{18}{subsubsection.6.2.5.1}
\contentsline {section}{\numberline {6.3}1D distributions from exponential family}{18}{section.6.3}
\contentsline {subsection}{\numberline {6.3.1}Polynomial rise with inverse exponential decay for largeness}{18}{subsection.6.3.1}
\contentsline {paragraph}{Inverse Gamma distribution}{18}{section*.10}
\contentsline {subsubsection}{\numberline {6.3.1.1}Exponential decay distribution $expo(\ensuremath {\mu })$}{19}{subsubsection.6.3.1.1}
\contentsline {paragraph}{Shift parameter}{19}{section*.11}
\contentsline {paragraph}{Bilateral-exponential decay distribution}{19}{section*.12}
\contentsline {chapter}{\chapternumberline {7}Other density families}{19}{chapter.7}
\contentsline {section}{\numberline {7.1}Sampling distributions}{19}{section.7.1}
\contentsline {subsection}{\numberline {7.1.1}Standard normal square sum}{19}{subsection.7.1.1}
\contentsline {subsection}{\numberline {7.1.2}Student's t distribution with k degrees of freedom}{19}{subsection.7.1.2}
\contentsline {subsection}{\numberline {7.1.3}F distribution}{19}{subsection.7.1.3}
\contentsline {section}{\numberline {7.2}Heavy tailed distributions}{19}{section.7.2}
\contentsline {subsection}{\numberline {7.2.1}Power law distributions}{20}{subsection.7.2.1}
\contentsline {subsubsection}{\numberline {7.2.1.1}With exponential cutoff}{20}{subsubsection.7.2.1.1}
\contentsline {subsubsection}{\numberline {7.2.1.2}Zipf's law for resource usage}{20}{subsubsection.7.2.1.2}
\contentsline {section}{\numberline {7.3}Mixture distribution}{20}{section.7.3}
\contentsline {section}{\numberline {7.4}Other pdf's}{20}{section.7.4}
\contentsline {subsection}{\numberline {7.4.1}Uniform and triangular distributions}{20}{subsection.7.4.1}
\contentsline {subsection}{\numberline {7.4.2}Log normal distribution}{20}{subsection.7.4.2}
\contentsline {subsection}{\numberline {7.4.3}Gumbel distribution}{20}{subsection.7.4.3}
\contentsline {subsection}{\numberline {7.4.4}Probability simplex coordinate powering}{20}{subsection.7.4.4}
\contentsline {subsubsection}{\numberline {7.4.4.1}2-dim case}{21}{subsubsection.7.4.4.1}
\contentsline {subsection}{\numberline {7.4.5}Wigner semicircle distribution}{21}{subsection.7.4.5}
\contentsline {part}{\partnumberline {III}Model dependence among random variables}{21}{part.3}
\contentsline {chapter}{\chapternumberline {8}Distribution models}{21}{chapter.8}
\contentsline {section}{\numberline {8.1}Discrete L: Response probability: Discriminative models}{21}{section.8.1}
\contentsline {subsection}{\numberline {8.1.1}Boolean valued functions}{21}{subsection.8.1.1}
\contentsline {subsection}{\numberline {8.1.2}Probability from regression models}{21}{subsection.8.1.2}
\contentsline {subsubsection}{\numberline {8.1.2.1}Advantages of modeling probability}{21}{subsubsection.8.1.2.1}
\contentsline {subsection}{\numberline {8.1.3}Model numeric labels with regression models}{22}{subsection.8.1.3}
\contentsline {subsubsection}{\numberline {8.1.3.1}Dependence on choice of ran(Y)}{22}{subsubsection.8.1.3.1}
\contentsline {subsubsection}{\numberline {8.1.3.2}y in 1 of k binary encoding format}{22}{subsubsection.8.1.3.2}
\contentsline {subsection}{\numberline {8.1.4}Logistic model}{22}{subsection.8.1.4}
\contentsline {subsubsection}{\numberline {8.1.4.1}Log linear model for class probabilities}{22}{subsubsection.8.1.4.1}
\contentsline {subsubsection}{\numberline {8.1.4.2}Equivalent form: model log odds}{22}{subsubsection.8.1.4.2}
\contentsline {subsubsection}{\numberline {8.1.4.3}2-class case}{23}{subsubsection.8.1.4.3}
\contentsline {subsubsection}{\numberline {8.1.4.4}Risk factors interpretation}{23}{subsubsection.8.1.4.4}
\contentsline {subsubsection}{\numberline {8.1.4.5}As a linear discriminant}{23}{subsubsection.8.1.4.5}
\contentsline {subsection}{\numberline {8.1.5}Estimating parameters}{23}{subsection.8.1.5}
\contentsline {subsubsection}{\numberline {8.1.5.1}Sparsity of model parameters}{23}{subsubsection.8.1.5.1}
\contentsline {section}{\numberline {8.2}Discrete L: Response probability: Generative models}{23}{section.8.2}
\contentsline {subsection}{\numberline {8.2.1}Latent variable model}{23}{subsection.8.2.1}
\contentsline {subsection}{\numberline {8.2.2}Assume conditional independence of input variables}{23}{subsection.8.2.2}
\contentsline {subsubsection}{\numberline {8.2.2.1}Linear separator in some feature space}{24}{subsubsection.8.2.2.1}
\contentsline {subsubsection}{\numberline {8.2.2.2}Success in practice.}{24}{subsubsection.8.2.2.2}
\contentsline {subsubsection}{\numberline {8.2.2.3}Discriminative counterpart}{24}{subsubsection.8.2.2.3}
\contentsline {subsection}{\numberline {8.2.3}Use exponential family models}{24}{subsection.8.2.3}
\contentsline {subsubsection}{\numberline {8.2.3.1}Specification}{24}{subsubsection.8.2.3.1}
\contentsline {subsubsection}{\numberline {8.2.3.2}Tree structure assumptions}{24}{subsubsection.8.2.3.2}
\contentsline {section}{\numberline {8.3}Latent variable models: Expectation Maximization (EM) alg}{24}{section.8.3}
\contentsline {subsection}{\numberline {8.3.1}Problem}{24}{subsection.8.3.1}
\contentsline {subsubsection}{\numberline {8.3.1.1}Tough to Optimize likelihood}{24}{subsubsection.8.3.1.1}
\contentsline {subsubsection}{\numberline {8.3.1.2}Examples}{25}{subsubsection.8.3.1.2}
\contentsline {subsection}{\numberline {8.3.2}Iterative algorithm}{25}{subsection.8.3.2}
\contentsline {subsubsection}{\numberline {8.3.2.1}Intuition}{25}{subsubsection.8.3.2.1}
\contentsline {subsubsection}{\numberline {8.3.2.2}E-step}{25}{subsubsection.8.3.2.2}
\contentsline {subsubsection}{\numberline {8.3.2.3}M-step}{25}{subsubsection.8.3.2.3}
\contentsline {subsection}{\numberline {8.3.3}Analysis}{25}{subsection.8.3.3}
\contentsline {subsubsection}{\numberline {8.3.3.1}Maximizing an approximation of the likelihood}{25}{subsubsection.8.3.3.1}
\contentsline {subsubsection}{\numberline {8.3.3.2}Q(w) is a lower bound}{25}{subsubsection.8.3.3.2}
\contentsline {subsubsection}{\numberline {8.3.3.3}Convergence}{26}{subsubsection.8.3.3.3}
\contentsline {chapter}{\chapternumberline {9}Graphical models}{26}{chapter.9}
\contentsline {section}{\numberline {9.1}Graphical model G of distribution}{26}{section.9.1}
\contentsline {subsection}{\numberline {9.1.1}The modeling problem}{26}{subsection.9.1.1}
\contentsline {subsubsection}{\numberline {9.1.1.1}Distribution structure/ sparsity}{26}{subsubsection.9.1.1.1}
\contentsline {subsubsection}{\numberline {9.1.1.2}Uses}{26}{subsubsection.9.1.1.2}
\contentsline {subsection}{\numberline {9.1.2}Factor graphs}{26}{subsection.9.1.2}
\contentsline {subsubsection}{\numberline {9.1.2.1}Factors of Pr(x)}{26}{subsubsection.9.1.2.1}
\contentsline {subsubsection}{\numberline {9.1.2.2}Conditional independence}{27}{subsubsection.9.1.2.2}
\contentsline {subsubsection}{\numberline {9.1.2.3}Expressiveness}{27}{subsubsection.9.1.2.3}
\contentsline {subsection}{\numberline {9.1.3}Undirected graphical models}{27}{subsection.9.1.3}
\contentsline {subsubsection}{\numberline {9.1.3.1}Factorization}{27}{subsubsection.9.1.3.1}
\contentsline {subsubsection}{\numberline {9.1.3.2}Conditional independence properties}{27}{subsubsection.9.1.3.2}
\contentsline {subsubsection}{\numberline {9.1.3.3}Tree structured case}{28}{subsubsection.9.1.3.3}
\contentsline {paragraph}{Importance}{28}{section*.23}
\contentsline {paragraph}{Form and connections}{28}{section*.24}
\contentsline {paragraph}{As directed model}{28}{section*.25}
\contentsline {paragraph}{In terms of marginals}{28}{section*.26}
\contentsline {subsubsection}{\numberline {9.1.3.4}Pairwise graphical model}{28}{subsubsection.9.1.3.4}
\contentsline {subsubsection}{\numberline {9.1.3.5}Hierarchical models}{28}{subsubsection.9.1.3.5}
\contentsline {subsubsection}{\numberline {9.1.3.6}Discrete models}{28}{subsubsection.9.1.3.6}
\contentsline {subsection}{\numberline {9.1.4}Junction tree model}{29}{subsection.9.1.4}
\contentsline {subsubsection}{\numberline {9.1.4.1}Factorization}{29}{subsubsection.9.1.4.1}
\contentsline {subsection}{\numberline {9.1.5}Directed}{29}{subsection.9.1.5}
\contentsline {subsubsection}{\numberline {9.1.5.1}Extra notation}{29}{subsubsection.9.1.5.1}
\contentsline {subsubsection}{\numberline {9.1.5.2}Factorization}{29}{subsubsection.9.1.5.2}
\contentsline {subsubsection}{\numberline {9.1.5.3}Marginal independence}{30}{subsubsection.9.1.5.3}
\contentsline {subsubsection}{\numberline {9.1.5.4}Dependency seperation of X, Y by Z}{30}{subsubsection.9.1.5.4}
\contentsline {subsubsection}{\numberline {9.1.5.5}Other conditional independence properties}{30}{subsubsection.9.1.5.5}
\contentsline {subsubsection}{\numberline {9.1.5.6}Marginalized DAG}{30}{subsubsection.9.1.5.6}
\contentsline {subsection}{\numberline {9.1.6}Comparison}{31}{subsection.9.1.6}
\contentsline {subsubsection}{\numberline {9.1.6.1}Expressiveness}{31}{subsubsection.9.1.6.1}
\contentsline {subsubsection}{\numberline {9.1.6.2}Structural equivalence}{31}{subsubsection.9.1.6.2}
\contentsline {subsubsection}{\numberline {9.1.6.3}Independence relationships amongst vars}{31}{subsubsection.9.1.6.3}
\contentsline {section}{\numberline {9.2}Inference, decoding using Graphical model}{31}{section.9.2}
\contentsline {subsection}{\numberline {9.2.1}Problems}{31}{subsection.9.2.1}
\contentsline {subsubsection}{\numberline {9.2.1.1}Inference problems}{31}{subsubsection.9.2.1.1}
\contentsline {subsubsection}{\numberline {9.2.1.2}Decoding problem}{31}{subsubsection.9.2.1.2}
\contentsline {paragraph}{Global maximum vs marginal maxima}{31}{section*.36}
\contentsline {subsubsection}{\numberline {9.2.1.3}Evidence}{32}{subsubsection.9.2.1.3}
\contentsline {subsubsection}{\numberline {9.2.1.4}Solving for all variables}{32}{subsubsection.9.2.1.4}
\contentsline {subsection}{\numberline {9.2.2}Factorization and graph-based computations}{32}{subsection.9.2.2}
\contentsline {subsubsection}{\numberline {9.2.2.1}Benefit of factorization}{32}{subsubsection.9.2.2.1}
\contentsline {subsubsection}{\numberline {9.2.2.2}Graph traversal view}{32}{subsubsection.9.2.2.2}
\contentsline {subsection}{\numberline {9.2.3}Belief propagation}{33}{subsection.9.2.3}
\contentsline {subsubsection}{\numberline {9.2.3.1}The Bottom-up idea}{33}{subsubsection.9.2.3.1}
\contentsline {subsubsection}{\numberline {9.2.3.2}Node Elimination algorithm: Undirected Trees}{33}{subsubsection.9.2.3.2}
\contentsline {subsubsection}{\numberline {9.2.3.3}Reusing messages: Undirected Tree}{33}{subsubsection.9.2.3.3}
\contentsline {subsubsection}{\numberline {9.2.3.4}Tree Factor graphs}{33}{subsubsection.9.2.3.4}
\contentsline {subsubsection}{\numberline {9.2.3.5}General undirected graphs}{34}{subsubsection.9.2.3.5}
\contentsline {subsubsection}{\numberline {9.2.3.6}Approximate inference: Loopy belief propagation}{34}{subsubsection.9.2.3.6}
\contentsline {subsection}{\numberline {9.2.4}For Gaussian graphical models}{35}{subsection.9.2.4}
\contentsline {subsubsection}{\numberline {9.2.4.1}Connection with solving Ax = b}{35}{subsubsection.9.2.4.1}
\contentsline {subsection}{\numberline {9.2.5}Directed graphical models}{36}{subsection.9.2.5}
\contentsline {chapter}{\chapternumberline {10}Sparse signal detection}{36}{chapter.10}
\contentsline {section}{\numberline {10.1}Scale mixture models}{36}{section.10.1}
\contentsline {chapter}{\chapternumberline {11}Affinity modeling}{36}{chapter.11}
\contentsline {section}{\numberline {11.1}Problem}{36}{section.11.1}
\contentsline {subsection}{\numberline {11.1.1}Motivation}{36}{subsection.11.1.1}
\contentsline {section}{\numberline {11.2}Non probabilistic ways}{36}{section.11.2}
\contentsline {section}{\numberline {11.3}pLSA}{36}{section.11.3}
\contentsline {subsection}{\numberline {11.3.1}Aspect model}{36}{subsection.11.3.1}
\contentsline {subsection}{\numberline {11.3.2}Modeling assumptions}{37}{subsection.11.3.2}
\contentsline {subsection}{\numberline {11.3.3}Dimensionality reduction}{37}{subsection.11.3.3}
\contentsline {subsection}{\numberline {11.3.4}Defects}{37}{subsection.11.3.4}
\contentsline {section}{\numberline {11.4}Latent Dirichlet Allocation (LDA)}{37}{section.11.4}
\contentsline {chapter}{\chapternumberline {12}Modeling stochastic processes}{37}{chapter.12}
\contentsline {section}{\numberline {12.1}Stochastic process with state space T}{37}{section.12.1}
\contentsline {subsection}{\numberline {12.1.1}Multiple coin toss processes}{37}{subsection.12.1.1}
\contentsline {subsection}{\numberline {12.1.2}Continuous time}{38}{subsection.12.1.2}
\contentsline {section}{\numberline {12.2}State transitions}{38}{section.12.2}
\contentsline {subsection}{\numberline {12.2.1}Assumptions about state transitions}{38}{subsection.12.2.1}
\contentsline {subsubsection}{\numberline {12.2.1.1}Dependence solely on prior state}{38}{subsubsection.12.2.1.1}
\contentsline {paragraph}{Sequence distribution: chain structure}{38}{section*.51}
\contentsline {subsubsection}{\numberline {12.2.1.2}Dependence on prior k states}{38}{subsubsection.12.2.1.2}
\contentsline {subsubsection}{\numberline {12.2.1.3}Reduction to bigram state chain}{38}{subsubsection.12.2.1.3}
\contentsline {subsection}{\numberline {12.2.2}Describing bigram model}{38}{subsection.12.2.2}
\contentsline {subsubsection}{\numberline {12.2.2.1}State transition matrix}{38}{subsubsection.12.2.2.1}
\contentsline {subsubsection}{\numberline {12.2.2.2}State transition graph}{39}{subsubsection.12.2.2.2}
\contentsline {subsubsection}{\numberline {12.2.2.3}Types of states and chains}{39}{subsubsection.12.2.2.3}
\contentsline {subsubsection}{\numberline {12.2.2.4}Learning transition probabilities}{39}{subsubsection.12.2.2.4}
\contentsline {subsection}{\numberline {12.2.3}Unique Stationary distribution $\pi $ of ergodic chains}{39}{subsection.12.2.3}
\contentsline {subsection}{\numberline {12.2.4}Mixing time of Ergodic chain}{39}{subsection.12.2.4}
\contentsline {subsubsection}{\numberline {12.2.4.1}Purpose, definition}{39}{subsubsection.12.2.4.1}
\contentsline {subsubsection}{\numberline {12.2.4.2}Coupling lemma}{39}{subsubsection.12.2.4.2}
\contentsline {subsubsection}{\numberline {12.2.4.3}Mixing time bound}{40}{subsubsection.12.2.4.3}
\contentsline {subsection}{\numberline {12.2.5}Straight line state transitions}{40}{subsection.12.2.5}
\contentsline {subsubsection}{\numberline {12.2.5.1}Gambler's winnings}{40}{subsubsection.12.2.5.1}
\contentsline {paragraph}{Analysis using martingale property}{40}{section*.53}
\contentsline {subsubsection}{\numberline {12.2.5.2}Queue}{40}{subsubsection.12.2.5.2}
\contentsline {section}{\numberline {12.3}Martingale $\ensuremath {\left (Z_{n}\right )}$ wrt filtration}{40}{section.12.3}
\contentsline {subsection}{\numberline {12.3.1}Problem}{40}{subsection.12.3.1}
\contentsline {subsubsection}{\numberline {12.3.1.1}Example}{40}{subsubsection.12.3.1.1}
\contentsline {subsection}{\numberline {12.3.2}Properties}{40}{subsection.12.3.2}
\contentsline {subsection}{\numberline {12.3.3}Stopping time T}{41}{subsection.12.3.3}
\contentsline {subsection}{\numberline {12.3.4}Doob martingale}{41}{subsection.12.3.4}
\contentsline {subsection}{\numberline {12.3.5}Find expected running time of a game}{41}{subsection.12.3.5}
\contentsline {subsection}{\numberline {12.3.6}Concentration around starting value}{41}{subsection.12.3.6}
\contentsline {subsubsection}{\numberline {12.3.6.1}Applied to Doob Martingale}{41}{subsubsection.12.3.6.1}
\contentsline {subsubsection}{\numberline {12.3.6.2}Additive Bound for deviation from mean}{42}{subsubsection.12.3.6.2}
\contentsline {subsubsection}{\numberline {12.3.6.3}Additive deviation bound for sum of Poisson trial RV's}{42}{subsubsection.12.3.6.3}
\contentsline {section}{\numberline {12.4}n-gram model}{42}{section.12.4}
\contentsline {subsection}{\numberline {12.4.1}Model}{42}{subsection.12.4.1}
\contentsline {subsubsection}{\numberline {12.4.1.1}Subsequence/ prefix probabilities: notation}{42}{subsubsection.12.4.1.1}
\contentsline {paragraph}{Occurrence near sentence terminals}{42}{section*.55}
\contentsline {subsubsection}{\numberline {12.4.1.2}Actual probability}{42}{subsubsection.12.4.1.2}
\contentsline {subsubsection}{\numberline {12.4.1.3}Markov assumption}{42}{subsubsection.12.4.1.3}
\contentsline {subsection}{\numberline {12.4.2}Estimation}{43}{subsection.12.4.2}
\contentsline {subsubsection}{\numberline {12.4.2.1}n and corpus size}{43}{subsubsection.12.4.2.1}
\contentsline {subsubsection}{\numberline {12.4.2.2}Rare words}{43}{subsubsection.12.4.2.2}
\contentsline {subsection}{\numberline {12.4.3}Smoothing}{43}{subsection.12.4.3}
\contentsline {section}{\numberline {12.5}Partially observed states}{43}{section.12.5}
\contentsline {subsection}{\numberline {12.5.1}Observations, states}{43}{subsection.12.5.1}
\contentsline {subsubsection}{\numberline {12.5.1.1}Use}{43}{subsubsection.12.5.1.1}
\contentsline {subsubsection}{\numberline {12.5.1.2}Applications}{43}{subsubsection.12.5.1.2}
\contentsline {subsection}{\numberline {12.5.2}Model classes}{44}{subsection.12.5.2}
\contentsline {subsubsection}{\numberline {12.5.2.1}Generative model of Pr(X, L)}{44}{subsubsection.12.5.2.1}
\contentsline {subsubsection}{\numberline {12.5.2.2}Model L given X}{44}{subsubsection.12.5.2.2}
\contentsline {paragraph}{Ignoring sequentiality}{44}{section*.56}
\contentsline {subsection}{\numberline {12.5.3}Partially observed state chain}{44}{subsection.12.5.3}
\contentsline {subsubsection}{\numberline {12.5.3.1}Graphical model}{44}{subsubsection.12.5.3.1}
\contentsline {subsubsection}{\numberline {12.5.3.2}Representations}{44}{subsubsection.12.5.3.2}
\contentsline {subsubsection}{\numberline {12.5.3.3}Decoding/ filtering}{44}{subsubsection.12.5.3.3}
\contentsline {paragraph}{Problem}{44}{section*.57}
\contentsline {paragraph}{Message passing algorithm}{45}{section*.58}
\contentsline {subsubsection}{\numberline {12.5.3.4}Online label distribution inference}{45}{subsubsection.12.5.3.4}
\contentsline {paragraph}{Problem}{45}{section*.59}
\contentsline {paragraph}{Forward algorithm}{45}{section*.60}
\contentsline {paragraph}{Analysis}{45}{section*.61}
\contentsline {subsubsection}{\numberline {12.5.3.5}Past Label Distribution inference}{45}{subsubsection.12.5.3.5}
\contentsline {paragraph}{Problem}{45}{section*.62}
\contentsline {paragraph}{Algorithm}{45}{section*.63}
\contentsline {paragraph}{Analysis}{46}{section*.64}
\contentsline {subsubsection}{\numberline {12.5.3.6}Learning given (X, L) examples}{46}{subsubsection.12.5.3.6}
\contentsline {paragraph}{Smoothing}{46}{section*.65}
\contentsline {paragraph}{Reestimation using observation sequences}{46}{section*.66}
\contentsline {subsubsection}{\numberline {12.5.3.7}Learning given observation samples X only}{46}{subsubsection.12.5.3.7}
\contentsline {subsection}{\numberline {12.5.4}k-gram HMM}{46}{subsection.12.5.4}
\contentsline {section}{\numberline {12.6}Decision process}{47}{section.12.6}
\contentsline {chapter}{\chapternumberline {13}Continuous response variables' prediction}{47}{chapter.13}
\contentsline {section}{\numberline {13.1}Data preparation and assumptions}{47}{section.13.1}
\contentsline {section}{\numberline {13.2}Generalized linear model}{47}{section.13.2}
\contentsline {subsection}{\numberline {13.2.1}Linear models}{47}{subsection.13.2.1}
\contentsline {subsection}{\numberline {13.2.2}Generalization}{47}{subsection.13.2.2}
\contentsline {subsubsection}{\numberline {13.2.2.1}Log linear model}{47}{subsubsection.13.2.2.1}
\contentsline {subsubsection}{\numberline {13.2.2.2}Logistic model}{47}{subsubsection.13.2.2.2}
\contentsline {subsubsection}{\numberline {13.2.2.3}Perceptron: step function}{47}{subsubsection.13.2.2.3}
\contentsline {section}{\numberline {13.3}Multi-layer generalized linear model}{48}{section.13.3}
\contentsline {subsection}{\numberline {13.3.1}Model}{48}{subsection.13.3.1}
\contentsline {subsubsection}{\numberline {13.3.1.1}Component names}{48}{subsubsection.13.3.1.1}
\contentsline {subsubsection}{\numberline {13.3.1.2}Activation function}{48}{subsubsection.13.3.1.2}
\contentsline {subsubsection}{\numberline {13.3.1.3}Visualization as a network}{48}{subsubsection.13.3.1.3}
\contentsline {subsubsection}{\numberline {13.3.1.4}Nomenclature}{48}{subsubsection.13.3.1.4}
\contentsline {subsection}{\numberline {13.3.2}Connection to other models}{48}{subsection.13.3.2}
\contentsline {subsection}{\numberline {13.3.3}Model training}{49}{subsection.13.3.3}
\contentsline {subsubsection}{\numberline {13.3.3.1}Gradient finding}{49}{subsubsection.13.3.3.1}
\contentsline {subsubsection}{\numberline {13.3.3.2}Weight initialization}{49}{subsubsection.13.3.3.2}
\contentsline {subsection}{\numberline {13.3.4}Flexibility}{49}{subsection.13.3.4}
\contentsline {subsection}{\numberline {13.3.5}Disadvantages}{49}{subsection.13.3.5}
\contentsline {section}{\numberline {13.4}Deep belief network}{50}{section.13.4}
\contentsline {part}{\partnumberline {IV}References}{50}{part.4}
\contentsline {chapter}{Bibliography}{50}{section*.69}
