Increasing attention to recommendation systems in general can be attributed primarily to commercial enterprises like Netflix and Amazon, where making good recommendations for the customers is important for business. A huge body of literature studies the problem of group recommendation, where the problem is to recommend items or products to a group of users in a friendship network.  Affiliation recommendation for users of a friendship network, however, is relatively new and less studied.

\subsection{Joint matrix factorization models}
We now examine the relationship of the latent factors model proposed in this paper to a variety of other models proposed recently. Bader and Chew \cite{baderChew08}, in the context of information retrieval, tackle the problem of applying LSA to multi-lingual corpora. In such corpora, one has access to term-similarity information along with term-document matrices corresponding to various languages. In order to derive low dimensional term and document factors which account for information from both these sources, they form a joint matrix similar to our combined adjacency matrix C and compute its SVD. However, unlike this work, \cite{baderChew08} does not deal with the item recommendation problem, and it does not view this joint matrix as arising out of a pair of networks.

We will now consider two other joint matrix factorization models: One class of models uses a probabilistic collaborative filtering to approach the problem, whereas another tackles the problem of combining information from multiple sources from the perspective of joint matrix factorization.

\subsubsection{Probabilistic Collaborative Filtering Models}
Collaborative filtering is a natural way to approach the affiliation recommendation problem. Typically collaborative filtering is applied to user-item preference problems. This is based on the simple idea that users with similar tastes behave similarly.

This approach has recently been applied to the affiliation recommendation problem by Chen et al. \cite{GoogleCFLatent}. The authors examined the use of Latent Dirichlet Allocation (LDA) in affiliation recommendation. The LDA approach does not use information from the friendship network among users. So, here we briefly examine the relationship between the latent factors model we propose and this LDA based approach, while ignoring the friendship network aspects of our model.

Consider the objective (\ref{e:objective}) we are trying to minimize. In the proposed model, if we ignore the constraint that the user factors $\U$ do not result in too large a deviation from $\SS$, we are essentially trying to find a low rank approximation to $\A$ in terms of the Frobenius norm. The solution which minimizes that objective is given by the SVD of $\A$. This is the Latent Semantic Analysis approach (LSA), which has long been exploited for similar problems in the area of information retrieval. pLSA, or probabilistic LSA \cite{HofmannPLSI}, instead proposes a statistical model for the process generating $\A$ and then learns the model parameters which are most likely to have generated the observations in $\A$. These parameters can then be used in finding a low rank approximation to $\A$, in terms of the KL divergence. It can thus be viewed as the probabilistic version of LSA. LDA, where Dirichlet priors are added to pLSA's generative model, can be viewed as the Bayesian version of pLSA. Thus, the LDA based approach to the affiliation recommendation problem may be viewed as trying to find a low rank approximation to $\A$, albeit from a probabilistic, Bayesian perspective, while ignoring information from $\SS$.

Combinatorial collaborative filtering \cite{GoogleCCF} is another work in the same vein. Unlike the LDA based approach, however, the probabilistic model of user-community relationships used in this work utilizes information not only from $\A$, but also from text descriptions of various communities. Next, we examine a couple of closely related matrix factorization models.

\subsubsection{Linked Matrix Factorization Models}
Tang et al have proposed Linked Matrix Factorization (LMF) \cite{WeiLMF} as a way of combining information from multiple graphs on the same set of entities, in order to make more accurate inferences. However, they tackle a different problem, namely, clustering. The link between their network model and ours is established by the objective functions that we optimize. The LMF model tries to simultaneously find a low rank approximation for the adjacency matrix of each network, using matrix factorization. Each such matrix factorization has a source-specific factor matrix, $\mathbf{\Lambda}^{(m)}$, and a factor matrix, $\V$, that is shared by all the sources. The objective function of LMF is effectively to minimize the quantity,
\begin{equation*}
\displaystyle\sum_{i=1}^{M}\|\A^{(m)} - \V \mathbf{\Lambda}^{(m)} \V^T\|_{F}^2
\label{e:LMF}
\end{equation*}

Comparing this to (\ref{e:objective}), we see that $\U$, which represents the user factors, is shared by the two sources of information, i.e., $\A$ and $\SS$. However, an important distinction is that we have two graphs which share only one set of entities in common, whereas in LMF, each source of information is a network on exactly the same set of users.

Singh and Gordon have proposed a model for relational learning called Collective Matrix Factorization \cite{SinghCMF}. They suggest a generalized framework for inferring relations, given a set of entities and observed relations among them. This model factors multiple source matrices simultaneously, and uses common factors for approximation whenever the same entity participates in multiple relations. It allows different loss functions for each matrix approximation, and combines the information from multiple relations using weights which reflect the relative importance for each relation. This essentially generalizes the idea of Linked Matrix Factorization. The Latent Factors Model proposed in this paper uses the parameter $\gl$ to determine the contribution of the friendship network $\SS$ in generating the user factors.

The above mentioned papers use optimization techniques based on the alternating least squares approach, we use SVD which efficiently solves the optimization problem posed by the latent factors model.

\subsection{Co-evolution of social and affiliation networks}
Researchers have studied the effects of friendship ties on affiliations in other contexts, like the growth and evolution of social networks \cite{GroupFormation}, and spread of influence through a social network 
\cite{KleinbergInfluence,ChenInfMax}. They tend to model the dependence of a user joining a group on the number of friends the user already has in the group. Zheleva et al. \cite{Coevolution} proposed a unified model for the generation of social and affiliation networks, and observed that the social network is one of the factors that influences the evolution of affiliation network. Our idea that friendship network combined with the affiliation network can be exploited in making affiliation recommendations is inspired by this line of research.
