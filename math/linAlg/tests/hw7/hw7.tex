\documentclass[10pt]{amsart}
\usepackage{amssymb, graphics, bm, verbatim, algorithm2e}

\input{../../macros}

\input{../../amsartMacros}

%opening
\title{Linear Algebra: Answer to Homework 7}
\author{vishvAs vAsuki}

\begin{document}

\maketitle

\section{24.1}
$A \in C^{m \times m}$.

\subsection{a}
\begin{thm}
$k \in C$. l is an ew of A. Then, l-k is an ew of A-kI.
\end{thm}
\begin{proof}
As l is an ew of A, $det(A-lI) = 0$. So, $det(A-kI-lI+kI) = 0$. So $det(A-kI-(l-k)I) = 0$. So, l-k is an ew of A-kI.
\end{proof}

\subsection{b}
\begin{thm}
The following claim is false:
"A is real. l is an ew of A. Then, so is -l."
\end{thm}
\begin{proof}
A = [a]. Now, Ax = ax for any $1 \times 1$ x. So, a is an eigenvalue of A. Also, there cannot be anyother ew as the eigenspace of a spans the entire space.
\end{proof}

\subsection{c}
\begin{thm}
A is real. l is an ew of A. Then, so is $\bar{l}$.
\end{thm}
\begin{proof}
Let P be the characteristic polynomial. As A is real, the coefficients in P are real. As l is an ew of A, $P(l) = 0$.

$P(l) = \sum a_{i}l^{i} = 0 = \conj{\sum a_{i}l^{i}} = \sum a_{i}\bar{l^{i}}= \sum a_{i}\bar{l}^{i} = P(\bar{l})$.

So, $\bar{l}$ is also an ew of A.
\end{proof}

\subsection{d}
\begin{thm}
l is an ew of A. A is nonsingular. Then, $l^{-1}$ is ew of $A^{-1}$.
\end{thm}
\begin{proof}
$\exists x \neq 0: Ax = lx$. So, $x l^{-1} = A^{-1}x$. Thus, $l^{-1}$ is ew of $A^{-1}$.
\end{proof}

\subsection{e}
\begin{thm}
The following claim is false:
If all ews of A are 0, A = 0.
\end{thm}
\begin{proof}
Take $A = \mat{0 & a \\ 0 & 0}$. $A-lI = \mat{-l & a \\ 0 & -l}$; and the characteristic polynomial is $l^{2} = 0$. So, all eigenvalues of A are 0; but $A \neq 0$.
\end{proof}

\subsection{f}
\begin{thm}
$A=A^{*}$. l is an ew of A. Then $|l|$ is a singular value of A.
\end{thm}
\begin{proof}
As a consequence of a theorem is stated in \cite{trefBau}, which follows directly from the theorem about the existance of the Schur factorization, A is unitarily diagonalizable.

So, $A=QLQ^{*}$. Rearranging, and fixing the signs of the columns of Q and L to ensure that $L_{i,i} \geq 0$, and that they occur in descending order, we arrive at $A=Q'\Sigma Q'^{*}$, where the elements of the diagonal matrix $\Sigma$ are the same as the elements of the diagonal matrix L. But, this is the unique SVD of A.

So, $|l|$ is a singular value of A.
\end{proof}

\subsection{g}
\begin{thm}
A is diagonalizable. All its ew's are equal. Then A is a diagonal matrix.
\end{thm}
\begin{proof}
Let $A = SLS^{-1}$ be the eigenvalue decomposition. But, we know that $L = lI$. So, $A = lSIS^{-1} = lI$. So, A is a diagonal matrix.
\end{proof}

\section{}
\begin{thm}
Let $\hat{x}$ be the solution of hermitian positive definite system $Ax=b$ via Cholesky Factorization (Algorithm 23.1, Trefethen and Bau). Let $\hat{x}$ be the exact solution to the following perturbed system: $(A+\delta A)\hat{x}=b$. Show that $\frac{\norm{\delta A}_\infty}{\norm{A}_\infty}\leq 3n^2\epsilon_{m}$.
\end{thm}

\begin{rem}
You can use the error analysis for LU factorization discussed in the class.
\end{rem}

\begin{proof}
Using the result from the error analysis for LU factorization, we know that $|\del A| \leq 3n\eps |L||U|$. But, as A is positive definite and Hermitian, $|L||U| = |L||DL^{*}| = |L||D^{0.5}D^{0.5}L^{*}| = |L||D^{0.5}||D^{0.5}L^{*}| = |LD^{0.5}||D^{0.5}L^{*}| = |R||R^{*}|$, where $D^{0.5}$ involves taking the +ve square roots of $\set{D_{i,i}}$, which means that $|D^{0.5}L^{*}| = |D^{0.5}||L^{*}|$ and $|LD^{0.5}| = |L||D^{0.5}|$.

So, $\norm{|\del A|}_{\infty} = \norm{\del A}_{\infty}\leq 3n\eps \norm{|R||R^{*}|}_{\infty} \leq 3n\eps \norm{|R|}_{\infty}\norm{|R^{*}|}_{\infty} = \\
3n\eps \norm{R}_{\infty}\norm{R^{*}}_{\infty} \leq 3n^{2}\eps \norm{R}_{2}\norm{R^{*}}_{2}$ (Using facts proved in exercise 3.2.). We know that $\norm{R}_{2} = \norm{R^{*}}_{2}$ (using SVD). So, $\norm{\del A}_{\infty} \leq 3n^{2}\eps \norm{R}_{2}^{2} = 3n^{2}\eps \norm{A}_{2} \leq 3n^{5/2}\eps \norm{A}_{\infty}$. (Using a fact from the last section of lecture 23 of \cite{trefBau}.)

\begin{rem}
We proved a slightly weaker bound above.
\end{rem}

\end{proof}


\bibliographystyle{plain}
\bibliography{../linAlg}

\end{document}

