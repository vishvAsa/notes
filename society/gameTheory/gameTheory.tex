\documentclass[oneside, article]{memoir}
\input{../packages}
\input{../packagesMemoir}
\input{../macros}


%opening
\title{algorithmorithmic Game Theory: Quick reference}
\author{vishvAs vAsuki}

\begin{document}
\maketitle

Based on \cite{algorithmGameTheory}.

\part{Prelude}
\chapter{Notation}
Pareto improvement: make some $p_{i}$ better off without penalizing any $p_{j}$. (Strong) Pareto optimality.

\chapter{Themes}
Finding equilibria in games, making the ideal move.

The complexity of that effort. Natural game strategies to converge to equilibrium. Internet as an equilibrium with unknown game.

Learning in Games.

Mechanism design: make games with players with unknown, private utilities; with desired dominant strategy solutions.

Find the price of anarchy: Total cost (equilibrium with selfish agents) - min Total cost (selfless agents).

\section{Applications}
Any human or AI endeavour involving optimum allocation of resources, maybe using a market.

\chapter{Games: introduction}
\section{Players, strategies, utilities}
Players $P = \set{p_{i}}$. A strategy is not a move but an algorithmorithm to make moves; compare with decision procedure in decision theory in statistics ref. $S_{i}$: strategy set of $p_{i}$. Strategy vector (strategy profile): $s = (s_{1}, .. s_{n})$. $s_{-i}$: s sans $s_{i}$.

\subsection{Mixed/ randomized strategies}
Independent mixed strategy of i: a Prob Distr over $S_{i}: D_{i}$.

Mixed strategy profile, perhaps $p_{i}$ coordinated: Probability distribution over $\times_{i}S_{i}$: D.

\subsection{Utility}
Preference ordering of outcomes for i: Cost, utility of strategy:\\
 $c_{i}(s) = -u_{i}(s)$. Compare with risk in decision theory in statistics ref.

\subsubsection{eps dominated strategy}
$s_{i}$ is $\eps$ dominated by $s_{i}'$ if, $\forall s_{-i}$ :\\
$u_{i}(s'_{i}, s_{-i}) \geq u_{i}(s_{i}, s_{-i}) + \eps$. Stronly vs weakly dominated strategy. Incomparable strategies: $s_{i}$ may be better wrt some $s_{-i}$, but worse wrt some other $s_{-i}'$.

\section{Simultaneous move game}
Here, strategy = move. Maybe $\forall i, j, S_{i} = S_{j}$.

\subsection{Standard (Explicit) form}
Cost (or utility) matrix: $C_{i,j}$: costs (or utility) to P if they select $(s_{i}, s_{j})$. Memory $\Omega(|S_{i}|^{n})$.

\subsection{Solution concept}
Rule for predicting how game will be played. Prediction is \textbf{solution} or value. Some solution concepts are better than others for certain games.

\chapter{Solution concepts: examples}
\section{Dominant strategy solution}
$\forall i$, $best(s_{i})$ unique, independent of $s_{-i}$: $u(s_{i}, s'_{-i}) \geq u(s'_{i}, s'_{-i}) \forall s'$. Eg: Prisoner's dilemma; not: Battle of sexes. So, players individually select strategies. May not lead to optimal payoff for any $p_{i}$.

\subsection{Prisoner's dilemma}
Cost matrix $C = \mat{(4, 4) & (1, 5)\\(5, 1) & (2, 2)}$. s = (2, 2) best for both, but unstable: If $p_{1}$ sets $s_{1} = 2$, $p_{2}$ tempted to set $s_{2} = 1$. $s = (1, 1)$ stable. Optimal selfish strategy of $p_{1}$ independent of $p_{2}$'s actions. Can be extended to multi-player game.

\subsection{Tragedy of commons}
n players; 1 common bandwidth. Strategy about demanding a portion. So, $\infty$ strategies for each: $s_{i} \in [0,1]$. If $\sum s_{i} > 1$, payoff for all 0; As $\sum s_{i}$ increases, utility decreases for all; so utility $u_{i}(s_{i}) = s_{i}(1-\sum_{j\neq i}s_{j})$. So, maximizing, best strategy: $s_{i} = (1-\sum_{j\neq i}s_{j})/2$. Unique stable soln: $s_{i} = (1+n)^{-1} \forall i$. $\sum u_i = \frac{n}{(1+n)^{2}} \approx n^{-1}$; so tragedy. A cartel would be better!

\subsection{2nd price auction}
Aka Vickery. 1 shot Auction of an item: $p_{i}$'s value for item is $v_{i}$; bids $s_{i}$; if $p_{i}$ looses, $u_{i}$ = 0; wins if $s_{i} = max_{j}s_{j}$. If $p_{i}$ wins, $u_{i} = v_{i} - s_{j}$, where j's bid is next highest. Dominant strategy: $s_{i} = v_{i}$! Item auctioned to $p_{i}$ who values it most: 'socially optimal outcome'.

\subsubsection{Revelation principle}
All $p_{i}$ can give Game Designer (GD) \\
valuation function, let GD play game. Maybe need exponential communication for value function. Also, security needed.

\section{Iterated elimination of str dominated strategies}
Take\\ game matrix. For each player: Amongst the strategies left, eliminate all dominated strategies.

Sometimes left with many incomparable strategies.

Elimination for weakly dominated strategies could lead to elimination of Nash equilibrium strategies.

\section{Nash equilibrium}

Defn: D or $\set{D_{i}}$ where even if all $p_{i}$ know all $D_{i}$, no treachery profitable. Maybe D not unique. So each $p_{i}$ can decide $D_{i}$ if he knows $D_{-i}$.

\subsection{Pure strategy}
s is Nash equilib if $\forall i, s': u_{i}(s_{i}, s_{-i}) \geq u_{i}(s'_{i}, s_{-i}) $. Eg: Battle of sexes. Includes dominant strategy solns.

\subsubsection{(Anti) Coordination games}
Battle of the sexes: $p_{1}, p_{2}$ gain when $s_{1} = s_{2}$. Players select strategies together. $C = \mat{(4, 5) & (1,1)\\(2, 2) & (5, 4)}$. Multiple equilibria; Eg: $Pr(s = (1,1)) = 1$.

\subsection{Randomized (mixed) strategies}
Not Pure strategy s, but distr D. Risk neutral $p_{i}$ maximize $u_{i}(D) = E_{s \distr D}[u_{i}(s)]$, with $Pr_{s \distr D}(s) = \prod_{i} Pr_{s_{i} \distr D_{i}}(s_{i})$.

D or $\set{D_{i}}$ is mixed strategy Nash equilib if $\forall i, D': u_{i}(D) \geq u_{i}(D'_{i}, D_{-i})$. (Check) Eg: Matching pennies. Generalizes pure strategy equilib.

\subsubsection{Matching pennies} $C = \mat{(1, -1) & (-1,1)\\(-1,1) & (1, -1)}$. A 0 sum game; so $p_{i}$ selects strategy independently. No stable s; so, $p_{1}$ randomizes $s_{1}$ to thwart 2.

\subsection{Existance of Equilibria}
(Nash) Any game with $|P|, |S_{i}|$ finite, $\exists$ mixed strategy Nash equilib. \why

Some games don't have Nash equilibrium.

\subsection{Properties}
If $D_{i}$ part of Nash equilibrium,\\
 every $t \in D_{i}$ is a best response to $D_{-i}$: $E_{D_{-i}}[t, D_{i}]$ is maximum: else there could've been 0 wt on t.

\subsection{Time Complexity}
Finding Nash equilibria is PPAD complete.

Games representable by digraphs with indegree, outdegree $\leq 1$; problem is to find source or sink other than a 'standard source'. Like Lemke - Howson polytope.

\tbc

\subsection{eps Nash equilib}
A special case: $\forall i, D': u_{i}(D) \geq u_{i}(D'_{i}, D_{-i}) - \eps$

\section{Correlated equilibrium D}
(Aumann). Coordinator has distr D, samples s from D, tells each $p_{i}$ its $s_{i}$. $p_{i}$ not told $s_{j}$, but knows it is correlated to $s_{i}$; so knows all $Pr(s_{-i}|s_{i})$. D known to every $p_{i}$. D is correlated equilib if it is not in any $p_{i}$'s interest to deviate from s, assuming other $p_{i}$ follow instructions: \\
$E_{s_{-i} \distr D|s_{i}} [u_{i}(s_{i}, s_{-i})] \geq E_{s_{-i}\distr D|s_{i}} [u_{i}(s'_{i}, s_{-i})] $.

Mixed strategy Nash equilibrium is the special case where $D_{i}$ are independently randomized (with diff coins).

Not well motivated in some games.

Coordinator picks correlated equilibrium by optimizing some fn (Eg: total payoff or avg payoff).

\subsection{Regret defn}
$f_{i}:S_{i} \to S_{i}$, regret $r_{i}(s,f) = u_{i}(f_{i}(s_{i}), s_{-i}) - u_{i}(s)$:\\
 $E_{s \distr D}[r_{i}(s,f_{i})] \geq 0$.

\subsection{eps correlated equilibrium}
$E_{s \distr D}[r_{i}(s,f_{i})] \leq \eps$.

\subsection{Traffic light/ Chicken} $C = \mat{(-100, -100) & (1,0)\\(0,1) & (0, 0)}$. s = (1, 2) and (2, 1) stable; so coordinator picks one randomly. This correlation increases payoff as the low expected utility mixed strategy $D_{i} = (101^{-1}, 1-101^{-1})$ is avoided.

\subsection{Reduction to LP}
Unknowns: concatenation of vectors $\set{D_{i}}$. If n players, m strategies each, mn unknowns. Make inequalities: $U_{i}(D_{i}, D_{-i}) \geq U_{i}(D_{i}', D_{-i})$; $\norm{D_{i}}_{1} = 1$; $D_{i} \geq 0$.

\tbc

\subsection{Time Complexity}
Correlated equilibria form a convex set; so if game specified explicitly, can find one in polynomial time if matrix U given. But finding optimal correlated equilibrium is hard. \tbc

\chapter{Games: classes}
\section{2 player games}
Aka bimatrix game. Row and column players: $p_{r}, p_{c}$; their Prob distr over $S_r$ and $S_{c}$ as vectors :$D_{r}, D_{c}$. Utility matrix wrt $p_{r}$ and $p_{c}$: R, C.

\subsection{2 - Player 0 sum games}
Utility matrix $A_{i,j} = u_{r}(..)$. (Nash) Eg: Matching pennies.

Value paid by $p_{c}$ to $p_{r}$: $v_{r} = D_{r}^{*} AD_{c}$.

Knowing $D_{r}$, $p_{c}$ always selects $min(D_{r}^{*}A)$ or finds \\$v_{c} = \min_{k_{1}} \max_{D_{r}} E_{k_{r} \distr D_{r}}[u_{1}(k_{1}, k_{2})] = \min_{k_{1}} \max_{D_{r}} u_{1}(k_{1},D_{r})$. So, best strategy for $p_{r}$ is to maximize (Maxmin) $min(D_{r}^{*}A)$.

\subsubsection{Solution by linear program}
$v_{r} = max\ v; D_{r}>0; \sum_{i} D_{r,i} = 1; (D_{r}^{*}A)_{j} \geq v \forall j$.

Dual of this LP finds $v_{c} = -v_{r}$ and $D_{c}$: aka Minmax / minimax theorem (Neumann).

\subsubsection{Reduction from constant (k) sum 2 player games}
Use a equivalent utility matrix $A_{i,j} = u_{r}(..)$. So, any constant sum game has well defined value: $(v_{r}, k-v_{r})$.

\subsection{Symmetric two player games}
R, C are same. $D_{c}$ is the best response to itself. $D_{c} = D_{r} = D$.

\subsubsection{Finding Nash Equilibrium}
(Lemke - Howson). Consider inequalities $Ax \leq 1$, $x \geq 0$; visualize 2d case like an LP: intersecting halfspaces in a plane with axes $\set{x_{i}}$. $\binom{2n}{n}$ verteces in n-d polytope.

Solution pt must lie in some vertex where payoff is maximum; at solution pt, $\forall i$: $A_{i}x = 1$ and $i \in D$ by prop of Nash equilib, or $x_{i} = 0$ and $i \notin D$. To get the final strategy, take x, and scale it so that $\sum x_{i}=1$. Move from vertex to vertex by relaxing constraints and moving along edges.

Almost always runs in poly time. (Smoothed complexity.)

\subsubsection{Reduction from general 2 player games}
R and C are $m\times n$. Make symmetric game $\mat{0 & R\\C^{T} & 0}$; Find solution distribution $\mat{x\\y}$: now, x and y best responses to each other, so solution to original game.

\section{Games with n turns}
\subsection{Casting as a simultaneous move game}
Each $p_{i}$ picks full strategy from $S_{i}^{n}$. But, $|S_{i}^{n}| = |S_{i}|^{n}$; so games with turns are a compact representation. Extensive form: Game tree with payoffs at leaves.

\subsection{Subgame Perfect Nash Equilibria}
Nash Equilib with notion of order of moves: Strategy should be Nash even if any prefix of the game is already played.

\subsubsection{Ultimatum game}
$p_{1}$, $p_{2}$ split money m; 1 turn each: $p_{1}$ offers n; $p_{2}$ accepts or reject. $p_{2}$'s interest to accept whatever offered. Cast to a simultaneous move game. Many Nash equilibria: If $p_{2}$ rejects if $n < o$, $p_{1}$ must offer o. 1 subgame perfect nash equilib.

\section{Games with partial info about utilities}
Work with beliefs about others' properties and preferences. 

\subsection{Bayesian Games}
Eg: Card game: \\
Only distribution of others' cards known.

\subsubsection{Bayesian first price auction}
$\set{p_{i}}$ have values $\set{v_{i}}$ for item. If all info available; best strategy for $p_{i}$: choose $s_{i}$ = $v_{j}$ next lower to $v_{i}$. If only distribution of $v_{k}$ for other players known, $p_{i}$ bids second E[$v_{j}$ next lowest to $v_{i}|v_{i}$ is max]. \why

\section{Cooperative games}
Groups (G ..) can change strategies jointly.

\subsection{Strong Nash Equilibrium}
In s, $G \subset P$ has \textbf{joint deviation} if $\exists s'_{G}| u_{i}(s) \leq u_{i}(s'_{G}, s_{-A})\forall p_{i} \in G$, and for some $p_{j} \in G, u_{i}(s) < u_{i}(s'_{G}, s_{-A})$.

s is strong Nash if no $G \subset P$ has joint deviation. Similarly, mixed strategy Nash equilibria. Few games have this. Eg: Stable marriage problem.

\subsection{Stable Marriage problem}
\tbc

\subsection{Transferable utility}
\tbc

\section{Market equilibria}
\subsection{Pricing and Allocation game with linear utility}
Aka Fisher's linear case. Bipartite graph G = (I, B) of goods and buyers: edges indicate interest of $b \in B$ in $i \in I$. Quantity of i scaled to 1; price vector for I: p; money vector for B: m. Utility of i for b: $u_{b, i}$.

Want to find optimal p (pricing) and partition items among B: allocation x. Equilibrium properties: all money, goods exhausted.

Best bang per buck for b: $a_{b} = max_{i}\frac{u_{b, i}}{p_{i}}$: a linear function: so 'linear case'.

Primal dual approach: Start with arbit p = 1; find x; find $\set{b}$ with excess money; adjust price; repeat.

Finding x by reduction to network flow problem: add source s and sink t; connect s to all I and t to all B; set capacities of edges in original graph to be $\infty$ and on new edges to match a(i) and m(b); thence find c.

\subsection{Find best allocation}
(Arrow Debreu) Agents come in with goods portfolio, utilities for various goods, leave with goods: money only inbetween. Generalizes Fisher's linear case: .

Auction based approx algorithm solves it: Market clears approximately.

\section{Repeated games with partial info about utilities}
$p_{1}$ in uncertain environment ($p_{-1}$); utilities of $p_{-1}$ not known. Eg: Choosing a route to go to school.

\subsection{Model}
Same game repeated T times; At time t:
$p_{1}$ uses online algorithm H to pick distr $D_{H}^{(t)}$ over $S_{1}$. $p_{1}$ picks action $k_{1}^{(t)}$ from $D_{H}^{(t)}$. Loss/ cost function for $p_{1}$: $c_{1}:\times_{i}S_{i} \to [0,1]$. $c_{1}^{(t)}(k_{1}^{(t)}) \dfn c_{1}(k_{1}^{(t)}, D_{-1}^{(t)})$, $c_{1}(D) \dfn E_{x \distr D}[c_{1}(x)]$.

\subsubsection{Model with full info about costs}
H gets cost vector $c_{1}^{(t)} \in [0,1]^{|S_{1}|}$, pays cost \\
$c_{1}(D_{H}^{(t)}, D_{-1}^{(t)}) = E_{k_{1}^{(t)} \distr D_{H}^{(t)}}[c_{1}(k_{1}^{(t)}, D_{-1}^{(t)})] = E_{k_{1}^{(t)} \distr D_{H}^{(t)}}[c_{1}^{(t)}(k_{1}^{(t)})]$.

Total loss for H: $L_{H}^{(T)} = \sum c_{1}(D_{H}^{(t)}, D_{-1}^{(t)})$.

\subsubsection{Model with partial info about costs}
Aka Multi Armed Bandit (MAB) model.\\
$p_{1}$ (or H) pays cost for $k_{1}^{(t)}$: $c_{1}(k_{1}^{(t)}, D_{-1}^{(t)}) = c_{1}^{(t)}(k_{1}^{(t)})$.

Total loss for H: $L_{H}^{(T)} = \sum c_{1}(k_{1}^{(t)}, D_{-1}^{(t)})$.

\subsubsection{Goal}
Minimize $\frac{L_{?}^{(T)}}{T}$. Maybe other $p_{i}$ do the same. $D_{-1}^{(t)}$ and $c_{1}^{(t)}$ can vary arbitrarily over time; so, model is adversarial.

\subsection{Best response algorithm} For every i: Start with s; suppose $s_{-i}$ fixed, do hill climbing by varying $s_{i}$.

\subsection{Regret analysis}
H incurs loss $L_{H}^{(T)}$; $p_{1}$ sees simple policy $\pi$ would have had much lower loss. Comparison class of orithms G. $\pi$ best algorithm in G: $L_{\pi}^{(T)} = min_{g \in G} L_{g}^{(T)}$. Regret $R_{G} = L_{H}^{(T)} - L_{\pi}^{(T)} = max_{g \in G} (L_{H}^{(T)} - L_{g}^{(T)})$.

\subsubsection{Goal}
Minimize $R_{G}$.

\subsubsection{Regret wrt all policies: Lower bound}
$G_{all} = \set{g: T \to S_{1}}$: $\exists$ sequence of loss vectors $c_{1}^{(t)}$: $R_{G_{all}} \geq T(1-|S_{1}|^{-1})$:

For $k' = argmin_{k_{1}^{(t)}} Pr_{D_{H}^{(t)}}(k_{1}^{(t)})$, $c_{1}^{(t)}(k') = 0$, for others, \\
$c_{1}^{(t)}(k_{1}^{(t)}) = 1$; $\min_{k_{1}^{(t)}} Pr_{D_{H}^{(t)}}(k_{1}^{(t)}) \leq |S_{1}|^{-1}$.

So, must restrict G.

\subsection{External regret}
Aka Combining Expert Advice. $G = \set{i^{T} : i \in S_{1}}$, policies where all $k_{1}^{(t)}$ are the same; $\pi$ is best single action. $L_{\pi}^{(T)} = \sum c_{1}(\pi, D_{-1}^{(t)})$.

If H has low external regret bound: H matches performance of offline algorithm. \why  H comparable to optimal prediction rule from some large hyp class H. \why

\subsubsection{Deterministic Greedy (DG) algorithm}
$S_{1}^{(t-1)} = \set{i: argmin_{i \in S_{1}} L_{i}^{(t-1)}}$,\\
 $k_{1}^{(t)} = \min_{i \in S_{1}^{(t-1)}} i$. $L_{DG}^{(T)} \leq |S_{1}| min_{i}(L_{i}^{(T)}) + (|S_{1}|-1)$: Suppose $c_{1}^{(t)} \in \set{0,1}^{|S_{1}|}$. For every increase in 
$\min_{i} L_{i}^{(t)}$, max loss $|S_{1}|$: For $L_{DG}^{(t)} = L_{DG}^{(t-1)} + 1$ but $\min_{i} L_{i}^{(t)} = \min_{i}L_{i}^{(t-1)}$: $S_{1}^{(t)} \subseteq S_{1}^{(t-1)}$; so count num of times $S_{1}^{(t)}$ can shrink by 1.

\subsubsection{Deterministic algorithm Lower bound} For any deterministic online algorithm H', $\exists$ loss seq where $L_{H'}^{(T)} = T, min_{i \in S_{1}}(L_{i}^{(t)}) \leq \floor{T/|S_{1}|}$: $c_{1}^{(t)}(k_{1}^{(t)}) = 1$, for other i, $c_{1}^{(t)}(i) = 0$; so $L_{H'}^{(T)} = T$; some action used by H' $\leq \floor{T/|S_{1}|}$ times; so $min_{i \in S_{1}}(L_{i}^{(t)}) \leq \floor{T/|S_{1}|}$.

So find rand algorithm.

\subsubsection{Rand Weighted majority algorithm (RWM)}
Suppose $c_{1}^{(t)} \in \set{0,1}^{|S_{1}|}$. Treat $S_{1}$ as a bunch of experts: Want to put as much wt as possible on best expert. Let $|S_{1}| = N$. Init weights $w_{i}^{(1)} = 1$, total wt $W^{(1)} = N$, $Pr_{D_{H}^{(1)}}(i) = N^{-1}$.

If $c_{1}^{(t-1)}(i) = 1$, $w_{i}^{(t)} = w_{i}^{(t)}(1-\eta)$, $Pr_{D_{1}^{(t)}}(i) = \frac{w_{i}^{(t)}}{W^{(t)}}$. \why Like analysis of mistake bound of panel of k experts in colt ref.

For $\eta < 2^{-1}$, $L_{H}^{(T)} \leq (1+ \eta) \min_{i \in S_{1}}L_{i}^{(t)} + \frac{\ln N}{\eta}$. Any time H sees significant expected loss, big drop in W. $W^{(T+1)} \geq max_{i}w_{i}^{(T+1)} = (1-\eta)^{\min_{i}L_{i}^{(T)}}$. \tbc

For $\eta = \min \set{\sqrt{\ln N/ T}, 2^{-1}}$: $L_{H}^{(T)} \leq \min_{i} L_{i}^{(T)} + 2\sqrt{T\ln N}$. If T unknown, use 'guess and double' with const loss in regret. \why

\subsubsection{Polynomial weights algorithm}
Extension of RWM to $c_{1}^{(t)} \in [0,1]^{|S_{1}|}$. Wt update is $w_{i}^{(t)} = w_{i}^{(t)}(1-\eta c^{(t-1)}(i))$. $L_{H}^{(T)} \leq \min_{i} L_{i}^{(T)} + 2\sqrt{T\ln N}$. \why

\subsubsection{Rand algorithm Lower bounds}
If $T <  \log_{2} N$: For any online algorithm H, $\exists$ stochastic generation of losses: $E[L_{H}^{(T)}] = T/2$, but $\min_{i} L_{i}^{(t)} = 0$: at t=1 let N/2 actions get loss 1; at time t: half the actions which had a loss 0 at time t-1 get loss 1; so, probability mass on actions with 0 = $2^{-1}$.

If N=2, $\exists$ stochastic generation of losses: $E[L_{H}^{(T)} - \min_{i} L_{i}^{(T)}] = \Omega(\sqrt{T})$. \why

\subsubsection{Convergence to equilibrium: 2 player constant sum repeated game}
All $p_{i}$ use algorithm H with external regret R; Value of game: $(v_{i})$. Avg loss: $\frac{L_{H}^{(T)}}{T} \leq v_{i}$. \why If $R_{G} = O(\sqrt{T})$, convergence to $v_{i}$.


\subsection{Low external regret algorithm in partial cost info model}
Exploration vs exploitation tradeoff in algorithms.

algorithm MAB: Divide time T into K blocks; in each time block $\tau+1$: explore and get cost vector: execute action i at random time to get vector of RV's: $\hat{c}^{(\tau)}$, also exploit: use distr $D^{(\tau)}$ as strategy; pass $\hat{c}^{(\tau)}$ to full info external regret algorithm F with ext regret $R^{(K)}$ over K time steps; get distr $D^{(\tau + 1)}$ from F.

Max Loss during exploration steps: NK. RV for total loss of F over K time blocks: $\hat{L}_{F}^{(T)} = \frac{T}{K}\sum_{\tau}p^{\tau}c^{\tau} \leq \frac{T}{K}(min_{i} \hat{L}_{i}^{(K)} + R^{(K)}$. Taking expectation, $L_{MAB}^{(T)} = E[\hat{L}_{MAB}^{(T)}]= E[\hat{L}_{F}^{(T)} + NK] \leq \frac{T}{K}(E[min_{i} \hat{L}_{i}^{(K)}] + R^{(K)}) + NK \leq \frac{T}{K}(min_{i} E[\hat{L}_{i}^{(K)}] + R^{(K)}) + NK \leq min_{i}L_{i}^{(T)} + \frac{T}{K}R^{(K)} + NK$.

Using the $O(\sqrt{K\log N})$ algorithm, with $K=(\frac{T}{K}R_{K})$, we get $L_{MAB}^{(T)} \leq min_{i}L_{i}^{(T)} + O(T^{2/3}N^{1/3}\log N)$.

\subsection{Swap regret}
Comparison algorithm (H,g) is H with some swap fn $g:S_{1} \to S_{1}$.

\subsubsection{Internal regret}
A special case: Swap every occurance of action $b_{1}$ with action $b_{2}$. Modification fn: $switch_{i}(k_{i},b_{1}, b_{2}) = k_{i}$ except $switch_{i}(b_{1},b_{1}, b_{2}) = b_{1}$.

\subsubsection{Low Internal regret algorithm using external regret minimization algorithms}
Let $N=|S_{i}|$; $(A_{1}, .., A_{N})$ copies of algorithm with external regret bound R. Master algorithm H gets from $A_{i}$ distr $q_{i}^{(t)}$ over $S_{i}$; makes matrix $Q^{(t)}$ with $q_{i}^{(t)}$ as rows; finds stationary distr vector $p^{(t)} = p^{(t)}Q^{(t)}$: Picking $k_{i} \in S_{i}$ same as picking $A_{j}$ first, then picking $k_{i} \in S_{i}$; gets loss vector $c^{(t)}$; gives $A_{i}$ loss vector $p_{i}^{(t)}c^{(t)}$.

$\forall j: L_{A_{i}} = \sum_{t} p_{i}^{(t)}\dprod{c^{(t)},q_{i}^{(t)}} \leq \sum_{t} p_{i}^{(t)}c_{j}^{(t)} + R$. Also, Sum of percieved losses = actual loss. So, for any swap fn g, $L_{H}^{T}\leq \sum_{i}\sum_{t} p_{i}^{(t)}c_{g(i)}^{(t)} + NR = L_{F,g}^{(T)} + NR$.

Thence, using polynomial weights algorithm, swap regret bound\\ $O(\sqrt{|S_{1}| T \log |S_{1}|})$.

\subsubsection{Convergence to Correlated equilibrium}
Every $p_{i}$ uses strategy with swap regret $\leq R$: then empirical distr Q over $\times_{i} S_{i}$ is an $\frac{R}{T}$ correlated equilibrium. $R = L_{H}^{(T)} - L_{H,g}^{(T)} = \sum_{t} E_{s^{(t)} \distr D^{(t)}}[r_{i}(s,g)] = T E_{s \distr Q}[r_{i}(s,g)]$.

Convergence if all players have sublinear swap regret.

\subsubsection{Frequency of dominated strategies}
$p_{1}$ uses algorithm with swap regret R over time T; w: avg over T of prob weight on $\eps$ dominated strategies; so $\eps wT \leq R$; so $w \leq \frac{R}{T\eps}$.

If algorithm minimizes external regret using polynomial weights algorithm, freq of doing dominated actions tends to 0.

\chapter{Mechanism design}
\section{Mechanism design}
Engineer / implement social choice function. Mech design in making protocols for computer network problems: algorithmorithmic mechanism design. Electronic market design: mech design in electronic markets.

Set of alternatives A. L: set of all linear orders over A. Preference order of $p_{i}: >_{i}$.

\subsection{Social welfare function}
$F:L^{n} \to L$.

\subsubsection{Properties}
Unanimity: $F(<^{n}) = <$. Dictatorship. Independence of irrelevant attributes: $F((<_{i}))$ between alternatives $a_{1}$ and $a_{2}$ depends only on $\set{a_{1}<_{i} a_{2}}$.

(Arrow): Every social welfare fn over A with $|A|>2$ that satisfies unanimity and independence of irrelevant alternatives is a dictatorship.

\subsection{Social choice function}
$f:L^{n} \to A$. Eg: Elections; markets: allocation of goods and money; auctions; government policy; runs of network protocols.

\subsubsection{Voting methods}
Ways of finding outcome of multicandidate ($>2$) elections.

Majority vote won't work: Condorcet paradox. Strategic voting: $p_{i}$ lies about his preference in order to get some one to win.

\subsubsection{Strategic manipulation}
Incentive compatible mechanism: No $p_{i}$ can be better off by lying about his prefs.

\subsection{VCG mechanism}
Maximizes social welfare: $\sum_{i} u_{i}(a)$. A general scheme: fix specific functions to suit need.

\section{Auctions}
1st price auction. 2nd price auction. Generalized 2nd price auction: winner pays a price between 1st price and 2nd price.

\subsection{Combinatorial auctions}
Each $p_{i}$ has a utility for every subset of goods: $u_{i}(S): S \subseteq A$.

\subsection{Search auctions}
How to order the list of ads? Payment per click $u_{i}$. Clicks $p_{i}$ get: $n_{i}$. Find $argmax_{i} u_{i}$. Or find $argmax_{i} n_{i}u_{i}$.

\tbc

\section{Prediction markets}
Markets whose purpose is to find a probability. People who buy low and sell high are rewarded for improving the prediction, those who buy high and sell low are punished for degrading it.

\bibliographystyle{plain}
\bibliography{gameTheory}

\end{document}
