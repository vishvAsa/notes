+++
title = "Twitter-files"
+++

Source: [TW](https://threadreaderapp.com/thread/1598822959866683394.html)


Thread: THE TWITTER FILES

## Background
What you’re about to read is the first installment in a series, based upon thousands of internal documents obtained by sources at Twitter. The “Twitter Files” tell an incredible story from inside one of the world’s largest and most influential social media platforms. It is a Frankensteinian tale of a human-built mechanism grown out the control of its designer.

Twitter in its conception was a brilliant tool for enabling instant mass communication, making a true real-time global conversation possible for the first time. In an early conception, Twitter more than lived up to its mission statement, giving people “the power to create and share ideas and information instantly, without barriers.” As time progressed, however, the company was slowly forced to add those barriers. Some of the first tools for controlling speech were designed to combat the likes of spam and financial fraudsters. Slowly, over time, Twitter staff and executives began to find more and more uses for these tools. Outsiders began petitioning the company to manipulate speech as well: first a little, then more often, then constantly.

By 2020, requests from connected actors to delete tweets were routine. One executive would write to another: “More to review from the Biden team.” The reply would come back: “Handled.” Image Celebrities and unknowns alike could be removed or reviewed at the behest of a political party: Image. Both parties had access to these tools. For instance, in 2020, requests from both the Trump White House and the Biden campaign were received and honored. However: This system wasn't balanced. It was based on contacts. Because Twitter was and is overwhelmingly staffed by people of one political orientation, there were more channels, more ways to complain, open to the left (well, Democrats) than the right. https://www.opensecrets.org/orgs/twitter/summary?id=D000067113 The resulting slant in content moderation decisions is visible in the documents you’re about to read. However, it’s also the assessment of multiple current and former high-level executives.

Okay, there was more throat-clearing about the process, but screw it, let's jump forward.

## Biden Laptop Story
The Twitter Files, Part One: How and Why Twitter Blocked the Hunter Biden Laptop Story. 

On October 14, 2020, the New York Post published BIDEN SECRET EMAILS, an expose based on the contents of Hunter Biden’s abandoned laptop:
    Smoking-gun email reveals how Hunter Biden introduced Ukrainian businessman to VP dad. [NYT](https://nypost.com/2020/10/14/email-reveals-how-hunter-biden-introduced-ukrainian-biz-man-to-dad/) Twitter took extraordinary steps to suppress the story, removing links and posting warnings that it may be “unsafe.” They even blocked its transmission via direct message, a tool hitherto reserved for extreme cases, e.g. child pornography. White House spokeswoman Kaleigh McEnany was locked out of her account for tweeting about the story, prompting a furious letter from Trump campaign staffer Mike Hahn, who seethed: “At least pretend to care for the next 20 days.” This led public policy executive Caroline Strom to send out a polite WTF query. Several employees noted that there was tension between the comms/policy teams, who had little/less control over moderation, and the safety/trust teams: Image. Strom’s note returned the answer that the laptop story had been removed for violation of the company’s “hacked materials” policy. [Link](https://web.archive.org/web/20190717143909/https://help.twitter.com/en/rules-and-policies/hacked-materials)
    
Although several sources recalled hearing about a “general” warning from federal law enforcement that summer about possible foreign hacks, there’s no evidence - that I've seen - of any government involvement in the laptop story. In fact, that might have been the problem... The decision was made at the highest levels of the company, but without the knowledge of CEO Jack Dorsey, with former head of legal, policy and trust Vijaya Gadde playing a key role. “They just freelanced it,” is how one former employee characterized the decision. “Hacking was the excuse, but within a few hours, pretty much everyone realized that wasn’t going to hold. But no one had the guts to reverse it.” You can see the confusion in the following lengthy exchange, which ends up including Gadde and former Trust and safety chief Yoel Roth. Comms official Trenton Kennedy writes, “I'm struggling to understand the policy basis for marking this as unsafe”.  By this point “everyone knew this was fucked,” said one former employee, but the response was essentially to err on the side of… continuing to err. Former VP of Global Comms Brandon Borrman asks, “Can we truthfully claim that this is part of the policy?” To which former Deputy General Counsel Jim Baker again seems to advise staying the non-course, because “caution is warranted”.

A fundamental problem with tech companies and content moderation: many people in charge of speech know/care little about speech, and have to be told the basics by outsiders. To wit: In one humorous exchange on day 1, Democratic congressman Ro Khanna reaches out to Gadde to gently suggest she hop on the phone to talk about the “backlash re speech.” Khanna was the only Democratic official I could find in the files who expressed concern.  Gadde replies quickly, immediately diving into the weeds of Twitter policy, unaware Khanna is more worried about the Bill of Rights. Khanna tries to reroute the conversation to the First Amendment, mention of which is generally hard to find in the files.

Within a day, head of Public Policy Lauren Culbertson receives a ghastly letter/report from Carl Szabo of the research firm NetChoice, which had already polled 12 members of congress – 9 Rs and 3 Democrats, from “the House Judiciary Committee to Rep. Judy Chu’s office.” NetChoice lets Twitter know a “blood bath” awaits in upcoming Hill hearings, with members saying it's a "tipping point," complaining tech has “grown so big that they can’t even regulate themselves, so government may need to intervene.” Szabo reports to Twitter that some Hill figures are characterizing the laptop story as “tech’s Access Hollywood moment”: 


Twitter files continued: "THE FIRST AMENDMENT ISN’T ABSOLUTE”

Szabo’s letter contains chilling passages relaying Democratic lawmakers’ attitudes. They want “more” moderation, and as for the Bill of Rights, it's "not absolute". An amazing subplot of the Twitter/Hunter Biden laptop affair was how much was done without the knowledge of CEO Jack Dorsey, and how long it took for the situation to get "unfucked" (as one ex-employee put it) even after Dorsey jumped in.

While reviewing Gadde's emails, I saw a familiar name - my own. Dorsey sent her a copy of my Substack article blasting the incident Image
    There are multiple instances in the files of Dorsey intervening to question suspensions and other moderation actions, for accounts across the political spectrum. The problem with the "hacked materials" ruling, several sources said, was that this normally required an official/law enforcement finding of a hack. But such a finding never appears throughout what one executive describes as a "whirlwind" 24-hour, company-wide mess. 

It's been a whirlwind 96 hours for me, too. There is much more to come, including answers to questions about issues like shadow-banning, boosting, follower counts, the fate of various individual accounts, and more. These issues are not limited to the political right. 

Source: [TW](https://threadreaderapp.com/thread/1601007575633305600.html)

THREAD: THE TWITTER FILES PART TWO.

TWITTER’S SECRET BLACKLISTS.

A new #TwitterFiles investigation reveals that teams of Twitter employees build blacklists, prevent disfavored tweets from trending, and actively limit the visibility of entire accounts or even trending topics—all in secret, without informing users. 

Twitter once had a mission “to give everyone the power to create and share ideas and information instantly, without barriers.” Along the way, barriers nevertheless were erected. 

- Take, for example, Stanford’s Dr. Jay Bhattacharya (@DrJBhattacharya) who argued that Covid lockdowns would harm children. Twitter secretly placed him on a “Trends Blacklist,” which prevented his tweets from trending. Image
- Or consider the popular right-wing talk show host, Dan Bongino (@dbongino), who at one point was slapped with a “Search Blacklist.” 
- Twitter set the account of conservative activist Charlie Kirk (@charliekirk11) to “Do Not Amplify.” 

Twitter denied that it does such things. In 2018, Twitter's Vijaya Gadde (then Head of Legal Policy and Trust) and Kayvon Beykpour (Head of Product) said: “We do not shadow ban.” They added: “And we certainly don’t shadow ban based on political viewpoints or ideology.” What many people call “shadow banning,” Twitter executives and employees call “Visibility Filtering” or “VF.” Multiple high-level sources confirmed its meaning. “Think about visibility filtering as being a way for us to suppress what people see to different levels. It’s a very powerful tool,” one senior Twitter employee told us. “VF” refers to Twitter’s control over user visibility. It used VF to block searches of individual users; to limit the scope of a particular tweet’s discoverability; to block select users’ posts from ever appearing on the “trending” page; and from inclusion in hashtag searches. All without users’ knowledge. “We control visibility quite a bit. And we control the amplification of your content quite a bit. And normal people do not know how much we do,” one Twitter engineer told us. Two additional Twitter employees confirmed.

The group that decided whether to limit the reach of certain users was the Strategic Response Team - Global Escalation Team, or SRT-GET. It often handled up to 200 "cases" a day. But there existed a level beyond official ticketing, beyond the rank-and-file moderators following the company’s policy on paper. That is the “Site Integrity Policy, Policy Escalation Support,” known as “SIP-PES.” This secret group included Head of Legal, Policy, and Trust (Vijaya Gadde), the Global Head of Trust & Safety (Yoel Roth), subsequent CEOs Jack Dorsey and Parag Agrawal, and others. This is where the biggest, most politically sensitive decisions got made. “Think high follower account, controversial,” another Twitter employee told us. For these “there would be no ticket or anything.”

One of the accounts that rose to this level of scrutiny was @libsoftiktok—an account that was on the “Trends Blacklist” and was designated as “Do Not Take Action on User Without Consulting With SIP-PES.” The account—which Chaya Raichik began in November 2020 and now boasts over 1.4 million followers—was subjected to six suspensions in 2022 alone, Raichik says. Each time, Raichik was blocked from posting for as long as a week. Twitter repeatedly informed Raichik that she had been suspended for violating Twitter’s policy against “hateful conduct.” But in an internal SIP-PES memo from October 2022, after her seventh suspension, the committee acknowledged that “LTT has not directly engaged in behavior violative of the Hateful Conduct policy."  The committee justified her suspensions internally by claiming her posts encouraged online harassment of “hospitals and medical providers” by insinuating “that gender-affirming healthcare is equivalent to child abuse or grooming.”

Compare this to what happened when Raichik herself was doxxed on November 21, 2022. A photo of her home with her address was posted in a tweet that has garnered more than 10,000 likes. When Raichik told Twitter that her address had been disseminated she says Twitter Support responded with this message: "We reviewed the reported content, and didn't find it to be in violation of the Twitter rules." No action was taken. The doxxing tweet is still up. 

In internal Slack messages, Twitter employees spoke of using technicalities to restrict the visibility of tweets and subjects. Here’s Yoel Roth, Twitter’s then Global Head of Trust & Safety, in a direct message to a colleague in early 2021: Image. Six days later, in a direct message with an employee on the Health, Misinformation, Privacy, and Identity research team, Roth requested more research to support expanding “non-removal policy interventions like disabling engagements and deamplification/visibility filtering.” Roth wrote: “The hypothesis underlying much of what we’ve implemented is that if exposure to, e.g., misinformation directly causes harm, we should use remediations that reduce exposure, and limiting the spread/virality of content is a good way to do that.” He added: “We got Jack on board with implementing this for civic integrity in the near term, but we’re going to need to make a more robust case to get this into our repertoire of policy remediations – especially for other policy domains.”

There is more to come on this story, which was reported by @AbigailShrier @ShellenbergerMD @NellieBowles @IsaacGrafstein and the team The Free Press @TheFP. Keep up with this unfolding story here and at our brand new website: thefp.com. The authors have broad and expanding access to Twitter’s files. The only condition we agreed to was that the material would first be published on Twitter.

We're just getting started on our reporting. Documents cannot tell the whole story here. A big thank you to everyone who has spoken to us so far. If you are a current or former Twitter employee, we'd love to hear from you. Please write to: tips@thefp.com . Watch @mtaibbi for the next installment. 
