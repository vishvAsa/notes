<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>&#43;Models on Vishvas&#39;s notes</title>
    <link>file:///storage/emulated/0/notesData/notes/biology/society/language/models/</link>
    <description>Recent content in &#43;Models on Vishvas&#39;s notes</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    
	<atom:link href="file:///storage/emulated/0/notesData/notes/biology/society/language/models/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Communication</title>
      <link>file:///storage/emulated/0/notesData/notes/biology/society/language/models/communication/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>file:///storage/emulated/0/notesData/notes/biology/society/language/models/communication/</guid>
      <description>Speech generation Speech generation involves the following tasks:
  Intention: Generating the thought to be spoken in the internal language of logic.
  Generation: Translating the logical language into natural language.
  Synthesis: Speaking the generated words with appropriate stresses, accents etc..
  Speech comprehension Tasks Speech comprehension involves the following tasks:
  Perception: Translating the sounds heard or symbols seen to words or tokens; this is akin to lexical analysis by compilers.</description>
    </item>
    
    <item>
      <title>Language</title>
      <link>file:///storage/emulated/0/notesData/notes/biology/society/language/models/language/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>file:///storage/emulated/0/notesData/notes/biology/society/language/models/language/</guid>
      <description>Definition A language model models the probability of every possible string being a sentence spoken by a human.
Applications Language models are useful in speech recognition, machine translation, handwriting recognition, machine translation, speech generation, (context sensitive) spelling correction etc..
Multi-set of words model This very simple model ignores word order - a very important information. It models $Pr(w_{1:m}) = \prod Pr(w_i)$; and the parameters of this model - the word occurrence probabilities - are easily estimated; and it is known to follow the Zipf&amp;rsquo;s law, which is a heavy tailed distribution.</description>
    </item>
    
  </channel>
</rss>