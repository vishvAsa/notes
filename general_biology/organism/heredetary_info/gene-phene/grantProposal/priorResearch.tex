A promising approach to disease modeling is through data analysis, in particular, analysis of disease-gene, phenotype-gene as well as gene-gene networks. The proposed research will involve the development of novel mathematical techniques that have their roots in diverse areas such as graph theory, network analysis, graphical models and compressive sensing. In this section, we describe prior and related work. 

Traditionally, gene-disease link identification has been done using Genome-Wide Association studies (GWA studies), which became truly feasible only after the completion of the Human Genome Project\cite{HumanGenomeProjectBook} in 2003 and the International HapMap Project\cite{HaplotypeLiu} in 2005. To carry out a genome-wide association study\cite{GWAurl, GWASZhang, GWASLi}, researchers use two sets of people: people with the disease being studied, and similar people without the disease. Researchers obtain DNA from each participant, usually by drawing a blood sample. Each person's complete set of DNA, or genome, is then purified from the blood, and specially designed machines then survey each person's genome for single nucleotide polymorphisms, or SNPs. If certain genetic variations are found to be significantly more frequent in people with the disease compared to people without disease, the variations are said to be "associated" with the disease.

GWA studies tend to be relatively slow and laborious. They search the entire genome for associations rather than focusing on small candidate areas. Besides this, there are other weaknesses of this approach. GWA studies often identify common variants of genes which tag along with rare variants of other genes which actually play a role in the disease as risk factors. The common variants identified by GWAS contribute little value to individual disease risk predictions over existing clinical markers for most common diseases. Also, knowledge of the rare variants of genes which actually play a role in the disease is essential for designing drugs. The gene-disease link identification approach proposed in this proposal attempts to rectify these drawbacks.

An approach to model human diseases by identifying  the ``closest'' orthologous phenotypes\footnote{phenotypes which are formed from orthologous genes in two given species} from various other species has been pioneered by Prof. Ed Marcotte of UT Austin \cite{McGaryOrthologousPhenotypes}. The method developed in \cite{McGaryOrthologousPhenotypes, McGarySI} uses a naive Bayes classifier to determine the probability of a gene influencing a given disease, given the evidence of expression of the gene in orthologous phenotypes of other organisms. The ``closest'' phenotypes are determined using a distance function based on the hypergeometric probability of observing the overlap of genes between two given phenotypes by chance. The preliminary results in \cite{McGaryOrthologousPhenotypes} indicate great promise in predicting genes that are responsible for human diseases. Marcotte's lab has already been able to predict novel genes associated with diseases, for example, a yeast model for angiogenesis effects, a worm model for breast cancer, mouse models of autism, and a plant model for the neural crest defects associated with Waardenberg syndrome, among others\cite{McGaryOrthologousPhenotypes}. However, they have barely scratched the surface of this promising line of research - better computational models are expected to have a significant impact on the accuracy of the predictions. As preliminary experiments described in Section \ref{sec:preliminaryResearch} indicate, application of ideas from social network analysis, recommender systems and matrix completion hold great promise in significantly furthering the state of the art in gene-disease link identification.

Research on large, complex networks and their properties has attracted attention from physicists, computer scientists, biologists, and social scientists \cite{internet, smallworldPNAS, mat1,mat2, nn, collab}. Networks are highly dynamic objects; they grow and change quickly over time through the addition of new edges, signifying the appearance of new interactions in the underlying structure. Understanding the mechanisms by which they evolve and discovering the underlying structure are  fundamental questions that are still not well understood. Particularly relevant to this proposal is the network analysis task of \emph{link prediction}. Indeed, the task of identifying links between genes and diseases may be cast as one of link prediction, when the interactions between genes and phenotypes are modelled as a graph.

The link prediction model tries to predict the presence or absence of a link between a certain pair of nodes, based on observed links in other parts of the networks. Typically this prediction is performed using features intrinsic to the network itself. Commonly used models include the Katz measure~\cite{Katz}, rooted PageRank~\cite{KleinbergLinkPred}, escape probability~\cite{1281272}, see~\cite{KleinbergLinkPred} for a comprehensive empirical comparison. In practice, in addition to the links between nodes, we also have extra information, including the properties of nodes or auxiliary links between nodes from different sources. Preliminary research in using such side information has been conducted in Prof. Dhillon's lab over the past year \cite{vasukiNatarajan, berkantSupervised}. As part of the goal of this proposal, we plan to investigate algorithms that make use of various forms of such side information to boost the prediction accuracy in the gene-phenotype network.

The gene-disease link identification problem can also be viewed as an item recommendation problem, where the task is to identify or recommend genes relevant to a particular phenotype. Recommendation systems\cite{ResnickRecommender,BurkeRecommender,SandvigRecommender,DemirizRecommender,GunawardanaRecommender,TikkRecommender,DBLP:conf/recsys/ViappianiB09,DBLP:conf/recsys/ParkT08,itemRecommendation} have attracted great deal of attention in recent years, due to their important commercial applications. Consider, for example, the famous example of the Netflix problem \cite{yehudaMillionDollar}, where the problem is to identify movies of interest to users of the movie rental service, Netflix, given some of the movies a user has watched in the past. The process of making such item-recommendations in the absence of side information, is called collaborative filtering. Even though there is a large body of literature addressing this problem \cite{yehudaMillionDollar, GoogleCFLatent, BillsusCollaborative,GeorgeCollaborative,LindenCollaborative,SarwarCollaborative,oneClassCollaborative}, the problem of using side information, such as relationships between various users and relationships among items, is just beginning to be tackled \cite{GoogleCCF}.

While combinations of recommendation algorithms have proven to be more powerful than using a single recommendation algorithm, identifying good recommendation algorithms which can be used in such predictor-ensembles is an important task. Particularly successful algorithms are based on posing the recommendation problem as a matrix completion problem or as a low rank matrix approximation problem. Matrix completion has been an active area of research and several impressive theoretical results guaranteeing exact recovery have recently been obtained, that generalize results from the area of compressive sensing\cite{DBLP:journals/tit/CandesT05,candesRPCA09,candesRecht08,Tsaig06compressedsensing, PrateekSVP, Baraniuk07compressivesensing, mekaMatrixCompletion,KeshavanMatrixCompletion,RechtMatrixCompletion}.