<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>&#43;Complexity on Vishvas&#39;s notes</title>
    <link>file:///storage/emulated/0/notesData/notes/computing/colt/complexity/</link>
    <description>Recent content in &#43;Complexity on Vishvas&#39;s notes</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    
	<atom:link href="file:///storage/emulated/0/notesData/notes/computing/colt/complexity/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Active learning</title>
      <link>file:///storage/emulated/0/notesData/notes/computing/colt/complexity/Active_learning/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>file:///storage/emulated/0/notesData/notes/computing/colt/complexity/Active_learning/</guid>
      <description>mq only model Finite attributes around. Exact learning using only membership queries (mq). Scenario: Robot explores labyrinth.
Constrained instance oracle for f: Takes partial assignment P and prediction b, if possible, extends P to a complete assignment A such that f(A) = 1-b.
Lower bound: By information theory, atleast \(\log |C|\) mq needed.
ae learning Monotone functions Learnability in mq only model does not always imply ae learnability for deterministic algorithms.</description>
    </item>
    
    <item>
      <title>Learnability despite noise</title>
      <link>file:///storage/emulated/0/notesData/notes/computing/colt/complexity/Learnability_despite_noise/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>file:///storage/emulated/0/notesData/notes/computing/colt/complexity/Learnability_despite_noise/</guid>
      <description>Classification noise Random noise vs Adversarial noise. Getting (x, l) instead of (x, c(x)).
Malicious noise: both x and c(x) corrupted.
Random Classification noise model Uniform noise \(\eta \leq \eta_{0} \in [0,.5)\); \(L\) given \(\eta_{0}\), also polynomial in \(\frac{1}{.5-\eta_{0}}\).
Statistical Query (SQ) learning model (Kearns). A \textbf{statistical query} (criterion, tolerance) = \((\chi, \tau)\) yields probability \(Pr_{x}(\chi)\) or \(E_{x}(\chi)\) of \(\chi\) over examples. \(\chi\) efficiently evaluatable, \(\tau\) not very tiny. \(L\) forms h using only statistical queries.</description>
    </item>
    
    <item>
      <title>Learning the best hypothesis</title>
      <link>file:///storage/emulated/0/notesData/notes/computing/colt/complexity/Learning_the_best_hypothesis/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>file:///storage/emulated/0/notesData/notes/computing/colt/complexity/Learning_the_best_hypothesis/</guid>
      <description>Aka Agnostic learning model.
The goal Let error in best fit, \(\eta = min_{c \in C} Pr(c(x) \neq l)\). Given \(\del, \eps\); get h where \(Pr(h(x) \neq l) \leq \eta + \eps\).
Underlying distribution Naught known to the algorithm about process generating data; just asking for approximately best fit or \(\eps\) approx of the \(c\) with error \(\eta\). Even same example \(s\) can have different label \(l\) at different times: this could either be because of noise/ corruption of the label or because of the underlying distribution.</description>
    </item>
    
    <item>
      <title>Mistake bounded models</title>
      <link>file:///storage/emulated/0/notesData/notes/computing/colt/complexity/Mistake_bounded_models/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>file:///storage/emulated/0/notesData/notes/computing/colt/complexity/Mistake_bounded_models/</guid>
      <description>Mistake bound (MB) learning model Problem \(L\) learns \(C\): \(L\) given sample point \(x\), returns h(x), told if it is correct; this is repeated; has mistake bound \(m\) (over any sequence of examples).
Adversarial nature and randomization The mistake bounded model is adversarial in nature - we are concerned with the number of mistakes made in the worst case. So, randomization helps : the adversary decides on the input before the coin is tossed, so not knowing the algorithm&amp;rsquo;s output, its attempts to cause mistakes are less successful.</description>
    </item>
    
    <item>
      <title>PAC learning</title>
      <link>file:///storage/emulated/0/notesData/notes/computing/colt/complexity/PAC_learning/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>file:///storage/emulated/0/notesData/notes/computing/colt/complexity/PAC_learning/</guid>
      <description>The goal Distribution and the oracle Distribution agnostic. Assumption: training distribution = testing distribution. 2 Oracle PAC model variant: Algorithm can use both \(D^{+}{c}\) and \(D^{-}{c}\), \(error \leq \eps\) wrt both.
EQ oracle can be simulated by the EX oracle.
Strong PAC learning Given \(\eps, \del, C\), we want to find \(h \in C\) such that, with probability \(1 - \gd\), \(Pr(c(x) \neq h(x)) \leq \eps\).
Weak PAC learning algorithm p, q polynomials; \(\eps \leq 2^{-1}-g = 2^{-1}-\frac{1}{p(n, size(c))}\), \(\del \leq \frac{1}{q(n, size(c))}\).</description>
    </item>
    
  </channel>
</rss>