<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>&#43;CPU on Vishvas&#39;s notes</title>
    <link>https://vishvAsa.github.io/notes/computing/computer_architecture/cpu/</link>
    <description>Recent content in &#43;CPU on Vishvas&#39;s notes</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <atom:link href="https://vishvAsa.github.io/notes/computing/computer_architecture/cpu/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Graphics processing (GPU)</title>
      <link>https://vishvAsa.github.io/notes/computing/computer_architecture/cpu/Graphics_processing_GPU/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://vishvAsa.github.io/notes/computing/computer_architecture/cpu/Graphics_processing_GPU/</guid>
      <description>&lt;p&gt;GPU&amp;rsquo;s, implementing common graphics tasks on specialized circuits, speed up display tasks involved in personal computing.&lt;/p&gt;&#xA;&lt;h2 id=&#34;high-data-parallelism&#34;&gt;High data parallelism&lt;/h2&gt;&#xA;&lt;p&gt;GPU&amp;rsquo;s follow a dataflow architecture: Highly pipelined, parallel with many small cores - much more than CPU&amp;rsquo;s. Usually, these parallel cores are divided profitably and easily: Like one core for a bunch of pixels.&lt;/p&gt;&#xA;&lt;p&gt;Earlier these processing elements were specialized for graphics, now these shaders are more programmable.&lt;/p&gt;&#xA;&lt;h2 id=&#34;for-general-computing&#34;&gt;For general computing&lt;/h2&gt;&#xA;&lt;p&gt;With GPGPU, one would Disguise program as geometry computation. Now, can do such computation directly: eg: NVidia CUDA.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Motherboard</title>
      <link>https://vishvAsa.github.io/notes/computing/computer_architecture/cpu/Motherboard/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://vishvAsa.github.io/notes/computing/computer_architecture/cpu/Motherboard/</guid>
      <description>&lt;p&gt;A mother-board provides suitable interface and circuits for communication and power-supply among/ for the processor, working memory, I/O, persistent storage etc..&lt;/p&gt;&#xA;&lt;p&gt;The motherboard contains the BIOS memory where the boot-program is located.&lt;/p&gt;&#xA;&lt;h2 id=&#34;system-bus&#34;&gt;System Bus&lt;/h2&gt;&#xA;&lt;p&gt;The system bus is a common communication channel on the motherboard. It has many different dedicated branches for communication between the different components and certain controller hubs.&lt;/p&gt;&#xA;&lt;p&gt;A computer bus operating with \textit{double data rate} transfers data on both the rising and falling edges of the clock signal.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Processor</title>
      <link>https://vishvAsa.github.io/notes/computing/computer_architecture/cpu/Processor/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://vishvAsa.github.io/notes/computing/computer_architecture/cpu/Processor/</guid>
      <description>&lt;h2 id=&#34;components&#34;&gt;Components&lt;/h2&gt;&#xA;&lt;p&gt;Every processor consists of an arithmetic and logic unit/ circuit (ALU), a few memory registers with a few layers of cache, memory and graphics controller circuits in order to be able to perform I/O operations and using extended working memory.&lt;/p&gt;&#xA;&lt;h2 id=&#34;tight-knit-parallelism&#34;&gt;Tight knit Parallelism&lt;/h2&gt;&#xA;&lt;h3 id=&#34;multiple-cores&#34;&gt;Multiple cores&lt;/h3&gt;&#xA;&lt;p&gt;Usually multiple cores share memory.&lt;/p&gt;&#xA;&lt;h3 id=&#34;pipelines&#34;&gt;Pipelines&lt;/h3&gt;&#xA;&lt;p&gt;Aka instruction level parallelism.&lt;/p&gt;&#xA;&lt;p&gt;Processing often has pipeline structure; eg: fetch instruction, fetch data, execute instruction, store data. There are usually separate functional units within a single processor which take care of these separate tasks in each clock cycle.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Working Memory</title>
      <link>https://vishvAsa.github.io/notes/computing/computer_architecture/cpu/Working_Memory/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://vishvAsa.github.io/notes/computing/computer_architecture/cpu/Working_Memory/</guid>
      <description>&lt;h2 id=&#34;memory-hierarchy&#34;&gt;Memory hierarchy&lt;/h2&gt;&#xA;&lt;p&gt;Memory access could be 100 times slower than flops: this is an important consideration when optimizing algorithms. Hence, there is a hierarchy of memory:&lt;/p&gt;&#xA;&lt;p&gt;Registers in the processor \(&amp;gt;\) On chip Cache: many layers \(&amp;gt;\) main memory \(&amp;gt;\) secondary memory located on the hard-disk for example.&lt;/p&gt;&#xA;&lt;h2 id=&#34;glossary&#34;&gt;Glossary&lt;/h2&gt;&#xA;&lt;h3 id=&#34;sdram&#34;&gt;SDRAM&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Working memory is capable of random, rather than serial, access.&lt;/li&gt;&#xA;&lt;li&gt;Also, it is dynamic - it retains data only when supplied electricity to periodically refresh its memory.&lt;/li&gt;&#xA;&lt;li&gt;It is commonly Synchronous - synchronized with the system bus.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;dimm&#34;&gt;DIMM&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;UDIMM (unregistered memory) faster than RDIMM (registered memory) but less stable; costs less.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;speed&#34;&gt;Speed&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;For final latency considering data rate, clock rate, latency, see &amp;ldquo;true latency&amp;rdquo; comments below. Actual data transfer speed  = true latency * read width.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;data-rates&#34;&gt;Data rates&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;SDR - Single data rate. 1x signals per clock clycle. 64 bit channel.&lt;/li&gt;&#xA;&lt;li&gt;DDR1 - Double data rate. 2x signals per clock cycle. So, DDR set with max 1600 clock cycles is advertised as DDR 3200. 64 bit channel.&lt;/li&gt;&#xA;&lt;li&gt;DDR2 - Read width (prefetch buffer) double relative to DDR1. 128 bit channel.&lt;/li&gt;&#xA;&lt;li&gt;DDR3 - Read width double relative to DDR2. 256 bit channel.&lt;/li&gt;&#xA;&lt;li&gt;DDR4 - Same read width as DDR3. 256 bit channel. But lower power.&lt;/li&gt;&#xA;&lt;li&gt;DDR5 - Read width double that of DDR4. 512 bit channel.&lt;/li&gt;&#xA;&lt;li&gt;QDR - Quad data rate - 4x signals per clock cycle.&lt;/li&gt;&#xA;&lt;li&gt;RDRAM - failed.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;signal-frequency&#34;&gt;Signal frequency&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Aka module speed.&lt;/li&gt;&#xA;&lt;li&gt;DDR4-3200 RAM has module speed/ advertised frequency 3200MHz (actually 1600 cycles per sec).&lt;/li&gt;&#xA;&lt;li&gt;clock rate (Eg: DDR-333 &amp;gt; DDR-200). DPC4-xxxx denotes clock speed (with the last two digits truncated).&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;latency--cl&#34;&gt;Latency / CL&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;RAM clock cycles (Not advertised frequency!) needed to get data.&lt;/li&gt;&#xA;&lt;li&gt;Example: 16-18-18-38 (CL/CAS, tRCD: RAS to CAS Delay, tRP: RAS Precharge, tRAS: Active to Precharge Delay.) and CL14-14-14-34 (CAS 14). ACT (Activate), RAS (Row Access Strobe), CAS (Column Access Strobe), and WE (Write Enable)&lt;/li&gt;&#xA;&lt;li&gt;Two RAM kits may have the same data transfer rate (example: DDR4-3200), but different latencies. DDR3 RAM usually has a CAS latency of 9 or 10, while DDR4 will have a CAS latency of at least 15. However, because of its faster clock speeds, the newer standard has better performance overall.&lt;/li&gt;&#xA;&lt;li&gt;Note: This is latency per cycle, not per advertised signal frequency! DDR3200 will have 1600M cycles per second. So, (1/(advertised frequency/cycle data rate)) * latency per cycle = true latency.&#xA;&lt;ul&gt;&#xA;&lt;li&gt;DDR4-3200 RAM with latency 16 will have true latency - 10ns.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Latencies have gradually increased over the years with the physical distance that signals have to travel (the speed of light is a hard limit)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;interface-size&#34;&gt;Interface Size&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Interface size is a bit dependent on read width. 256 bit read requires atleast 256 pins!&lt;/li&gt;&#xA;&lt;li&gt;DDR SDRAM modules come in different interface sizes; the number of pins can be different: laptop units are smaller. Vostro 1000 laptop accepts DDR2 PC2-5300 RAM, even 2GB DDR2 800MHz/PC2-6400 200-pin SODIMM.&lt;/li&gt;&#xA;&lt;li&gt;Desktops accept 288 pin modules.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;power-efficiency&#34;&gt;Power efficiency&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;In terms of power efficiency, DDR4 (1.2V) &amp;gt; DDR3 (1.5V).&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;ddr-sdram-tech&#34;&gt;DDR SDRAM tech&lt;/h2&gt;&#xA;&lt;h3 id=&#34;read-phases&#34;&gt;Read phases&lt;/h3&gt;&#xA;&lt;p&gt;bitline precharge, activate, row access, column access. Row access is the heart of a read operation, as it involves the careful sensing of the tiny signals in DRAM memory cells; it is the slowest phase of memory operation. However, once a row is read, subsequent column accesses to that same row can be very quick.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
