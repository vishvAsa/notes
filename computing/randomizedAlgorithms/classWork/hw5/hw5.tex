\documentclass[10pt]{amsart}
\usepackage{amssymb}


\newtheorem{thm}{Theorem}[subsection]
\newtheorem{cor}[thm]{Corollary}
\newtheorem{lem}[thm]{Lemma}

\theoremstyle{remark}
\newtheorem{defn}[thm]{Definition}
\newtheorem*{ack}{Acknowledgement}
\newtheorem{alg}[thm]{Algorithm}
\newtheorem{rem}[thm]{Remark}

%opening
\title{CS388R: Answer to Homework 5}
\author{vishvAs vAsuki}

\begin{document}

\maketitle

\begin{ack}
I benefitted from discussions with Jing-Tang Jang in solving this assignment.
\end{ack}

\section{Question}
Exercise 6.17: Use the general form of the Lovasz local lemma to prove that the symmetric version of Theorem 6.11 can be improved by replacing the condition $4dp \leq 1$ by the weaker condition $ep(d+1)\leq 1$

\subsection{Solution}

The general case of the Lovasz local lemma states the following:

Consider the dependency graph G= (V,E) for events E1, E2 ... En. Suppose that there exist x1,x2, ... xn such that $Pr(Ei) \leq x_{i} \prod_{(i,j)\in E} (1-x_{j})$, then $Pr(\cap_{i=1}^{n}\overline{E_{i}}) \geq \prod_{i=1}^{n}(1-x_{i})$.

Let d be the maximum degree of any node in G. Consider what $ep(d+1) \leq 1$ implies.

\begin{eqnarray}
ep(d+1) &\leq& 1\\
p &\leq& (d+1)^{-1}e^{-1}\\
 &\leq& (d+1)^{-1}(1-\frac{1}{1+d})^{d}\\
Pr(E_{i}) &\leq& (d+1)^{-1}(1-\frac{1}{1+d})^{d}\\
\end{eqnarray}

Thus, $ep(d+1) \leq 1$ satisifies $Pr(Ei) \leq x_{i} \prod_{(i,j)\in E} (1-x_{j})$, the precondition for the general case of the lovasz local lemma, with $x_{i} = (d+1)^{-1}$. Thus, we conclude that whenever $ep(d+1) \leq 1$, $Pr(\cap_{i=1}^{n}\overline{E_{i}}) > 0$.

\section{Question}
Exercise 7.6: In studying the 2-SAT algorithm, we considered a 1-dimensional random walk with a completely reflecting boundary at 0. That is, whenever position 0 is reached, with probability 1 the walk moves to position 1 at the next step. Consider now a random walk with a partially reflecting boundary at 0. Whenever position 0 is reached, with probability 1/2 the walk moves to position 1 and with probability 1/2 the walk stays at 0. Everywhere else the random walk moves either up or down 1, each with probability 1/2. Find the expected number of moves to reach n, starting from position i and using a random walk with a partially reflecting boundary.

\subsection{Solution}
Consider the Markov chain described in the question.

Let $Z_{i}$ be the random variable which represents the number of steps executed in going from the state i to the state n. Let $h_{i}=E[Z_{i}]$. We know from the construction of the Markov chain that $Z_{i}=\frac{1}{2}(Z_{i-1}+1)+\frac{1}{2}(Z_{i+1}+1)$.

Due to linearity of expectations, we see that $h_{i}=\frac{1}{2}h_{i-1}+\frac{1}{2}h_{i+1} + 1$. Also, we have $h_{n}=0$ and $h_{0}=h_{1}+2$.

We solve this system of equations below to arrive at the solution.

\begin{eqnarray}
h_{n} &=& 0\\
h_{0} &=& h_{1}+2\\
h_{j} &=& 2h_{j-1}-h_{j-2}-2\\
h_{j+1} &=& 2h_{j}-h_{j-1}-2\\
\therefore  h_{j+1}-h_{j} &=& 2h_{j}-h_{j-1}-2h_{j-1}+h_{j-2}\\
\therefore  h_{j+1}-3h_{j}+3h_{j-1}-h_{j-2} &=& 0\\
\text{Characteristic equation:} && \\
x^{3}-3x^{2}+3x-1 &=& 0\\
(x-1)^{3} &=& 0\\
\therefore h_{j} &=& a+bj+cj^{2}\\
But: h_{j} &=& 2h_{j-1}-h_{j-2}-2\\
\therefore a+bj+cj^{2} &=& 2(a+b(j-1)+c(j-1)^{2}) \\
&& - (a+b(j-2)+c(j-2)^{2}) -2\\
\therefore c &=& -1\\
\therefore h_{j} &=& a+bj-j^{2}\\
h_{0} - 2 &=& h_{1}\\
\therefore a - 2 &=& a+b-1\\
\therefore b &=& -1\\
\therefore h_{j} &=& a-j-j^{2}\\
h_{n} &=& 0\\
\therefore a-n-n^{2} &=& 0\\
\therefore h_{j} &=& n+n^{2}-j-j^{2}\\
\end{eqnarray} 

\section{Question}
Exercise 7.9: In the analysis of the randomized algorithm for 3-SAT, we made the pessimistic assumption that the current assignment Ai and the truth assignment S differ on just one variable in the clause chosen at each step. Suppose instead that, independently at each step, the two assignments disagree on one variable in the clause with probability p and at least two variables with probability 1-p. What is the largest value of p for which you can prove that the expected number of steps before Algorithm 7.2 terminates is polynomial in n? Give a proof for this value of p and give an upper bound on the expected number of steps in this case.

\subsection{Solution}
Let E be the event where a certain clause disagrees on one variable.

Pr(E)=p. Consider the Markov chain, M, where each state corresponds with the number of variables whose truth value corresponds to the satisfying assignment.

Let F be the event where the action of the algorithm causes a forward movement in M. $Pr(F) = Pr(E)Pr(F|E) + Pr(\sim E)Pr(F|\sim E) = \frac{2}{3}p + \frac{1}{3}(1-p) = \frac{1}{3}(1+p)$. Similarly, the probability of moving backward in M is $Pr(\sim E) = \frac{1}{3}(2-p)$.

Let $Z_{i}$ be the random variable which represents the number of steps executed in going from the state i to the state n. Let $h_{i}=E[Z_{i}]$. Then, $Z_{i}=\frac{1}{3}(1+p)(Z_{i-1}+1)+\frac{1}{3}(2-p)(Z_{i+1}+1)$.

By linearity of expectations, $h_{i}=\frac{1}{3}(1+p)(h_{i-1}+1)+\frac{1}{3}(2-p)(h_{i+1}+1)$. Also, we have $h_{n}=0$ and $h_{0}=h_{1}+2$.

When p is 0.5, we have: $h_{i}=\frac{1}{2}(h_{i-1}+1)+\frac{1}{2}(h_{i+1}+1)$. Then, the system of equations reduces to the one used by \cite{mitzenmacherUpfal} in the analysis of the Markov Chain used in solving 2-SAT. Referring to that analysis, we note that in such a case, our algorithm terminates in time polynomial in n.

The characteristic equation corresponding to the recurrance relation is $(2-p)x^{3}-(5-p)x^{2}+(p+4)x - (p+1) =0$. This is equivalent to the equation $(x-1)^{2}(x-\frac{p+1}{2-p})=0$. So, the sequence is defined by $h_{j} = a(1^{j}) + bj(1^{j-1}) + c(\frac{p+1}{2-p})^{j}$. From this, we see that for values of $p>0.5$, the expected number of steps required to solve the 3-SAT problem is exponential. For $p < 0.5$, the expected number of steps is polynomial, as $(\frac{p+1}{2-p}))^{j} = o(1)$ in such a case.

\section{Question}
Exercise 7.12: Let Xn be the sum of n independent rolls of a fair die. Show that, for any $k\geq 2$,
$\lim_{n \to \infty}Pr(X_{n} $ is divisible by k$)=1/k$.

\subsection{Solution}
Consider the Markov chain M defined as follows: M has k states, numbered from 0 to k-1. Let Xn be the sum of n independent rolls of a fair die. If $Xn \% k = j$, then the Markov chain will be in the state j. Suppose that the value of a certain die roll is i. Then, if the Markov chain was in the state j, it will transition to the state $(j+i \% k)$. As the die is fair, all state tranistions have the same probability. Note that the chain described here is Markovian as the state transitions depend only on the current state.

The state of the Markov chain at any point in time corresponds to $Xn \% k$. Note that M is finite in length. Due to its construction, it is irreducible. All states in the M are positive recurrant. Also, as the die rolls produce values ranging from 1 to 6, all states in M are aperiodic. Thus, M possesses a unique stationary distribution. Furthermore, due to the construction of the Markov chain described above, every state is identical in all respects to every other state. In other words, in terms of structure, all states are indistinguishable from each other. Thus, due to symmetry, in its stationary distribution, the current state of M is uniformly distributed among all its states.

Thus, Pr(state in stationary distribution = j) = $\lim_{n \to \infty}Pr(X_{n} $ is divisible by k$)=1/k$.

\section{Question}
Exercise 7.20: We have considered the gambler's ruin problem in the case where the game is fair. Consider the case where the game is not fair; instead, the probability of losing a dollar each game is 2/3 and the probability of winning a dollar each game is 1/3. Suppose that you start with i dollars and finish either when you reach n or lose it all. Let $W_{t}$ be the amount you have gained after t rounds of play.

\subsubsection{1} Show that $ E[2^{W_{t+1}}]=E[2^{W_{t}}]$.
\subsubsection{2} Use part (a) to determine the probability of finishing with 0 dollars and the probability of finishing with n dollars when starting at position i.
\subsubsection{3} Generalize the preceding argument to the case where the probability of losing is $p>1/2$. (Hint: Try considering $E[c^{W_{t+1}}]$ for some constant c.)


\subsection{Solution}

\subsubsection{1}
\begin{eqnarray}
E[2^{W_{t+1}}] &=& \frac{2}{3}E[2^{W_{t}-1}] + \frac{1}{3}E[2^{W_{t}+1}]\\
&=& \frac{1}{3}E[2^{W_{t}}] + \frac{2}{3}E[2^{W_{t}}]\\
&=& E[2^{W_{t}}]\\
\end{eqnarray}

\subsubsection{2}
Consider a Markov Chain with states with the names : $-i, ..., 0, ..., n-i$. The states correspond to the gambler's winnings, $W_{t}$. -i and n-i are absorbing states. The rest of the states are transient states. So, in the limiting case where we wait for sufficiently long time, the state will be -i with probability q and n-i with probability 1-q.

Consider $E[2^{W_{1}}]$. $E[2^{W_{1}}] = \frac{2*2^{-1}}{3} + \frac{1*2}{3} = 1$. Using the result of the previous subquestion, we conclude that $E[2^{W_{t}}]=1$. So, $\lim_{t \to \infty}E[2^{W_{t}}] = q2^{-i}+(1-q)2^{n-i} =  1$. So, $q(2^{-i}-2^{n-i}) = 1-2^{n-i}$. Hence, the probability of loosing everything is $q= (1-2^{n-i})/(2^{-i}-2^{n-i})$. The probability of winning n dollars is $1-q=(2^{-i}-1)/(2^{-i}-2^{n-i})$.

\subsubsection{3}
Let p be the probability of loosing. Let $c=\frac{p}{1-p}$. Then, we see that $E[c^{W_{t+1}}]=E[c^{W_{t}}]$.

Consider a the markov chain described in the previous subsection. Again, -i and n-i are the abosorbing states. Consider $E[c^{W_{1}}]$. $E[c^{W_{1}}] = pc^{-1}+(1-p)c = 1$. So, we conclude that $E[c^{W_{t}}]=1$. So, $\lim_{t \to \infty}E[c^{W_{t}}] = qc^{-i}+(1-q)c^{n-i} =  1$. Hence, the probability of loosing everything is $q= (1-c^{n-i})/(c^{-i}-c^{n-i})$. The probability of winning n dollars is $1-q=(c^{-i}-1)/(c^{-i}-c^{n-i})$.

\section{Question}
Exercise 7.23, parts a and b: One way of spreading information on a network uses a rumor-spreading paradigm. Suppose that there are n hosts currently on the network. Initially, one host begins with a message. Each round, every host that has the message contacts another host chosen independently and uniformly at random from the other n-1 hosts, and sends that host the message. We would like to know how many rounds are necessary before all hosts have received the message with probability 0.99.

\subsubsection{1} Explain how this problem can be viewed in terms of Markov chains.
\subsubsection{2} Determine a method for computing the probability that j hosts have received the message after round k given that i hosts have received the message after round k-1. (Hint: There are various ways of doing this. One approach is to let P(i, j, c) be the probability that j hosts have the message after the first c of the i hosts have made their choices in a round; then find a recurrence for P.)

\subsection{Solution}
\subsubsection{1} The problem described can be viewed as the following Markov chain, M. The states of M are numbered from 1 to n. The current state of M corresponds to the number of hosts which have the message. The transition probability from i to j corresponds to the probability that j hosts have received the message after round k given that i hosts have received the message after round k-1. Note that the Markov property holds, as at any step, the transition probabily depends only on the number of hosts which have the message.

\subsubsection{2} Let Pr(i, j, c) be the probability that j hosts have the message after the first c of the i hosts have made their choices in a round; then find a recurrence for P. Let the event E stand for the case where a node that has the message sends a message to another node which already has the message. (Note that a node cannot send a message to itself.) Pr(E) corresponds to Pr(i,j,x|i,j,x-1). Then, we see that $Pr(i, j, c) = Pr(i, j, c-1) Pr(E) + Pr(i, j-1, c-1)Pr(\sim E) = Pr(i, j, c-1) (j-1)/(n-1) + Pr(i, j-1, c-1)(n-j+1)/(n-1)$. Solving this recurrance, one can find Pr(i,j,i).

Thus we have determined a method for computing the probability that j hosts have received the message after round k given that i hosts have received the message after round k-1.

\section{Question}
Exercise 7.26: Let n equidistant points be marked on a circle. Without loss of generality, we think of the points as being labeled clockwise from 0 to n-1. Initially, a wolf begins at 0 and there is one sheep at each of the remaining n-1 points. The wolf takes a random walk on the circle. For each step, it moves with probability 1/2 to one neighboring point and with probability 1/2 to the other neighboring point. At the first visit to a point, the wolf eats a sheep if there is still one there. Which sheep is most likely to be the last eaten?

\subsection{Solution}

We want to find the probability that the wolf visits node i after visiting every other point.

Consider the Markov chain, M, whose graph is a straight line. The states in M are labelled 0 to n-1. The transition probability between any two neighboring points on the line is 1/2, except for the terminal points, which are absorbing states. The current state of M represents the position of the wolf.

Consider the case where the graph corresponding to M is obtained by cutting the circle at point 1. The initial state is point 0. Thus, the terminal states of M represent the point number 1 in the circle. Applying the result from the Gambler's ruin problem, we find that the probability of reaching a terminal state is $\frac{1}{n-1}$. This corresponds to the probability that the wolf visits position 1 only after visiting all other points. Due to symmetry, the case where the wolf visits point n-1 only after visiting all other points is identical.

Now, consider the general case where we wish to calculate the probability that the sheep at point i is the last to be eaten. Pr(point i is visited last) = Pr(i-1 reached before i+1) Pr(starting at i-1, i+1 is visited without going through i) + Pr(i+1 reached before i-1) Pr(starting at i+1, i-1 is visited without going through i) = $\frac{n-i+1}{n-2}\frac{1}{n-1} + \frac{i-1}{n-2}\frac{1}{n-1} = \frac{1}{n-1}$. Pr(i-1 reached before i+1) and Pr(i+1 reached before i-1) were calculated by considering a gambler's ruin type Markov chain constituted by n-2 points from (i+1) through 0 to (i-1). Pr(starting at i-1, i+1 is visited without going through i) and Pr(starting at i+1, i-1 is visited without going through i) were calculated by considering the fact that these cases are symmetric to the case where, starting from point 0, point 1 is the last to be visited.

Hence, every sheep is equally likely to be the last to be eaten - with probability 1/(n-1).

\section{Question}
Exercise 7.27: Suppose that we are given n records, R1, R2, \dots, Rn. The records are kept in some order. The cost of accessing the jth record in the order is j. Thus, if we had four records ordered as R2, R4, R3, R1, then the cost of accessing R4 would be 2 and the cost of accessing R1 would be 4.

Suppose further that, at each step, record Rj is accessed with probability pj, with each step being independent of other steps. If we knew the values of the pj in advance, we would keep the Rj in decreasing order with respect to pj. But if we don't know the pj in advance, we might use the 'move to front' heuristic: at each step, put the record that was accessed at the front of the list. We assume that moving the record can be done with no cost and that all other records remain in the same order. For example, if the order was R2, R4, R3, R1 before R3 was accessed, then the order at the next step would be R3, R2, R4, R1.

In this setting, the order of the records can be thought of as the state of a Markov chain. Give the stationary distribution of this chain. Also, let Xk be the cost for accessing the kth requested record. Determine an expression for $\lim_{k \to \infty} E[X_{k}]$. Your expression should be easily computable in time that is polynomial in n, given the pj.

\subsection{Solution}

Consider a Markov chain M, with states corresponding to different permutations of n records. M is finite, irreducible, positive recurrant and aperiodic. Hence, it has a unique stationary distribution, p.

Let $h_{i}$ be the expected number of steps to return to state i upon starting from state i. Let state i correspond to the record sequence Ra, Rb, Rc, Rd ... Rx. The only way to return to state i in 1 step is if the record Ra were accessed. The only way to return to state i in exactly 2 steps if if the records Rb and Ra were accessed in that order. In general, the only way to return to state i in exactly s steps if if the first s records are accessed in a certain unique order. From the definition of expectations, we see that $h_{i}=1p_{a}+2p_{b}p_{a}+3p_{c}p_{b}p_{a} + \dots + x\prod_{j=a}^{x}p_{j}$. We note that $h_{i}$, for any state i, can be computed in time polynomial in n.

From a theorem in \cite{mitzenmacherUpfal}, we note that $p_{i}=\frac{1}{h_{i}}$. Thus, the probability of any state occuring in the stationary distribution can be found in time polynomial in n.

Let Xk be the cost for accessing the kth requested record. In the limiting case where an infinite number of transitions have happened, the probability of the current state being any state in M is given by the stationary distribution. The following discussion assumes that we are in the stationary distribution.

Let Rij represent the event that Ri is in position j.

Pr(Ri1) = Pr(Ri was requested in the previous step) = $p_{i}$.

Pr(Ri2) = Pr(Ri was requested 2 steps ago, and another record was requested in the previous step) = $p_{i}(1-p_{i})$.

Pr($R_{i,3}$) = Pr($R_{i}$ was requested 3 steps ago, and other records were requested in the other previous steps) = $p_{i}(1-p_{i})^{2}$.

In general, Pr($R_{i,x}$ is in position x) = Pr($R_{i}$ was requested x steps ago, and other records were requested in the other previous steps) = $p_{i}(1-p_{i})^{x-1}$.

Let Ai be the event where the kth requested record is Ri.

Then, $\lim_{k \to \infty} E[X_{k}] = \lim_{k \to \infty} \sum_{i=1}^{n} E[X_{k}|Ai]p_{i} = \\
\sum_{i=1}^{n} p_{i}\sum_{x=1}^{n} xPr(R_{i,x}) = \sum_{i=1}^{n} p_{i}(1p_{i}+2p_{i}(1-p_{i})+3p_{i}(1-p_{i})^{2}+\dots + np_{i}(1-p_{i})^{n-1}) = \sum_{i=1}^{n} p_{i}^{2}\frac{(1-(1-p_{i})^{n+1})}{p_{i}^{2}} = \sum_{i=1}^{n} (1-(1-p_{i})^{n+1})$.

This function is computable in time polynomial in n.

\bibliographystyle{plain}
\bibliography{../randomizedAlgorithms}

\end{document}
