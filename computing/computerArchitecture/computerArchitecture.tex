\documentclass[oneside, article]{memoir}
\input{../packages}
\input{../packagesMemoir}
\input{../macros}


%opening
\title{Computer architecture: Quick reference}
\author{vishvAs vAsuki}

\begin{document}
\maketitle

\chapter{Architecture of a computer}
\section{Gross view}
Visualize a processor connected to some working memory and to an input output device. This is aka von-Neumann architecture.

\section{Motherboard}
A mother-board provides suitable interface and circuits for communication and power-supply among/ for the processor, working memory, I/O, persistent storage etc..

The motherboard contains the BIOS memory where the boot-program is located.

\subsection{System Bus}
The system bus is a common communication channel on the motherboard. It has many different dedicated branches for communication between the different components and certain controller hubs.

A computer bus operating with \textit{double data rate} transfers data on both the rising and falling edges of the clock signal.

\subsection{Quality}
Important factors determining quality are: the bus clock frequency, the choice of I/O protocols supported.

\section{Processor}
\subsection{Components}
Every processor consists of an arithmetic and logic unit/ circuit (ALU), a few memory registers with a few layers of cache, memory and graphics controller circuits in order to be able to perform I/O operations and using extended working memory.

\subsection{Tight knit Parallelism}
\subsubsection{Multiple cores}
Usually multiple cores share memory.

\subsubsection{Pipelines}
Aka instruction level parallelism. 

Processing often has pipeline structure; eg: fetch instruction, fetch data, execute instruction, store data. There are usually separate functional units within a single processor which take care of these separate tasks in each clock cycle.

'Superscalar processors' try to parallelize these tasks. Branch prediction problem: how to pipeline if the instruction to be executed is a conditional: multiple choices of what to prefetch to the pipeline.

\paragraph{Simultaneous multithreading}
Parallelism in use of functional units within processors to execute two instruction threads at once, rather than one instruction thread faster is a feature provided in 'SMT' processors. This is called hyperthreading by Intel.

\subsection{Memory cache}
There is a tradeoff between latency and miss-rate: the larger the cache, the lower the possibility of necessary data not being cached, but latency is higher because of greater addressing/ accounting needs. Hence, there are multiple cache-levels, denoted L1 .. Lk in increasing order of size.

\subsection{Quality}
The frequency indicates the speed at which a processor can be operated. Processors also differ in the ability to undertake 16 vs 32 vs 64 bit arithmetic. They also differ in the number of cores to accommodate parallelism.

They differ in the number and sizes of memory-cache levels they offer, and the speed with which they can be accessed.

They differ in the power they consume - for mobile devices, the ability to adjust processing speed (stepping) according to computing needs is important.

\subsubsection{Best and economical}
2011: 4-core 64 bit processors running at 2.7 GHz with 4MB L3 cache size by Intel and AMD are available for $\approx 110\$$.

\subsubsection{Trends}
Graphene replacing silicon can lead to continuation of moore's law - enabling smaller and smaller transistors on the Integrated circuit/ IC chip. But smaller communication channels implies greater power costs for pushing electrons across the channels within the chip.

Then, it will be possible to have a thousand-core processor.

\section{Working Memory}
\subsection{DDR SDRAM}
This is Double data rate synchronous dynamic random access memory. The terms are explained below.

Working memory is capable of random, rather than serial, access; though it may still be efficient to read big blocks of memory together into the CPU cache for processing. Also, it is dynamic - it retains data only when supplied electricity to periodically refresh its memory. It is commonly Synchronous - synchronized with the system bus.

\exclaim{Current bottleneck!}

\subsubsection{Quality}
They mainly vary in the clock/ data transfer rate (Eg: DDR-333 $>$ DDR-200) and in size. PC2-xxxx denotes theoretical bandwidth (with the last two digits truncated).

\paragraph{Best and economical}
As of 2011: 2*2 = 4GB RAM modules are economical - sometimes insufficient for programming and surfing the web simultaneously - some website/browser combos consume much memory! Macbook pro comes with 8GB RAM.

\subsubsection{Interface}
DDR SDRAM modules come in different interface sizes; the number  of pins can be different: laptop units are smaller. Vostro 1000 accepts DDR2 PC2-5300 RAM, even 2GB DDR2 800MHz/PC2-6400 200-pin SODIMM.

Some motherboards support dual channel memory, which theoretically doubles the throughput if both SDRAM-slots in the contain identical memory modules.

\subsection{Memory hierarchy}
Memory access could be 100 times slower than flops: this is an important consideration when optimizing algorithms. Hence, there is a hierarchy of memory:

Registers in the processor $>$ On chip Cache: many layers $>$ main memory $>$ secondary memory located on the hard-disk for example.

\section{Graphics processing (GPU)}
GPU's, implementing common graphics tasks on specialized circuits, speed up display tasks involved in personal computing.

\subsection{High data parallelism}
GPU's follow a dataflow architecture: Highly pipelined, parallel with many small cores - much more than CPU's. Usually, these parallel cores are divided profitably and easily: Like one core for a bunch of pixels.

Earlier these processing elements were specialized for graphics, now these shaders are more programmable.

\subsection{For general computing}
With GPGPU, one would Disguise program as geometry computation. Now, can do such computation directly: eg: NVidia CUDA.

\chapter{Storage devices}
\section{Magnetic storage}
Unlike optical storage, magnetic storage is re-writable.

\subsection{Bus interface}
While SCSI has a processor integrated into the controller, SATA makes greater use of the system processor to serve that function; the former is costlier.

\subsection{Quality}
Hard disk drives differ mainly in speed, storage capacity, size, redundancy (RAID), error correction, shock resistance.

\subsubsection{Best and economical}
Areal density doubling every two to four years since their invention. So, even 1TB is economical.

\section{Optical storage}
They are compact, but have the disadvantage of being over-writable a limited number of times.

\subsection{Quality}
\subsubsection{Best and economical}
Blu-Ray - where blue laser is used - is the rage. It is even more burdened than the DVD with copy-protection mechanisms like region code and DRM.

\section{Flash memory}
These use floating gate MOSFET transistors. They are fast and compact.

\subsection{SD cards}
\subsubsection{Size}
They come in 3 sizes: micro, mini and regular. A smaller card can be used in place of a larger card using an adapter.

\subsubsection{Speed}
Depending on transfer speed (in MBps), they are classified into various classes, with class 4 commonly used. Class 10 is recommended for watching movies etc..

\chapter{Display}
\section{Display screens}
Liquid Crystal displays tend to be more ergonomically friendly than CRT tube monitors.


\subsection{Quality}
\subsubsection{Image quality}
Display screens vary in image quality parameters: screen size, maximum resolution: SVGA (800 x 600), XGA (1024 x 768), SXGA (1280 x 1024), or UXGA (1600 x 1200), contrast ratio.

They also vary in refresh rate, in the case of images generated from projection, as in CRT monitors or projectors: low refresh rate results in flicker and eye strain - especially from typing distance. Higher resolutions require correspondingly higher refresh rates.

\subsubsection{LCD screens}
In addition LCD screens vary in adjustibility of height, orientation etc. and whether they also function as a touch sensitive input device. Screen size of around 14' has been quite adequate in my laptop computer.

\subsubsection{Best and economical}
23 inch LCD without touch sensitivity was available for around 110\$ in a sale.

\section{Projectors}
Using projectors for display allows display size to be set dynamically; allowing a variety of postures and ability to view from a distance, it may be ergonomically better. But, it is not suitable for close viewing (and there fore use as a second monitor), because of the flickering in the display.

\subsection{Quality}
Besides image quality parameters described in the Display screens section, Projectors vary in portability, the noise they make while operating due to cooling needs, the brightness of the image, lamp life, energy consumption.

\subsection{Best and economical}
Image brightness of atleast 1400 is good (2300 was tested successfully). Lamp life should be atleast 2000 lumens.

For 340\$, good projectors are available.

\chapter{Input}
\section{Gaming input}
\subsection{Motion detection}
Microsoft Kinect detects hand motions at a certain optimum distance using a camera - no external devices are required.

\section{Containment/ Size}
\subsection{Computer case}
The case/ tower provides power-supply and cooling. Good cooling systems try to be noiseless - they rely on airflow or ensure that the fan speed is usually low.

\subsection{Size}
Computer's processing and storage components are sometimes fit into the monitor or under keyboard in case of a notebook computer, or in a small case.

\subsubsection{Best and economical}
Demand and competition ensure that fairly powerful laptops are now available at a price comparable to equally powerful desktop machines.

\chapter{Interfaces and networking}
\section{Device interfaces}
Common standards are often used to connect a wide variety of device pairs.

\subsection{Universal serial bus}
USB is currently most popular. USB 3 enables superior data-transfer speeds.

USB allows for a tiered star topology: so one can connect many devices to a particular device with a single usb wire branching out into many others. Power dissipation limits the extant to which this can be done.

\subsection{USB Plugs}
USB wires have 4 (sometimes 5) terminals arranged in various shapes.

Type A is most common.

Micro B is a small trapezoid - often used with pocket computers.

Mini A and B are also sometimes used.

Type B is used with monitors.


\section{Modems}
Modems provide a link to a wider network - usually the Internet. They differ based on the means of communication used in providing this link, and the links it can provide to devices seeking connection to the wider network.

\subsection{Mobile Wifi (MiFi)}
These connect to the wider network using 3G or 4G compatible protocols; and allow devices to connect to it using WiFi protocol - for which reason, they are called 'hotspots'.

\chapter{Special computers}
\section{Pocket computers}
\subsection{Components}
These devices are very compact, and often combined with specialized equipment like ability to connect to certain mobile phone networks, GPS, gyroscopes, compasses, cameras, flash led's, accelerometers. Such components often make single function devices much less attractive.

\subsection{Customizability}
The hardware customizability is often very limited; but communication interfaces (eg: bluetooth, card slots) enable expansion.

\subsection{OS}
The operating systems used are often not easily switched; but may be upgradeable or hacked in minor ways. Popular OSes are Apple iOS, Windows, HP's OS, Blackberry OS, Google's Android (often allied with HTC sense UI). Applications/ programs for these operating systems can be bought/ distributed on the internet.

\subsection{Quality}
A major feature of the device is its interface. Touch screen devices which recognize gestures were pioneered by Apple's iphones.

\subsubsection{Best and economical (2011)}
Small size of hard-disks enable provision of large internal storage space.

Popular features: 1GHz processors with 512MB RAM, 5 to 8MP cameras, atleast 8GB storage, 800*480 screens, video cards capable of 20 frames per second.

Current devices weigh around 4.5 oz.

\chapter{Procurement and maintenance}
\section{Maintenance}
\subsection{Fan vent cleaning}
In case of a laptop, the fan-vent needs to be cleaned periodically. CPU temperature can be monitored in the GUI using common applications.

\subsection{Battery}
If laptop is always connected, best to disconnect battery \chk.

\subsection{Vostro 1000 disassembly procedure}
Remove panel above keyboard. Disconnect keyboard, wires to monitor, trackpad. Remove screws in the front and in the back. Remove the panel from above the keyboard.

\section{Upgrades}
\subsection{Understand needs}
In order to understand what needs to be change, it is good to understand resource limitations: is working memory low, or is the CPU too slow. Hence, run a system monitor application.

\chapter{Parallel computers}
\section{Architecture}
Possible 4 uses of multiple processing units were named by Flynn as single/ multiple instructions single/ multiple data-streams.

\section{Communication}
Shared memory vs message passing architectures. Can use shared memory abstraction over message passing, vice-versa.

\chapter{Number storage formats}
\section{Design factors}
\subsection{Words and bits}
Suppose $b$ bits are available to store a certain type of number: this is usally expressed in terms of multiples of words (collection of $w$ bits). Because binary logic is used for addressing and processing, $w$ is generally a power of 2. In old days, it used to be $w = 2^2$, now 64 bit words are common.

\subsection{Simplicity of computation logic}
Some representation formats require simpler and more efficient circuits for performing basic arithmetic operations than others. This is an important factor in choosing the representation format.

\subsection{Special numbers}
ONe may want to reserve space in representation set for storing special numbers like +Inf, -Inf, NaN (for storing results of illegal operations).

\section{Integers}
Suppose $b$ bits are available to store a number.

\subsection{Unsigned}
Any $x \in \set{0} \union N$ can be stored in the natural binary representation. So, in $b$ bits, $2^b$ unsigned numbers $x \in (0: 2^{b} -1 )$ can be stored.

\subsection{Signed}
While storing negative numbers along with positive numbers, one has to distinguish it from positive numbers, one requires a sign bit.

\subsubsection{Use sign bit + absolute value}
A straightforward way to store $x \in Z^{-}$ is to set the sign bit to $1$ and store $-x \in N$ in the remaining $b-1$ bits. In this case, $x \in (-2^{b-1}+1: 2^{b-1}-1)$ can be stored. Note that there is redundancy in possible representations of 0: the sign bit may be 1 or 0 (one of which can then be taken to mean NaN). Thus, a total of $2^{b}-1$ numbers can be stored.

\subsubsection{Offset/ biased storage}
One can take a large natural number called $k$ the bias. Then, one can store $2^b$ (as against $2^b -1$ in another representation) numbers $x \in -k:2^b - k-1$ by simply storing $x + k \in \set{0} \union N$.

\subsubsection{1's complement storage}
Suppose we use the bias $2^{b} - 1$ to store $x \in Z^-$. This amounts to inverting bits in the binary representation of $-x \in N$, is called (one's) complement representation of $x \in Z^-$.

\subsubsection{2's complement bias}
Here again, we used biased representation only to store -ve numbers, we store $2^{b} + x = 2^{b} - |x|$: this is the 2's complement of $x$ - we discuss this below.

If b=3, the numbers $-4:-1$ have representations $100:111$.

Note that this representation of $x$ effectively constitutes the use of the most significant (b-th) bit as a sign bit - distinguishing $x \in Z^-$ from $x \in \set{0} \union N$. Thus, we can store $x \in -2^{b-1}:2^{b-1} - 1$: a total of $2^{b}$ numbers.

Addition of -ve and +ve numbers (ie subtraction) becomes slightly easier: the circuit used to add two unsigned numbers will work fine.

\section{IEEE floating point}
\subsection{Division of bits}
The bits provided for storage are divided into the following components: 1 sign ($\pm$) bit, $M$ bits to store part of the mantissa, $E$ bits to store a function of the exponent. These components are described below.

\subsection{Number stored}
This imitates scientific notation of numbers: $1.2332 * 10^{-9}$. Stores $\pm (1+f/2^{M})2^{e + 2^{E-1} - 1}$. $\pm (1+f/2^{M})$:= mantissa, f:= significand or precision; $e$ := exponent stored in the biased representation; $k = 2^{E-1} - 1$ := exponent bias. 

Note that rather than use a sign bit in the exponent, the biased representation is used.

As scientific notation is used, 1 in (1+f) assumed, so the number of bits needed is effectively reduced by 1 bit!

\subsection{IEEE standards}
\textbf{Single precision}: M= 23 bits, E = 8 bits.

\textbf{Double precision}: M= 52 bits, E = 11 bits.

\subsection{Reserved numbers}
0 := is stored as $\pm 1\ 2^{-k}$, which amounts setting all non-sign bits to 0: note that -0 and +0 are distinct (to indicate different underflow conditions while performing arithmetic).

$\pm \infty = \pm 1.0\ 2^{k+2^{E-1}}$, which amounts to setting f=0, exponent bits being 1111...

NaN $= \pm 1.f 2^{k+2^{E-1}}$: identical to $\pm \infty$, except $f \neq 0$.

\subsection{Range}
Allowing for the reserved numbers and considering the range of M and E bits, we can observe the range.

Smallest non 0: $\pm 1.0..01\ 2^{-k}$. Largest num: $\pm 1.11...\ 2^{k+2^{E-1}-1} = \pm 2^{2^{E-1}}$.

So, underflow or overflow rare.

\subsection{Increasing gaps in different ranges}
In [1,2]: $2^{-M}$; In [2, 4]: $2^{-M+1}$; In $[2^{j}, 2^{j+1}]$: $2^{-M+j}$; relative gap only $2^{-M}$. So, 'Floating point'. Matlab eps: (num next to 1) - 1: $2^{-M} = 2^{-52} \approx  2.2204\ 10^{-16}$.

\subsection{Representation Accuracy}
Let $fl:R \to Q$ be a function which maps any number to its floating point representation.

\subsubsection{Machine epsilon}
In case of floating point representations, we can guarantee that $\forall x \in \mathbb{R}$, given that $x$ in range of floating point number system: $\frac{fl(x) - x}{x} \leq \eps$.

In case of a floating point number system with $M$ mantissa bits, $\eps_{M} = 2^{-M -1} = 2^{-53}$. This is because, in storing the number $1.f * 2^t$: 1] We assume that sufficient bits are available to store the exponent, 2]$M$ bits are available to store $f$.

Yet, note that $fl(\epsilon_M) = \eps_M$.

\subsubsection{Error guarantee view!}
Then, roundoff error [$fl(a \odot \epsilon) = a$] guaranteed. So, $fl(1+10^{-16}) = 1$. 

\subsection{Accuracy of arithmetic operations}
IEEE ensures: $fl(x \odot y) = (x \odot y)(1+\eps), \eps \leq \eps_{M}$ if $\odot = +-/\times$. See this by finding $x(1 + \eps) \odot y(1 + \eps)$. $fl(x \odot y)$ is written as $\oplus \ominus \otimes$.

For complex numbers $\otimes$ and div, use $\eps_{M} = 2^{-M-2}$.


% \bibliographystyle{plain}
% \bibliography{compArch}

\end{document}
