\documentclass[10pt]{amsart}
\usepackage{amssymb}


\newtheorem{thm}{Theorem}[subsection]
\newtheorem{cor}[thm]{Corollary}
\newtheorem{lem}[thm]{Lemma}

\theoremstyle{remark}
\newtheorem{defn}[thm]{Definition}
\newtheorem*{ack}{Acknowledgement}
\newtheorem{alg}[thm]{Algorithm}
\newtheorem{rem}[thm]{Remark}

%opening
\title{CS388R: Answer to Homework 6}
\author{vishvAs vAsuki}

\begin{document}

\maketitle

\begin{ack}
I benefitted from discussions with Yuchul Kim and Qi Li in solving this assignment.
\end{ack}


\section{Question}
Exercise 10.6: The problem of counting the number of solutions to a knapsack instance can be defined as follows: Given items with sizes $a1, a2,\dots, an>0$ and an integer $b> 0$, find the number of vectors $(x1, x2,\dots, xn)\in\{0, 1\}^{n}$ such that $\sum_{i=1}^{n}a_{i}x_{i}\leq b$. The number b can be thought of as the size of a knapsack, and the xi denote whether or not each item is put into the knapsack. Counting solutions corresponds to counting the number of different sets of items that can be placed in the knapsack without exceeding its capacity.

\subsubsection{1} A naive way of counting the number of solutions to this problem is to repeatedly choose $(x1, x2,\dots, xn)\in\{0, 1\}^{n}$ uniformly at random, and return the $2^{n}$ times the fraction of samples that yield valid solutions. Argue why this is not a good strategy in general; in particular, argue that it will work poorly when each $a_{i}$ is 1 and $b=\sqrt{n}$.

\subsubsection{2}

Consider a Markov chain X0, X1,... on vectors $(x1, x2,\dots, xn)\in\{0, 1\}^{n}$. Suppose Xj is $(x1, x2,\dots, xn)$. At each step, the Markov chain chooses $i\in[1, n]$ uniformly at random. If xi=1, then $X_{j+1}$ is obtained from Xj by setting xi to 0. If xi=0, then $X_{j+i}$ is obtained from Xj by setting xi to 1 if doing so maintains the restriction $\sum_{i=1}^{n}a_{i}x_{i}\leq b$. Otherwise, $X_{j+1}$=Xj.

Argue that this Markov chain has a uniform stationary distribution whenever $\sum_{i=1}^{n}a_{i}> b$. Be sure to argue that the chain is irreducible and aperiodic.

\subsubsection{3} Argue that, if we have an FPAUS for the knapsack problem, then we can derive an FPRAS for the problem. To set the problem up properly, assume without loss of generality that $a1\leq a2 \leq ... \leq an$. Let b0=0 and $b_{i}=\sum_{i=1}^{n}a_{i}$. Let $\Omega(bi)$ be the set of vectors $(x1, x2,\dots, xn)\in\{0, 1\}^{n}$ that satisfy $\sum_{i=1}^{n}a_{i}x_{i}\leq b$. Let k be the smallest integer such that $b_{k}\geq b$. Consider the equation
$|\Omega(b)|=\frac{|\Omega(b)|}{|\Omega(b_{k-1})|} \frac{|\Omega(b_{k-1})|}{|\Omega(b_{k-2})|} \dots \frac{|\Omega(b_{1})|}{|\Omega(b_{0})|}\Omega(b_{0})|$.

You will need to argue that $|\Omega(b_{i-1})|/|\Omega(b_{i})|$ is not too small. Specifically, argue that $|\Omega(b_{i})|\leq (n+1)|\Omega(b_{i-1})|$.

\subsection{Solution}

\subsubsection{1}
A naive way of counting the number of solutions to this problem is to repeatedly choose the vector $(x1, x2,\dots, xn)\in\{0, 1\}^{n}$ uniformly at random, and return the $2^{n}$ times the fraction of samples that yield valid solutions. This is not a good strategy in general. 

The following arguement is a suitably reworded version of the one used in the case of counting the number of satisfying assignments to a DNF in \cite{mitzenmacherUpfal}. Consider the case where the number of satisfying choices of vectors is polynomial in n. If at each step we sample uniformly at random from the $2^{n}$ possible choices for the vector, then, with high probability we must sample an exponential number of vector values before finding the first satisfying vector. So, we cannot distinguish between n, $n^{2}$ and $n^{3}$ satisfying vector values without considering exponentially many random choices of values for the vector, as with high probability we obtain 0 satisfying value choices for the vector in all three cases.

One could use the Theorem 10.1 in \cite{mitzenmacherUpfal} to argue the above rigorously. That theorem states that the number of samples required to obtain an (e,d) approximation is inversely proportional to the probability that a sample belongs to the set we are interested in. In our case, as we argued above, that probability is exponentially small in case the number of satisfying choices of vectors is polynomial in n. So, an exponential number of samples are required with high probability.

When each $a_{i}$ is 1 and $b=\sqrt{n}$, the total number of satisfying solutions is $\sum_{i=0}^{\sqrt{n}} \binom{n}{i} \leq \sqrt{n}n^{\sqrt{n}} = \sqrt{n}2^{\sqrt{n}\log n }$. Hence, the probability of sampling an item with the desired properties is $\sqrt{n}2^{\sqrt{n}\log n  - n}$. This probability being exponentially small in n, according to Theorem 10.1 in \cite{mitzenmacherUpfal}, we would require an exponentially large number of samples.

\subsubsection{2}

Consider a Markov chain X0, X1,... on vectors $(x1, x2,\dots, xn)\in\{0, 1\}^{n}$. Suppose Xj is $(x1, x2,\dots, xn)$. At each step, the Markov chain chooses $i\in[1, n]$ uniformly at random. If xi=1, then $X_{j+1}$ is obtained from Xj by setting xi to 0. If xi=0, then $X_{j+i}$ is obtained from Xj by setting xi to 1 if doing so maintains the restriction $\sum_{i=1}^{n}a_{i}x_{i}\leq b$. Otherwise, $X_{j+1}$=Xj.

This Markov chain is irreducible. This is because every state is reachable from the state corresponding to the vector $(0, 0, \dots 0)$; and because one can reach that state from any other state. In other words, there is a non-zero probability of reaching any state from any other state.

This Markov chain is aperiodic. This is because, whenever $\sum_{i=1}^{n}a_{i}> b$, we can guarantee the existance of vectors which do not satisfy the requirement $\sum_{i=1}^{n}a_{i}x_{i}\leq b$. Furthermore, one can deduce from this the existance of a certain vector which satisfies $\sum_{i=1}^{n}a_{i}x_{i}\leq b$, such that if a certain 0 is changed to 1, $\sum_{i=1}^{n}a_{i}x_{i}\leq b$ is no longer satisfied. Hence, due to the construction of the Markov chain, there exists atleast one state with a "self loop".

As this Markov chain is finite, irreducible and aperiodic, it has a unique stationary distribution whenever $\sum_{i=1}^{n}a_{i}> b$. According to the construction of the Markov chain, the probability of going from any given state to any neighboring state is 1/n. Hence, we see that the Markov chain is time reversible. Consider the case where the states in the markov chain are distributed uniformly. So, each state has probability 1/M, where M is the number of states.

Using the fact that the Markov chain is time reversible, we make the following observation: Given a unifrom distribution over the states of the Markov chain, the cumulative probability of transition into a state x is exactly equal to the cumulative probability of transition out of that state. ($\frac{N(x)}{(Mn)}$, where $N(x)$ is the number of neighbors of x in the Markov chain.) This being a characteristic feature of stationary distributions, we can conclude that the uniform distribution is a stationary distribution.

\subsubsection{3}
To set the problem up properly, assume without loss of generality that $a1\leq a2 \leq ... \leq an$. Let b0=0 and $b_{i}=\sum_{i=1}^{n}a_{i}$. Let $\Omega(b_{i})$ be the set of vectors $(x1, x2,\dots, xn)\in\{0, 1\}^{n}$ that satisfy $\sum_{i=1}^{n}a_{i}x_{i}\leq b_{i}$. Let k be the smallest integer such that $b_{k}\geq b$. 

Note that $\Omega(b_{i-1}) \subseteq \Omega(b_{i})$. So, every element in $\Omega(b_{i-1})$ also belongs to $\Omega(b_{i})$. Furthermore, we note that every element s in $\Omega(b_{i}) - \Omega(b_{i-1})$ can be obtained by extending some element s' in $\Omega(b_{i-1})$ by adding one more item to the knapsack. (This is due to the fact that $b_{i}-b_{i-1}=a_{i}$. So, for s to belong to $\Omega(b_{i}) - \Omega(b_{i-1})$, it must have an element of value $a_{i}$ or greater.) So, the number of elemtns in $\Omega(b_{i}) - \Omega(b_{i-1})$ is at most $n|\Omega(b_{i-1})|$. Hence, we conclude that $|\Omega(b_{i})|\leq (n+1)|\Omega(b_{i-1})|$.

From this, we conclude that $|\Omega(b_{i-1})| /|\Omega(b_{i})| \geq 1/(n+1)$. Note that, as $|\Omega(b_{k-1})| /|\Omega(b_{k})| \geq 1/(n+1)$ and $|\Omega(b_{k})| \geq |\Omega(b)|$, $|\Omega(b_{k-1})| /|\Omega(b)| \geq \\
|\Omega(b_{k-1})| /|\Omega(b_{k})| \geq 1/(n+1)$.

Then, it is reasonable to suppose that we have an FPRAS to estimate this fraction. (One could, for example, use as an FPAUS the Markov Chain for $\Omega(b_{i})$ used in the answer to the previous subquestion and count the number of times we visit a state which also belongs to $\Omega(b_{i-1})$.)

Consider the equation
$|\Omega(b)|=\frac{|\Omega(b)|}{|\Omega(b_{k-1})|} \frac{|\Omega(b_{k-1})|}{|\Omega(b_{k-2})|} \dots \frac{|\Omega(b_{1})|}{|\Omega(b_{0})|}\Omega(b_{0})|$.

With this equation, and by using the FPRAS to approximate the fraction $\frac{|\Omega(b_{i-1})|}{ |\Omega(b_{i})|}$ for the n values of i, we arrive at an FPRAS for estimating $|\Omega(b)|$.

\section{Question}
Exercise 10.7: An alternative definition for an $\epsilon $uniform sample of $\Omega$ is as follows: A sampling algorithm generates an $\epsilon$ uniform sample w if, for all $x\in \Omega$,
$\frac{|Pr(w=x)-1/|\Omega||}{1/|\Omega|} \leq \epsilon $

Show that an $\epsilon $ uniform sample under this definition yields an $\epsilon$ uniform sample as given in Definition 10.3.

\subsection{Solution}

Consider any $S \subseteq \Omega$.

\begin{eqnarray*}
\frac{|Pr(w=x)-1/|\Omega||}{1/|\Omega|} &\leq& \epsilon \\
\therefore |Pr(w=x)-1/|\Omega|| &\leq& \frac{\epsilon }{|\Omega|}\\
\therefore \frac{-\epsilon }{|\Omega|} \leq Pr(w=x)-1/|\Omega| &\leq& \frac{\epsilon }{|\Omega|}\\
\therefore \frac{-|S|\epsilon }{|\Omega|} \leq \sum_{x \in S} (Pr(w=x)-1/|\Omega|) &\leq& \frac{|S|\epsilon }{|\Omega|}\\
\therefore \frac{-|S|\epsilon }{|\Omega|} \leq Pr(w\in S)-|S|/|\Omega| &\leq& \frac{|S|\epsilon }{|\Omega|}\\
\therefore |Pr(w\in S)-|S|/|\Omega|| &\leq& \frac{|S|\epsilon }{|\Omega|}\\
\end{eqnarray*}
Thus, the definition provided in the question implies Definition 10.3. Also, it is easy to see that Definition 10.3 implies the definition provided in the question.

Hence, we claim that the definitions are equivalent.

\section{Question}
Exercise 10.9: Recall the Bubblesort algorithm of Exercise 2.22. Suppose we have n cards labeled 1 through n. The order of the cards X can be the state of a Markov chain. Let f(X) be the number of Bubblesort moves necessary to put the cards in increasing sorted order. Design a Markov chain based on the Metropolis algorithm such that, in the stationary distribution, the probability of an order X is proportional to $l^{f(X)}$ for a given constant $l>0$. Pairs of states of the chain are connected if they correspond to pairs of orderings that can be obtained by interchanging at most two cards.

\subsection{Solution}

The order of the cards X constitute the state of a Markov chain, M. Now, we define the transition probabilities in M. In Bubblesort, only adjascent cards can be swapped. We use the Metropolis algorithm to decide the next state, given any arbitrary current state, $X_{i}$:

\begin{itemize}
\item Select a pair of cards at random, with probability 1/T, where $T \geq (2N)$, so that T is at least the number of neighbors of any state in M.
\item If the resulting exchange takes us away from the sorted order, make this $X_{i+1}$ with the probability min (1, $1/l$).
\item Otherwise, if the resulting exchange takes us closer to the sorted order, make this $X_{i+1}$ with the probability min (1, $l$).
\item If no other state was chosen in the previous two steps, stay in the current state.
\end{itemize}

So, there is transition to a new state with either the probability (1/T)min (1, $1/l$) or with the probability (1/T)min (1, $l$). With the remaining probability, the state remains the same at any given time-step.

Thus, M satisfies all the preconditions required for the application of Lemma 10.8 in \cite{mitzenmacherUpfal}. So, with the use of that lemma, we can conclude that the resulting Markov chain has a stationary distribution such that the probability of an order X is proportional to $l^{f(X)}$ for a given constant $l>0$.

\section{Question}
Exercise 11.4:

\subsubsection{1} Consider the Markov chain given by the transition matrix
P=\[ \left( \begin{array}{ccccc}
1/2 & 0 & 1/2 & 0 & 0 \\
0 & 1/2 & 1/2 & 0 & 0 \\
1/4 & 1/4 & 0 & 1/4 & 1/4 \\
0 & 0 & 1/2 & 1/2 & 0 \\
0 & 0 & 1/2 & 0 & 1/2 \\
\end{array} \right)\].

Explain why Theorem 11.5 is not useful when applied directly to P. Then apply Theorem 11.5 to the Markov chain with transition matrix P2, and explain the implications for the convergence of the original Markov chain to its stationary distribution.

\subsubsection{2} Consider the Markov chain given by the transition matrix
P=\[ \left( \begin{array}{ccccc}
1/2 & 0 & 1/2 & 0 & 0 \\
0 & 1/2 & 1/2 & 0 & 0 \\
1/5 & 1/5 & 1/5 & 1/5 & 1/5 \\
0 & 0 & 1/2 & 1/2 & 0 \\
0 & 0 & 1/2 & 0 & 1/2 \\
\end{array} \right)\].

Apply Theorem 11.5 to P. Then apply Theorem 11.5 to the Markov chain with transition matrix $P^{2}$, and explain the implications for the convergence of the original Markov chain to its stationary distribution. Which application gives better bounds on the variation distance?


\subsection{Solution}

Let $p_{x}^{t}$ represent the probability distribution over the states in a Markov chain at time-step t, if the initial state is x.

\subsubsection{1} Consider the Markov chain given by the transition matrix
P=\[ \left( \begin{array}{ccccc}
1/2 & 0 & 1/2 & 0 & 0 \\
0 & 1/2 & 1/2 & 0 & 0 \\
1/4 & 1/4 & 0 & 1/4 & 1/4 \\
0 & 0 & 1/2 & 1/2 & 0 \\
0 & 0 & 1/2 & 0 & 1/2 \\
\end{array} \right)\].

Applying Theorem 11.5 is not useful when applied directly to P, as it merely tells us that $||p_{x}^{t}-\pi|| \leq 1$, which is true by definition for all Markov chains. In other words, the application of Theorem 11.5 does not give us any new way of bounding the mixing time.

$P^{2}$=\[ \left( \begin{array}{ccccc}
3/8 & 1/8 & 1/4 & 1/8 & 1/8 \\
1/8 & 3/8 & 1/4 & 1/8 & 1/8 \\
1/8 & 1/8 & 1/2 & 1/8 & 1/8 \\
1/8 & 1/8 & 1/4 & 3/8 & 1/8 \\
1/8 & 1/8 & 1/4 & 1/8 & 3/8 \\
\end{array} \right)\].

This Markov chain has the same stationary distribution as the original Makrov chain. Every transition in this Markov chain is equivalent to two transitions in the original Markov chain.

The sum of the columnwise minimum transition probabilities, m, is $4/8+1/4=3/4$. Applying Theorem 11.5 to the Markov chain described by $P^{2}$ tells us that $||p_{x}^{t}-\pi|| \leq 4^{-t}$. To ensure that the variation distance from the stationary distribution is c, $t = -\log_{4}c$. For the original markov chain, t should satisfy $t = -2\log_{4}c$. (We are using the coupling lemma here.)

Thus, applying Theorem 11.5 to the Markov chain described by $P^{2}$ gives us a much tighter bound on the variation distance at time t, and on the mixing time.

\subsubsection{2} Consider the Markov chain given by the transition matrix
P=\[ \left( \begin{array}{ccccc}
1/2 & 0 & 1/2 & 0 & 0 \\
0 & 1/2 & 1/2 & 0 & 0 \\
1/5 & 1/5 & 1/5 & 1/5 & 1/5 \\
0 & 0 & 1/2 & 1/2 & 0 \\
0 & 0 & 1/2 & 0 & 1/2 \\
\end{array} \right)\].

Applying Theorem 11.5 directly to P, us that $||p_{x}^{t}-\pi|| \leq (4/5)^{t}$, which is true by definition for all Markov chains.

$P^{2}$=\[ \left( \begin{array}{ccccc}
7/20 & 1/10 & 7/20 & 1/10 & 1/10 \\
1/10 & 7/20 & 7/20 & 1/10 & 1/10 \\
7/50 & 7/50 & 1/2 & 7/50 & 7/50 \\
1/10 & 1/10 & 7/20 & 7/20 & 1/10 \\
1/10 & 1/10 & 7/20 & 1/10 & 7/20 \\
\end{array} \right)\].

This Markov chain has the same stationary distribution as the original Makrov chain. Every transition in this Markov chain is equivalent to two transitions in the original Markov chain.

The sum of the columnwise minimum transition probabilities, m, is $4/10+7/20=15/20=3/4$. Applying Theorem 11.5 to the Markov chain described by $P^{2}$ tells us that $||p_{x}^{t}-\pi|| \leq (1/4)^{t}$. To ensure that the variation distance from the stationary distribution is c, $t = -\log_{4}c$. For the original markov chain, t should satisfy $t = -2\log_{4}c$. (We are using the coupling lemma here.)

Thus, applying Theorem 11.5 to the Markov chain described by $P^{2}$ gives us a much tighter bound on the variation distance at time t, and on the mixing time.

\section{Question}
Exercise 11.7: A technique we use repeatedly in the chapter is to define a distance function $d_{t}$ that represent the distance between the two states of our coupling after t steps, and then show that when $d_{t}>0$ there exists a $b<1$ such that
$E[d_{t+1}|d_{t}]\leq bd_{t}$.

\subsubsection{1} Under this condition, give an upper bound for $T(\epsilon)$ in terms of b and d*, where d* is the maximum distance over all possible pairs of initial states for the coupling.

\subsubsection{2} Suppose that instead we have
$E[d_{t+1}|d_{t}]\leq d_{t}$.

Suppose we have the additional conditions that $d_{t+1}$ is one of $d_{t}, d_{t}-1,$ or $d_{t}+1$ and that $Pr(d_{t} \neq d_{t+1})\geq g$. Give an upper bound for $T(\epsilon)$ in terms of $\epsilon$, d', and g. Your answer should by polynomial in d' and $1/g$. (Hint: Think of $d_{t}$ as being similar to a random walk on the line.)

\subsubsection{3} Using (a) and (b), show that the mixing time of the coloring chain of Section 11.5 is polynomial in the number of vertices in the graph and $\ln(1/\epsilon)$, even when the number of colors is only 2d.

\subsubsection{4} By extending the argument of part (b), show that the mixing time of the Markov chain for independent sets given in Section 11.6 is polynomial in the number of vertices in the graph and $\ln(1/\epsilon)$.

\subsection{Solution}

Consider a distance function $d_{t}$ that represent the distance between the two states of our coupling after t steps. d' is the maximum distance over all possible pairs of initial states for the coupling. Let $T(\epsilon)$ represent the time when the variation distance is at most $\epsilon$. Due to the coupling lemma, this is same as the time when the probability of the coupled chains being in different states is at most $\epsilon$.

\subsubsection{1}

Suppose that when $d_{t}>0$ there exists a $b<1$ such that $E[d_{t+1}|d_{t}]\leq bd_{t}$.
\begin{eqnarray}
E[d_{t+1}|d_{t}] &\leq& bd_{t}\\
E[d_{t+1}] = E[E[d_{t+1}|d_{t}]] &\leq& bE[d_{t}]\\
\therefore E[d_{t+1}] &\leq& b^{t+1}E[d_{0}]\\
E[d_{t}] &\leq& b^{t}E[d_{0}]\\
E[d_{t}] &\leq& b^{t}d'\\
\end{eqnarray} 

We want $Pr[d_{t} > 0] \leq \epsilon$. Note that below, we assume that $d_{t}$ does not take on any value between 0 and 1.

\begin{eqnarray}
Pr(d_{T(\epsilon)} > 0) \leq E[d_{T(\epsilon)}] &\leq& b^{T(\epsilon)}d' \leq \epsilon\\
\therefore T(\epsilon) \leq \log_{b} \frac{\epsilon}{d'}\\
\end{eqnarray}

\subsubsection{2} Suppose that instead we have
$E[d_{t+1}|d_{t}]\leq d_{t}$.

Suppose we have the additional conditions that $d_{t+1}$ is one of $d_{t}, d_{t}-1,$ or $d_{t}+1$ and that $Pr(d_{t} \neq d_{t+1})\geq g$. We want an upper bound for $T(\epsilon)$ in terms of $\epsilon$, d', and g. 

Think of $d_{t}$ as being similar to a random walk on the line stretching from 0 to d', such that 0 is an absorbing state and $Pr(d_{t+1}=d'-1|d_{t}=d') \geq g$ . $E[d_{t+1}|d_{t}]\leq d_{t}$ tells us that $Pr(d_{t+1}=d_{t}-1) \geq Pr(d_{t+1}=d_{t}+1)$. To get an upper bound on $T(\epsilon)$, we want an upper bound on the expected time to reach node 0 using the random walk. So, we can bound this with the expected number of steps required to reach 0, when the transition probabilities are such that $Pr(d_{t+1}=d_{t}-1) = Pr(d_{t+1}=d_{t}+1)$, and where $Pr(d_{t} = d_{t+1}) = 1-g$.

Let $Z_{i}$ represent the number of steps required to move from the state i to state 0. Also, let $h_{i}$ represent $E[Z_{i}]$. $E[Z_{i}]=E[\frac{g}{2}(1+Z_{i-1})+\frac{g}{2}(1+Z_{i+1})+(1-g)(Z_{i}+1)]$. For the special case where i=n, $E[Z_{i}]=E[gZ_{i-1}]+(1-g)(Z_{i}+1)$. Thus, we have the following system of eqations:

\begin{eqnarray}
h_{d'} &=& h_{d'-1}+g^{-1}\\
h_{0} &=& 0\\
h_{i} &=& h_{i-1}/2 + h_{i+1}/2 + g^{-1}\\
\end{eqnarray} 

The above recurrance relations are symmetric to those used in the analysis of the Markov chain for the randomized algorithm for 2-SAT in section 7.1.1 of \cite{mitzenmacherUpfal}. It is easy to prove, using induction, that $h_{i}=(d'^{2}-(d'-i)^{2})/g \leq d'^{2}/g$ satisfies the above system of recurrance relations.

We want to find $T(\epsilon)$ such that $Pr(d_{T(\epsilon)}>0) \leq \epsilon$. In other words, we want $Pr(Z_{d'}>T(\epsilon))<\epsilon$. To find this, let us consider the time required by the ith attempt to move from a position d' in the Markov chain to the position 0 as a Poisson trial. Each attempt is stopped after $2d'^{2}/g$ moves. The trial succeeds if we get to position 0 in the Markov chain. Due to the Markov's inequality, the probability that such a trial fails is at most $2^{-1}$.

Consider n such Poisson trials. The probability that every one of those trials fails is at most $2^{-n}$. We want to choose n such that $2^{-n}<\epsilon$. So, $n \geq \log (1/\epsilon)$.

Hence, after $\log (1/\epsilon)$ trials, the probability that $d_{t} \neq 0$ is at most $\epsilon$. As each trial requires at most $2d'^{2}/g$ steps, we conclude that after $2d'^{2}\log (1/\epsilon)/g$ steps, the probability that $d_{t} \neq 0$ is at most $\epsilon$; and due to the coupling lemma, the variation distance is at most $\epsilon$. Hence, $2d'^{2}\log (1/\epsilon)/g$ constitutes an upper 
bound for $T(\epsilon)$.

\subsubsection{3}
Let d be the maximum degree of any vertex in the graph to be colored. Let n be the number of verteces. Let c be the number of colors. In the proof to theorem 11.8 in \cite{mitzenmacherUpfal}, a distance metric $d_{t}$ for a certain coupling was defined, and it was shown that, for this distance metric $E[d_{t+1}|d_{t}]\leq d_{t} (1-\frac{c-2d}{nc})$. (Each state in the Markov chain corresponds to a certain proper coloring. $d_{t}$ represents the number of verteces which are colored differently in the Markov chains being coupled.)

Transitions in the Markov chain correspond to recoloring of atmost one vertex. Furthermore, as shown in the same proof, $Pr(d_{t} \geq d_{t+1})\geq (cn)^{-1}((c-2d)d_{t}+m') = g$, where m' is the sum of the number of verteces adjascent to each vertex in $D_{t}$, the set of verteces which are colored differnetly in the Markov chains being coupled. So, the construction of the Markov chain and the coupling satisfies the additional conditions that $d_{t+1}$ is one of $d_{t}, d_{t}-1,$ or $d_{t}+1$ and that $Pr(d_{t} \neq d_{t+1})\geq g$. (The value of g was specified above.)

$(1-\frac{c-2d}{nc}) = 1$ when c = 2d. Thus, when c = 2d, $E[d_{t+1}|d_{t}]\leq d_{t} \leq n$. As shown in the answer to the previous subquestion, when this condition is satisfied, the mixing time of the corresponding Markov chain is bounded by $2n^{2}\log (1/\epsilon)/g$.

\subsubsection{4}
Consider a Markov chain on independent sets. So, each state represents an independent set. In section 11.6 in \cite{mitzenmacherUpfal}, a distance metric between states, $d_{t}$, was defined such that it counts the number of verteces which are not present in both the corresponding independent sets. So, $d_{t} \leq n$.

In that section, it was proved that $E[d_{t+1}|d_{t}]\leq d_{t}$. It can be inferred from the discussion in that section that $Pr(d_{t} \neq d_{t+1})\geq \frac{1}{|E|} = g$. So, the construction of the Markov chain and the coupling satisfies the additional conditions that $d_{t+1}$ is one of $d_{t}, d_{t}-1,$ or $d_{t}+1$ and that $Pr(d_{t} \neq d_{t+1})\geq g$. ($\frac{1}{|E|} = g$.) (Actually, according to the discussion in \cite{mitzenmacherUpfal}, it is clear that $d_{t+1}$ can be $d_{t}+2$. But, I proceed to illustrate the general argument to be used if this were not the case.)

So, applying a result proved earlier in the answer to this question, the mixing time of the corresponding Markov chain is bounded by $2n^{2}\log (1/\epsilon)/g$.

\section{Question}
Exercise 11.14: Consider the following variation on shuffling for a deck of n cards. At each step, two specific cards are chosen uniformly at random from the deck, and their positions are exchanged. (It is possible both choices give the same card, in which case no change occurs.)

\subsubsection{1} Argue that the following is an equivalent process: at each step, a specific card is chosen uniformly at random from the deck, and a position from [1, n] is chosen uniformly at random; then the card at position i exchanges positions with the specific card chosen.
\subsubsection{2} Consider the coupling where the two choices of card and position are the same for both copies of the chain. Let Xt be the number of cards whose positions are different in the two copies of the chain. Show that Xt is nonincreasing over time.
\subsubsection{3} Show that
$Pr(X_{t+1} \leq X_{t}-1|X_{t}>0)\geq (\frac{X_{t}}{n})^{2}$.
\subsubsection{4} Argue that the expected time until Xt is 0 is $O(n^{2})$, regardless of the starting state of the two chains.

\subsection{Solution}

\subsubsection{1} Selecting a specific card uniformly at random from the deck is equivalent to selecting a position uniformly at random in the deck, as for any ordering of the cards, there is a one-to-one mapping between the cards and the positions. Hence, as the mapping described above is a bijection, the process of exchanging two randomly selected cards is equivalent to the process of exchanging a randomly selected card with a card in a randomly selected position. In either case, the probability of any pair of cards being selected is $1/n^{2}$.

\subsubsection{2} Consider the coupling where the two choices of card and position are the same for both copies of the chain. Let $X_{t}$ be the number of cards whose positions are different in the two copies of the chain. Let S be the set of cards whose positions are identical in the two stacks. Let S' be the set of positions which contain an identical card in either stack. Note that $|S|=|S'|=X_{t}$ Consider all possible selections of the card and the position. The only way $X_{t}$ can change is if the card selected belongs to S and the position belongs to S'. In this case, as two cards which were previously in different positions are moved to the same target position, $X_{t}$ actually decreases by 1.

Note that it is possible for $X_{t}$ to decrease by 2, in the case where, beside belonging to S, the two cards which are being exchanged are the same in both the stacks.

\subsubsection{3} As explained in the answer to the previous subquestion, the only way $X_{t}$ can change is if the card selected belongs to S and the position belongs to S'. As $|S|=|S'|=X_{t}$, and as the total number of cards is n, this can happen with probability $(\frac{X_{t}}{n})^{2}$.

\subsubsection{4} 
\begin{ack}
I benefitted from discussion with Aditya Saurabh and Julian Bishop in solving this problem.
\end{ack}

As explained in a previous subquestion, $X_{t}$ is non-increasing. And, $X_{t}$ can decrease by either 1 or 2 at each step. As we are looking for an upper bound for the expected time until $X_{t}$ is 0, let us consider a pessimistic version, where $X_{t}$ can only decrease by 1.

Now, consider the Markov chain whose transition graph is a line. It has n+1 states, such that state i corresponds to a state where $X_{t}=i$. Furthermore, node 0 is an absorbing state, and probability of moving to state i-1 from state i is $(\frac{i}{n})^{2}$. With the remaining probability, transition happens to the same state. Also, the probability of moving to state i+1 from state i is 0. Also, the probability of moving to state n-1 from state n is 0. We want the expected number of steps required to go from any node i to the node 0.

Let $h_{i}$ represent the number of steps required to go from state i to state 0. Note that the expected number of steps required before moving left on the Markov chain is $(\frac{n}{i})^{2}$, as this is the expected number of steps for a geometric random variable with parameter $(\frac{X_{t}}{n})^{2}$. Hence, we have the following system of equations:

\begin{eqnarray}
h_{i} &=& h_{i-1} + (\frac{n}{X_{t}})^{2}\\
h_{n} &=& h_{n-1} + 1 \\
h_{0} &=& 0\\
\end{eqnarray}

The solution for this set of recurrance equations is $h_{i}= \sum_{i=1}^{n} (\frac{n}{i})^{2} \\
\leq n^{2} \sum_{i=1}^{n} (\frac{1}{2^{i}}) \leq 2n^{2}= O(n^{2})$.

\section{Question}
Exercise 11.16: Consider the following simple Markov chain whose states are independent sets in a graph G=(V, E). To compute Xi+1 from Xi:

\begin{itemize}
\item choose a vertex u uniformly at random from V, and flip a fair coin;
\item if the flip is heads and $u \in Xi$, then $X_{i+1}=Xi \setminus \{u\}$;
\item if the flip is heads and $u \notin Xi$, then $X_{i+1}=Xi$;
\item if the flip is tails, $u \notin Xi$, and adding u to Xi still gives an independent set, then $Xi+1=Xi\cup\{u\}$;
\item if the flip is tails and $u\in Xi$, then $X_{i+1}=Xi$.
\end{itemize}

\subsubsection{1} Show that the stationary distribution of this chain is uniform over all independent sets.

\subsubsection{2} We consider this Markov chain specifically on cycles and line graphs. For a line graph with n vertices, the vertices are labeled 1 to n, and there is an edge from 1 to 2, 2 to 3, ..., n-1 to n. A cycle graph on n vertices is the same with the addition of an edge from n to 1.

Devise a coupling (Xt, Yt) for this Markov chain such that, on line graphs and cycle graphs, if $d_{t}=|Xt-Yt|+|Yt-Xt|$ is the number of vertices on which the two independent sets disagree, then at each step the coupling is at least as likely to reduce dt as to increase dt.

\subsubsection{3} With the coupling from part (b), argue that you can use this chain to obtain an FPAUS for independent sets on a cycle graph or line graph. You may want to use Exercise 11.7.
\subsubsection{4} For the special cases of line graphs and cycle graphs, we can derive exact formulas for the number of independent sets. Derive exact formulas for these cases and prove that your formulas are correct. (Hint: You may want to express your results in terms of Fibonacci numbers.)

\subsection{Solution}
\subsubsection{1} 

First, we note that the chain has a finite number of states. Let the total number of states be S.

Consider the Markov chain described in the question. We note immediately that any independent set can be reached from the null set; and the null set can be reached from any independent set. Hence, there is a non zero probability that one can reach any state from any state. Hence, the chain is irreducible.

Furthermore, there is always the possibility of getting heads in the coin flip, selecting a vertex u not in Xi (in which case $X_{i+1}=X_{i}$). Hence, there is a non-zero probability of transitioning to the same state. Hence, the Markov chain is aperiodic.

As the Markov chain is aperiodic, finite and irreducible, it has a unique stationary distribution. 

Furthermore, due to the consruction of the Markov chain, we note that the probability of moving from $X_{i}$ to some independent set $X_{i}-{v}$ is $|X_{i}|/(2|V|)$. Let $Big(X_{i})$ represent the set of independent sets which can be reached from the independent set $X_{i}$ by adding a vertex which was not in $X_{i}$. So, we see that the probability of moving from $X_{i}$ to some independent set $X_{i}\cup {v}$ is $(|Big(X_{i}|))/(2|V|)$. Thus, the cumulatuve probability of leaving the state is $(|X_{i}|+|Big(X_{i}|)/(2|V|)$.

Consider the case where the current state could be any one of the states in the Markov chain with equal probability. (That is, we are in a uniform distribution.) Then, from the above discussion, we know that the total probability of transitions out of the state is $(|X_{i}|+|Big(X_{i}|)/(2|V|S)$. Now, the probability of entering the state $X_{i}$ from a neighbor of the form $X_{i}-{v}$ is $|X_{i}|/(2|V|S)$. Also, the probability of entering the state $X_{i}$ from a neighbor of the form $X_{i}\cup {v}$ is $(|Big(X_{i}|))/(|S|2|V|)$. Hence, the total probability of a transition into the state, given a uniform distribution, is the same as the total probability of a transition out of the state. In other words, our Makrov chain is doubly stochastic.

This is a charactaristic property of stationary distributions. Hence, the uniform distribution is the stationary distribution.

\subsubsection{2} 


\subsubsection{3} 
The previous subquestion defines a distance metric, $d_{t}=|Xt-Yt|+|Yt-Xt| \leq n$ is the number of vertices on which the two independent sets disagree. The same subquestion suggests that, for some coupling, at each step the coupling is at least as likely to reduce dt as to increase dt. This implies that, for that coupling, $E[d_{t+1}|d_{t}]\leq d_{t}$. The current subquestion suggests that the construction of the Markov chain and the coupling satisfies the additional conditions that $d_{t+1}$ is one of $d_{t}, d_{t}-1,$ or $d_{t}+1$ and that $Pr(d_{t} \neq d_{t+1})\geq g$, for some g.

Hence, applying our answer to Exercise 11.7, we conclude that $2n^{2}\log (1/\epsilon)/g$ constitutes an upper bound for $T(\epsilon)$. Thus, we conclude that the Markov chain is within variation distance $\epsilon$ of the stationary distribution in time polynomial in $\log (1/\epsilon)$, n. Furthermore, we have already shown that the stationary distribution of the Markov chain is the uniform distribution.

Thus, this Markov chain can be used to construct an FPAUS to almost uniformly sample independent sets on a line graph or a cycle.

\subsubsection{4}

\begin{ack}
Discussions with Padmadevan Chettiar helped me solve this question.
\end{ack}

\begin{rem}
Let the number of independent set inside a line graph of n nodes be denoted by I(n).
\end{rem}

\begin{thm}
The number of independent sets in a line graph can be accurately counted in polynomial time.
\end{thm}
\begin{proof}
Consider a line graph of 0 verteces. It contains exactly one independent set - the null set. Consider a line graph of 1 vertex. It contains exactly 2 independent sets.

Consider a line graph of n verteces. An independent set in this graph either contains the initial vertex, or it does not. The number of independent sets which do not contain the initial vertex is I(n-1). The independent sets which do contain the initial vertex do not contain the vertex next to it. The number of such independent sets is I(n-2). So, I(n)=I(n-1)+I(n-2).

Thus, we have a recurrence relation : the Fibonacci series in particular. Thus, I(n) can be found accurately in polynomial time.

\end{proof}

\begin{thm}
The number of independent sets in a cycle can be accurately counted in polynomial time.
\end{thm}
\begin{proof}
Consider a cycle of 0 verteces. It contains exactly one independent set - the null set.

Mark a particular node in the cycle as the head node. An independent set in the cycle either contains the head node, or it does not.

If an independent set contains the head node, it cannot contain the verteces adjacent to the head node. The number of such independent sets is I(n-3) (which refers to the number of independent sets in a line graph of n-3 nodes).

If an independent set does not contain the head node, it can contain the verteces adjacent to the head node. The number of such independent sets is I(n-1).

So, total number of independent sets = I(n-1)+I(n-3).

Thus, using the fibonacci series, the number of independent sets in a cycle can be accurately counted in polynomial time.

\end{proof}


\bibliographystyle{plain}
\bibliography{../randomizedAlgorithms}

\end{document}
